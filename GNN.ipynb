{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNN.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/Nishant-Ramakuru/Inference-based-GNNS/blob/main/GNN.ipynb",
      "authorship_tag": "ABX9TyO626TRS5mpB+BDyuqDNA0H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nishant-Ramakuru/Inference-based-GNNS/blob/main/GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install jit"
      ],
      "metadata": {
        "id": "gB64pJwLJ9Pr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sho3YQ82-xwt"
      },
      "outputs": [],
      "source": [
        "import time, os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import argparse\n",
        "import pickle\n",
        "#import jit, cuda\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCING'] = \"1\"\n",
        "\n",
        "import torch.nn.functional as F\n",
        "device = torch.randn([1]).device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "_aWXPofELC-6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "!pip install patool\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"/content/drive/MyDrive/boids_buffer.rar\", outdir=\"/content/drive/MyDrive\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eyPvTxTIouBF",
        "outputId": "847fa721-9d8c-40d2-a14e-9de78401e52f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!pip install patool\\nimport patoolib\\npatoolib.extract_archive(\"/content/drive/MyDrive/boids_buffer.rar\", outdir=\"/content/drive/MyDrive\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_pickle('/content/drive/MyDrive/GNNs/boids_buffer_50.csv')"
      ],
      "metadata": {
        "id": "pb51ZO2Sw3vu",
        "outputId": "d32a5d69-b436-455a-8a8c-4d32a01bdba9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.index.rename('Time_Step',inplace = True)"
      ],
      "metadata": {
        "id": "U4DeDtkxqC6u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Time steps:\", dataframe.shape[0])\n",
        "print(\"Number of Agents:\", len(dataframe.R[0]))\n"
      ],
      "metadata": {
        "id": "xR1jUFS6xFvk",
        "outputId": "acccb412-e96d-47fe-f9aa-f4178ae6eafd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time steps: 800\n",
            "Number of Agents: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.head(1)"
      ],
      "metadata": {
        "id": "xDnJ8Ss5xlAq",
        "outputId": "cc0a1aaf-ea4c-4d49-fc71-8c7325f6aa4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                           R  \\\n",
              "Time_Step                                                      \n",
              "0          [[539.74475, 245.03323], [543.6497, 141.5064],...   \n",
              "\n",
              "                                                       theta  \n",
              "Time_Step                                                     \n",
              "0          [1.4382355, 1.8777844, 1.0181143, 2.6681843, 0...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b53e06b3-e893-4020-bec6-40d4ddf7ad60\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R</th>\n",
              "      <th>theta</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time_Step</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[539.74475, 245.03323], [543.6497, 141.5064],...</td>\n",
              "      <td>[1.4382355, 1.8777844, 1.0181143, 2.6681843, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b53e06b3-e893-4020-bec6-40d4ddf7ad60')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b53e06b3-e893-4020-bec6-40d4ddf7ad60 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b53e06b3-e893-4020-bec6-40d4ddf7ad60');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "traj_1 = []\n",
        "traj_2 = []\n",
        "for i in range(len(dataframe)):\n",
        "  traj_1.append(dataframe.R[i][0])\n",
        "  traj_2.append(dataframe.R[i][1])\n",
        "x,y = zip(*traj_1)  \n",
        "p,q = zip(*traj_2)\n",
        "plt.scatter(x,y)\n",
        "plt.scatter(p,q)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "6n5i67VEkMxz",
        "outputId": "74baf72d-26d1-4fe4-fcbe-b6668f84fa09"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f4eb649b2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29f5gV5ZXv+1ndNKbBnG5aPT7Y0IFMcphzEGKbvglzkzPjCUkUA9jmZlonPzTRCefcJOMgcwkQvdIwmAN6rmKemcmEjObRaCKdDLaIcUxikjmHM0MmINhIHCaOAtL+Dj8yYkcaet0/qqrZvXtX1Vt7V9Wu2vv9PA/svevHrrf3rv2tVWutdy1RVSwWi8VSWzRUewAWi8ViiR8r7haLxVKDWHG3WCyWGsSKu8VisdQgVtwtFoulBplQ7QEAnHvuuTpjxoxqD8NisVhyxa5du15X1fNKrcuEuM+YMYOdO3dWexgWi8WSK0TkoN8665axWCyWGsSKu8VisdQgVtwtFoulBrHibrFYLDWIFXeLxWKpQYyyZUTkRuCPAQX2Ap8DpgIPAucAu4DPqOpJETkLuA94L/Br4CpVPRD/0BNmoA+eWAvHD0PLNJh/C8ztqfaoxtC/e5DbH9/Pi8eGuKC1meWXzqK7s73aw7JY8k2U3/7oti+ANIKeBgRHKoHmNliwoSraEWq5i0g7cAPQpaoXAo3A1cAG4E5VfRdwFLje3eV64Ki7/E53u3wx0AeP3OB8YajzuGUJbFtW7ZGN0r97kFVb9jJ4bAgFBo8NcePmPdzcv7faQ6sJ+ncP8oH1P2Hmykf5wPqf0L97sNpDsqRBqd/+Izc4ywO3xRV2GBV2gKEj8PAXS++fMKZumQlAs4hMACYBLwEfAr7vrr8X6HafX+G+xl0/X0QknuGmxBNrYXioaKHCznuq8iWV4vbH9zM0fHrMMgXu33GIzrU/tGJUAf27B1n+vafGXDiXf+8p+5nWA6V++8NDznKTbUtx+mTp/RMmVNxVdRD4H8AhHFE/juOGOaaqp9zNDgOeP6AdeMHd95S7/TnF7ysiS0Rkp4jsfO211yr9O+Ll+GGfFVqVL6kULx7zP6mOvjlsrfgK6N26j+GRsX0OhkeU3q37qjQiS2p4VrjJcl+dKLV/hG1jwsQtMwXHGp8JXABMBi6r9MCquklVu1S167zzSs6erR4t0/zX+X35KXNBa3Pges+KtwIfnWNDw5GWW2qEoLtyaRy/LEgnKtk2JkzcMh8GnlfV11R1GNgCfABodd00ANMA7551EJgO4K5vwQms5of5twSvz4BrZvmlszDxdVk3jcViyGMr/Nfp6fHL5t8CTcFGFgCNE8M1JQFMxP0QME9EJrm+8/nAL4GfAp9wt7kWeNh9vtV9jbv+J5q3Xn5hke1tS9MZRwDdne18al6HkcAffXOYpZv3MPuWv7MiXyH286thho74r2uZPn7Z3B54zyeD33PiZLjiL7OZLaOqP8cJjD6JkwbZAGwCVgDLRORZHJ/63e4udwPnuMuXASsTGHfylPoyPU6eyETmzLruOdx51UW0NjcZbX/i5GmWbt5jLfkKsH73OsXP8n7qQf99Jk6Gr7xYtRRqo2wZVV2tqr+rqheq6mdU9S1VfU5V36eq71LVP1TVt9xtf+u+fpe7/rlk/4SECLuN2nl3Jtwz3Z3t7Fn9UT49r8N4HxtwDWbKJP+LpfW71ymlBHrbMhg+4b/Pwo3JjccAO0PVj7k90DQ5eJsgH13KrOuew6cN3TRgA65BrF40u9pDsKRNVENtoM8x8IKo8qRHK+5BLAq58gb56KpAVDcNWIEvhZ3lW4dENdQeCYm7NbeVP5aYsOIexNwe6Lo+eJsMuGYKKcdNc/+OQ8xY+aj1xRtiP6MaJMhQKxbqgb5gdww4JQeqjBX3MBbeEeyeyUDmTCnWdc9hY0Qr3suqsZZ8MKu2DFR7CJY4CTPQioU6bCJj1/VVd8mAFXczgtwzGcmcKYVnxR9Y/7HIlny9W/FBQdWh4ZG6/mxqjiADrWnyeKEOmsg4cbJjEGaATPRQzTxze2DL5/3X77wbOuZl4mrtx7ruOYAj3CZ4GTU7Dx4Z3beeWL1oNks37/Fdf/vj+61vPg1KVV00fWyZHl7Nddsyx0Dzo9iwCzPkqpwhU4gVd1Oa24L9co+tyLS4wxmBf2DHIUxmlXkZNYX71gvdne3c9NBeTpwsMTMRp5iYpUyiCHZh+Vxvlqjp4/EXHKPsof8KOhL83n4U/qZzkCFTiHXLmBIWIMlY5owfNqPGnFuvDL6gWddMBAb6YMNM6G1xBLe4TK7fo5EZEoKOlPfexYHUsAyZoImPVcCKuykmmTM5wfPFb7zqIpqbzE6BehT4MLeLDawa4In6ls/nxgAapdCgC5uwhFSlfkwQVtyjEBYoyVhaZBjdne088+cLjLNq6lHg2wOqb9rAagjbljlNbvIm6jA242XbsnB3TNd1mXLJgBX3eMnQjNUoRMmNv3/HoboStOWXzgpcb613H0YFMV81A0EcYV94x5m7jjBhz1CGTCFW3KMS5FfLo4VSgFfCIIx6Kp7V3dnO5Iklanm7WOu9BAN9TteyXKKw61tnYgMmv+kMZcgUYsU9CgN9wWlTNYCJwNdb8aywwGo9XeyMeGItxha7uBJUqhlGtfACsCZkZMJSKay4m5Jn/2FETC34eiHMej82NGyt90JMupU1t8HHvwlXfsO5Gy7VDCPreO6bjGLFPYjC9C0T/2EGigXFRb3ltYcRZr1b37tL2CSfmX/giPnQESf/vDAtMjdI5oUdrLiXptz0rQwUC4qThoD6wfVmqXZ3tgfezQwNj9RdJtE4TLJKnv/7ghz3CO6PrNDcBh/flHlhB7MG2bNEZE/Bv9+IyFIRaRORH4nIr9zHKe72IiJfE5FnRWRARC5O/s+IgeJJFlHdL81tmfW9lctIwI1KPfqZw+5m6jFVdBQTYc8znhtpxfO5+Z2btNnbr6oXqepFwHuBN4GHcNrnPaGq7wae4Ew7vQXAu91/S4CvJzHw2IhjkkVTc81Z7RCc411vQVWPoIJiUKcCn6qwu7eTXgB29LHBYBvTx4L3yqGoe0StLTMf+FdVPSgiVwCXuMvvBX6G01f1CuA+tyn2DhFpFZGpqvpSTGOunIE+Jyc9juCoSXGinLL80lmBxbPqkbCCYuAI/KMDL7F60ezaLy6WtLBHKQJmGUNUcb8a+K77/PwCwX4ZON993g4URkgOu8vGiLuILMGx7OnoSDgzo7BQkUmxoDCa2xxLvcZPtO7OdivuRXR3trPz4JHQ6ppebfylm/fQ3trM8ktn1Y7Qj/k9xYn727RCHgvG4i4iE4HFwKridaqqIhJJMVV1E7AJoKurK/5pbL4nYAWHqhNRtwQTtXzy4LGh2imfvG2ZO0Epxp+sFfNEiGK5LwCeVNVX3NeveO4WEZkKvOouHwQKp3FOc5clS9zWuYcVdF/6dw/WjjUakagC75VP/s7PDzGi5MeaH1OetyGGDBdrnadFFHH/I864ZAC2AtcC693HhwuWf0lEHgTeDxxPzN+ehHXuYUU9lHpvWBG1Pj6cyUAaPDaUXbeN3++qImEXp7hWDlIIU2H0Mz4MLdMSudCJE/cM2UhkMnAIeKeqHneXnQP0AR3AQaBHVY+IiAB/AVyGk1nzOVXdGfT+XV1dunNn4CbjGeiDR26A4RibJlhBH0fn2h9y9E3/zJgD6z+W4miySf/uQXq37oslg6iqQh9nogFgrfQCwjwLTc2w6GuRPyMR2aWqXSXXmYh70pQl7ndeGF9Ax4q6L/27B32DqgI8b8V9lJv790ay4sOYMqkp+YybJIKj9fp7qtQ13DIdbnw60i61Ke69rVTkfrHWhDEzVj7qu85a7mPp3z3I7Y/vj7UNX4MQn58+dh96ATP/AK7dGt/7ZY2g9oCxxPkEeo9F2yNA3PPbQ7Vlmrm14Z3EVtAtCdPd2T4qvnG5ayr20yfiQy+iua02hN3U+k6iHWDLtMrfo4D8ivv8W8J97lbME6eeM2bC8IQ+CWu+UOh93Tex+9D9kOzM0C5lXfuJtGf0+W6XolejqTn2Nn35dctA6S/SCnrsBAVVW5ub2LP6oymPKL8kIfQeDQILZTtfmfg9zuc1Auq+xUs1KiRGEfGsU0GMojZ97pbUCAqqgvW7l0uh0FciS4sbttPbdB9TeAMASU3VSUfYk5rDUi1idBPXps/dkhq2DEEyFPrnIbqPvlDU4xF0Vzib28xcOUkJe6CY51DYqxTzs+JusWSE4mBsKfdNnFa6qiOVr8p5vHDxcv6Pxf/VWbFhZvjOcQl7qFWeUTEv9tdn0C1sxd1ihJeOVwobVI0f7/Pc8+gm/vjk/bTL64wgNKBlC7oqjOBI6It6Lred6mHryAedlf8A/MOjrJ3wLT7TeCT4GJUIe16t8hxm3FlxtxgR1Lhj1ZYBK+5xMtDH0Udu5oqTr3AFZ8qLN1YgfiMK3z79YVafus53mzUT7uEzjT+OX9iTLBMSxGgev2G2TAat70qw4m4xor212TfDY2h4xFrvceCmLurQEZy2ZuW/VaCVXoLFDdu5JkDYVeG+0x9m9fb5tD/9k+Ac+7QDoMUiXSPiXCk2W8ZiRFjGTHtrM/975YdSHFGNEOP0f++nfETPZs2pawLFvJinz7qOs+W3vut/PXI27z25adzyRhFOq56ZVDX4/8VfEtiPei1zUIDNlrFUTHdnOzc9tJcTJ0+XXJ9E3nbNEvPkItXyBN1jzYR7mIy/sI8orDl1Tcl1H5P/xZeb+rhg6HW035H0WFMxc+jrzgpW3C3G3HrlnEDr3bpmfEignotnpR/lbHqHr+FR/c+cVh21pL3HoEA4OMIe5o759ukPl7xoeD76hiTy6q1VXjHWLWOJRFARseamBp758wUpjibjJGChq8Bvm6cyacFaY+ErTKssFP9bGu8OFHaAfxs5izknvzX6enHDdlZPuI82iXHClLXKy8a6ZSyxYQOrIcTsQy8Mik77xH9H5vYwKeL7FE+WGh3nlicC9xtRuOnU9cBYUa8sFdNJ5xzkXG4b7mHXv/sIyy+ZRffcOj5nEsJa7pZI2MBqCRIo0FWcuhj757phZuB4Fdgil/FnQ9dU5H7x5GXQIGMncx2pckDFtWVEpBX4G+BCnO/9OmA/sBmYARzA6cR01O3EdBdwOU4nps+q6pNB72/FPV/MvuXvfAOrUEe1ZmIUdcURdL/UxY1XXRSf6G1bBjvvDt5m5h/Ay3vL/ttUz8QDygnyptKopAaIQ9zvBf6Xqv6NiEwEJgFfAY6o6noRWQlMUdUVInI58Cc44v5+4C5VfX/Q+1txzxdh1vun53WM9hetOZIoo9vcxg3Hr/YVwckTG9m39rJ4jmUi7A0TYeRk5LeOYqWbYkU+mIrEXURagD04/VO1YPl+4BJVfUlEpgI/U9VZIvIN9/l3i7fzO4YV9/wRFFiFmC3NahJ7psv4vqJhF8vYPksTYS+DQiv9Q3/4pVgqXZbCCv14Kg2ozgReA74lIu8BdgF/CpxfINgvA+e7z9uBwmjSYXfZGHEXkSXAEoCOjg6zv8SSGYICq5DzkgSJdC4S6Lqu5NT9VVsGfPeaPLExk8JenIrpWelfq7DSZRBH3xxm6eY9LOvbE1/bwRqmwWCbCcDFwNdVtRM4Aaws3MC16CNdpFV1k6p2qWrXeeedF2VXSwZYfumswNnxXuZMrhjocwKNWz4fU8No9xNqmQ4f31RS2Pt3DzI07H/RuPXKGNxbMQv7iFuKYOZb3+HitzaNCntrc9O4bbs729mz+qMcWP8xNl51Ee2tzbEcH5yJczdu3sPN/Xsrfs9axMRyPwwcVtWfu6+/jyPur4jI1AK3zKvu+kFgesH+09xllhqiu7OdnQePcP+OQ77b9G7dl32rKsbUxVEiTMDp3bovcH3Fn1/Mwn5E/YOkvYtnB+7rV9K4EveNAvfvOMSjAy9Zl00RoeKuqi+LyAsiMktV9wPzgV+6/64F1ruPD7u7bAW+JCIP4gRUjwf52y35ZV33HB56ctA3c+bY0HA2894TCoqWM6MyyF0xZdJ4SzgScQq7+/dd/J3JvptE+Z4rbVRSjOeyidw8vIYxncT0J8ADbqbMc8DncFw6fSJyPXAQ8M7qH+BkyjyLkwr5uVhHbMkUYSUJMuV7z5CoA6Fuq9WLgi3hQOIS9uISv98JDqSXS7FVX4nQe+6anQeP1G7WlgFG4q6qe4BSEdn5JbZV4IsVjsuSE8LcM0PDI9zcv7d6P7IkBD2m6fJBLpmKAqkDfW5lxgopEva0Yiie0Fci8tZdY8sPWGJgXfecQN/7/TsO0fWOtnR+YCmkLsZFkGhVFEh9bAWhXmyv9rkfJZpyrHnE/2JUKphaKSZtB8M4+uZw3VrxVtwtsTBlUhNH3/QXq0TdMymnLsZBmBVc9me1bVn4Xcq5vwuv/7P/ep9uS0Hfb1gwtVIqcdt4VjxQVwJvkgppsYQS5h9OJDWyCqmLcXH74/vjf1PTsgJBwg5l/d1puj289MpPz+uI1Kzq/h2HmLHyUTrX/jB/abplYC13SyyklhqZsaBouQS5F8rKkjER9q7rYeDB4G2a20ouzqIYruueQ9c72iK7a7zMmlp31Vhxt8RGIqmRCTS6AKreDCIotztyloyJsHuiffJE8HYLNpRcnMidRgxU4q6p9YCrdctYYiUsEBg01X4c25bBliVnXC5xCHtzG3z8m7Di+ao2hwgKd0YSGqOUR4HZV4Zn0HRd7/uZBFnGSQRTy6HQXWOKF3CtxVmu1nK3xIpJaqSv9Z6UlV6rnX5Mc9m7roN9DxF4SWmaHOhrD2rXl3QwNSqeq+WBHYeMZr7WasDVWu6W2An7gYyx3gf64M4LobdlbGC0bGEvDIp+E3qPw41PZ0rYY/FfGwv79dAxLzxGsWhj4OqgPqxZdGms657DnVddFOmu4v4dh2oq2Gotd0siBKVGfuT0/+StW/8bZw0fi++AOWqoHDR5ySiYGkXYF94BX70gfLuAzy2vYlc4GWrVloHAAm0etZQXb8XdkgirF80eV5ZgccN2epvuYwpvIJVXgHXIkah7BAX8AoOpUTKFPGHftiw4iOqT015IVoOppkSd8Vorbhor7pZE6O5s56aH9jL/1N+PCjpQdnPlMdSqD50AF8e2ZW5A1MCL7An2QF+4hW+Q056HYKoJnsjf3L83MGXXI+8Cb8XdEi8FQdGnGwSaNB5Bz6GFHhtRioAVWuLblgZv65PTXkyegqkmRAm45lngrbhbKsdn+r+gRJpCWIoattKNKFfYB/rKzmkvJm/BVBO8CVAmbpq8CrwVd0v5xD5bNLkiXbnEWNhL1MF5bEXwLiFBVI+8BlNNiOKmyaPAW3G3RCPGzkVeH06ZVMcuFz9Mhb2Uu2qgL/iCG5LTXkhQJchawRPsWhN4I3EXkQPAvwGngVOq2iUibcBmYAZwAOhR1aMiIsBdOA073gQ+q6pPxj90S8WMmTTkloAdfYxxElERqk67tjWnnHZtG7svontuPm/vEyFqquO4/UN87SE57YUEVYLMUzA1jFoU+CiW+39R1dcLXq8EnlDV9SKy0n29AlgAvNv9937g6+6jpZqEzf70anuPPsYr7J6VXijqHrnotZoWlQp7mK/d0B1jQh6DqUHUmsBX4pa5ArjEfX4v8DMccb8CuM/tyLRDRFq9RtqVDNQSQhQrPCGL3JeW6Xz56BV87+T/WXJ1ue3UaonFDdtZPeE+2PlG+MZBuelhVnuMZYxr8YJcSwJvKu4K/FBEFPiGqm4Czi8Q7JeB893n7UChQ/awu2yMuIvIEmAJQEeHeaEfC6WFvJCErfBgSgdFP7B7kO8F9FqtZ9ZMuIfPNP6YBpPMokBhD5mwZJj66FHLwdQgakXgTcX9g6o6KCL/HviRiIyp9q+q6gq/Me4FYhNAV1dXpH3rhpLWeLEVHtAqLVWCOxd1d7Zz4+Y9vnnFkUsB1whrJtzDNY0/NpsLECTsJn1TDVMfR8dWB8FUP2pB4E0bZA+6j6+KyEPA+4BXPHeLiEwFXnU3HwSmF+w+zV1mCcLYGk/ZpRJItNTFoCt4om34Mkpswg7OuRNW9TGir71egql+5F3gQ8VdRCYDDar6b+7zjwJrga3AtcB69/Fhd5etwJdE5EGcQOpx628vILPWuCvUJtkyZc4WbW9t9p3KHlgKuAYxF3bDXq5hqakRMmRMqLVgqh+mAv9Amk3gDTGx3M8HHnIyHJkAfEdV/05EfgH0icj1wEHA+6X/ACcN8lmcVMjPxT7qvJAHazxMqEf/hsPQMq2iyUXLL501rphYIXWRNTPQx66JN9Imb4QLu+lFdKAveH2MGTIeNf89FWAi8Er2zt9QcVfV54D3lFj+a2B+ieUKfDGW0eWFrFrjxVkz5cz8nNsTmzB4xcSC2vDVNG7xr3MaIhT/Mnrf+DNk6jWY6oeJwB8bGubm/r2Zcc/YGapRyZw1XuROyfjU/VuvnBNovdcs5daIMXnfoAyZlun+6wKo52CqHyYCf3+G3DNW3P3IujWecRH3o7uzvf7E3VDYVeG5GVfzO6bCblLSd/4tZu9VRL0HU/0wEfisJAdYcQdrjWeImguqGgr7iMK3T3+YOw/9Xxhf+sLcMWVkyJhQL8FUP9Z1z+HRgZd8L4BDwyOZcM/Ul7hbazzzZC0oVTaGFTNV4Shn0zvslmQ4ZRh3MCnpG3OGjEdNfD8VUqrTWCFZSI+sXXE3rqVirfG0CeqvWhNBVcOuSapw3+kPs/rUddGP8cTa4PUVZMjYYGo4YckBUH3/e/7F3cgar0KqoRVxX8KsnlwTwb9etrBDcF57hJK+pbDBVDNMkgOqeSeaX3EvddtrrfFcULNB1QgZMRUJe1hee4XuGBtMNaO7s52dB4+EpkeOUsoQTVAz8inuA33wyA0w7N+4NxGsiFv8iNg1afX2cVNEIhwrJJCa4HlZ78HUYoqzZxY3bOfLE/pol9c5TQONjHC613kcg2eIHn/B0TKI/XvLp7g/sTZBYbfWuCUCUVoNFs443f6o72aBGUNhgdQy89pNscHUAtzvft3QEf78LCfCIjA683iCK+jjhL2Y4SFH06y440yFrxgr4pYKMQycApEmJgX6acOs9jLz2j2CgqmV9jrPLQZxPZEKP59YNG0s+RT3lmnl9/Ass+iVxTKGCmeclpUxFGa1x5DXHhRMrYu63GF3YknF9Vqmxft+5FXc59/i43O31rglBWIoJVBWxtBjK4LXx5DXHhRMbW9trvj9M4NJll1aNDVXfMdVinyKuyfWMVUrtKRPgzizMkuR6VmqEQOnQc1LIon7QF+wXz+h2aiFLL90VqLvnxjVssZNsNkyJYixWqElffyEHTI6S7XcwGlchPnaE5qNWkjmvpNiMmSNq8II0ABnsmZooEFGaEjJo5BfcbfkmqDGHZmbpZpQ4DSIMXcvYb72mOq15yqYmklr3HELD+q5bBjuccpJlOBA78dSGY0Vd0tVCGvckRlGe5OmJ+wAtz++/4y4J1CvvRSZDKZmyBp3CI/r/WL3IFsDzu203I7G4i4ijcBOYFBVF4rITOBB4BxgF/AZVT0pImcB9wHvBX4NXKWqB2IfuSXX5GaW6mMrSErYgzJmRu9qwqz25rZIxwyi6sHUDFvjUXzjYed2WiWBo1jufwo8A/w79/UG4E5VfVBE/hq4Hvi6+3hUVd8lIle7210V45gtlnTYtszAx27Y47QEQRkzo26QsAyZBRsiH7ccYg2m5tAaj0oW+gUbibuITAM+BtwKLBOnoeqHgE+6m9wL9OKI+xXuc4DvA38hIuK237NYgGD/bkMWHLwmWTEVBk6DLLzRH0uVM2Q8yhaiGrHGo5KFfsGmlvtG4MvA293X5wDHVPWU+/ow4I20HXgBQFVPichxd/vXC99QRJYASwA6OjrKHb8lp/Ru9ffvBmXSpIKJsMfoX/cl4QJhhVRc5rcOrPEoZKFfcKi4i8hC4FVV3SUil8R1YFXdBGwC6OrqqvbP2ZIyQSd3VSfLmFrsSQs7BAdSY7bag4KpYypBRml4U2PWeFTCSgIn7Zoxsdw/ACwWkcuBt+H43O8CWkVkgmu9TwO8S/8gMB04LCITgBacwKrFYkTVJsuMZsYEIan4uRc3bEdPnvBPQYw5r70wmDqusqGOwBrbfjIqYdZ70q6ZUHFX1VXAKgDXcv9/VPVTIvI94BM4GTPXAg+7u2x1X/+ju/4n1t9uiULVJsuYZMZ0XRermPhlzHy16Z7g3PK4xuD6xJ8/y/GJ+1U2rEr7yQxa41EJst6Tds1Ukue+AnhQRNYBuwHvXvZu4Nsi8ixwBLi6siFaLClgkhmTgJ+9VMbM4obtTOa3/juVk/4Y4k7xxDz9WHa+rPGoVDPlN5K4q+rPgJ+5z58D3ldim98CfxjD2CyWdBjoq1oAtdSP/6tN94yKbUnC3EKZzFDxyL81nhfsDFVL6mSuAXNYLnkamTEuoVZ7YSA1cxkqHrVtjcdJkkFVK+6W1AlKg6wKQe6YtDJjXL48oS/Yah8+Ab0t45dX0xq3Ih5I0EzkJIOqVtwtqRMUSJoyKWMNmFPIjCn88bfL6yFbp4cqOPMVC6xwK+SRCZqJnGRQ1Yq7JVXCXDKrF2WsAXOS4uX6xp8cOQJnVbfTkZfPNoLjVHlRz+W2Uz187av/vYqjqg2qFVS14m5JlVVbBnzXTZ7YmP2a4eUQlqni/pdepsoZa3xET/PiiCPkpUrUfi21MdUvSfndrbhbUqN/9yBDw/4+4VuvnJPiaAzZtiyazz2TmSr+GSrvXPmo715jZqZaEmNMeecYseJuSY0gqx0y2unHS5EsFvjMZaqUl6ES1O6wd3HGXGQ5xqi8c8xYcbekQpjVXtVAanNbcMbMzrtdkfcEtHZqqQQVacvkxTanGJV3jhkr7jVM/+5Bbn98P4PHhmgU4bRq6OOUSU2oOlF80328x/bWZpZfOqukKNz++P7AsVY1kLpgA2z5vMGGrhJWyzqPuTdr5uYb1DBG5Z1jxop7xihHkP0eXdsOgNNuOkTYY+Gto+k+3uPgsSGWbt7D0s17aG1uonfx7FGhD7r1rBf76FMAABtVSURBVHogdW4PHNoRPks1QRTHim4A/zz302/Fmr0TdsG15Bsr7jFQSpALfZmeyIaJcbH/M6q4Fj9WM7Xu2NAwSzfv4cbNe0LHkYlAqudTT1zgS/vGZW4Pv7PyUbZPvIFpfrnuJ084vv6YBD7ogmuDqemSRMZMXYl7nFZxmCAXLjO1nqvepCIBTP6kzPh2RwXesCG2EdF847ed6uGupr/yt963LY1N3G0wNTskkTGTe3E3EexSJ3GlVnEtC3KaVLUxRykW3gEd84LTGccRXy2VrSMf5Fa9m7fLW6U3iNF6t8HUZPDTpCAGjw3Fbr3nWtz7dw+yastehoadbAUrwPlCqGJjjiDm9jj/xuWsp1MQ66ZT1wdb74+tqPiY9RZMDTICy3GhlutaDWLVlr1AfBfWXIv77Y/vHxV2S2minqzlZMsE3d4H8al5Hdm2ED2RTwkvFzrUeh86UrH1Xq1gahKu0UoFtxwXahKG5NDw6VjdM7kW9xcTSv7PCpVaEUGpiXHTv3uQNY/s852oUfx3fWpeB+u6MxBIzRCFudA3nbqejU1/RUNCvvewiTO/s+oHiQhrIXG5RmvJdRqnppk0yH4b8D+Bs9ztv6+qq0VkJk6LvXOAXcBnVPWkiJwF3Ae8F6d36lWqeiC2ERdwQWtzYrO7ysUT5Epu9dIU5bjo7mwfHW+QdZbHvy0tCnOht458kPee/heuafxxSfeMvnWCG2/6Cv2nPxBJYAvTY4OoR2HNAhfEGIOSsPam4tT8nKyqb4hIE7Ad+FNgGbBFVR8Ukb8GnlLVr4vIF4C5qvrfRORq4EpVvSroGF1dXbpz587Igy/2uUehUqvYilb9kXS2VSnhff6sT/r63t/Qt3HhW2ENvS15YuNVF0XSEBHZpapdpdaZNMhW4A33ZZP7T4EPAZ90l98L9AJfB65wnwN8H/gLEZEkmmR7H0KUbJniyTWW/FMounEGx9LOtir1AzmiZ3OOvFFiDUzmtyxu2F6ymqMlGxSfg2HxqdSzZUSkEcf18i7gL4F/BY6p6il3k8OAN6p24AUAVT0lIsdxXDevF73nEmAJQEdHR+SBez/oF48NcUFrc+QrniVZoqaolivExT+WOINjWXAtrDl1jW/mjIjTuWnrSSvuUQgS3LgMgqA7+RkBlTjjTIc0EndVPQ1cJCKtwEPA71Z6YFXdBGwCxy0TZd9id8zgsSFu3LyHnQeP2CBdAHG4FUx+CKYzbeMQ4lr36YZlzmSpc1NU4naN5sV1GlQhsmrZMqp6TER+Cvwe0CoiE1zrfRrgJc4OAtOBwyIyAWjBCazGRqkUSAXu33GIrne0Vf3Li0pSboUkMhVMBLnWBTdtwvLe10y4h9Wnrov1mEnGFLIistUiqEJk2tky5wHDrrA3Ax8BNgA/BT6BkzFzLfCwu8tW9/U/uut/Ere/PegDWLVlIJaTphbcClZka4OtIx9kI39VsjSsCFzT+GN2jfwHHtX/XFbQtpAD6z+WwF9gKaS7s903bTjObBkTy30qcK/rd28A+lR1m4j8EnhQRNYBuwGv4tLdwLdF5FngCHB1bKN1CUqBHBoe8fVbFediW7eCpVySCNYGCe+Leq5vQTER+NrZ9/K1r4T3O+3fPViVfp6WsaxeNHtcpl9zU2OsM7ZNsmUGgM4Sy58D3ldi+W+BP4xldD4sv3RW4AnqWe9+7o7RsbqPVnBrkyQEOI1sq1IBt9tO9QRPajKsObPmkX0xjNBSKYWZfl5SSNyuqlzOUO3ubOemh/Zy4mTp/Pah4RE+csfPePbVE6MCbgW7epjcIeVpNm418CY1XTvhx/4bGdScCZpBbMv8pkvhxL8kyKW4g1MDPMh6/9WrJ1IcTf6II0YQ9h61Lrhps/rUdVzb/I8w7HNuG1exLI0t81tb5Fbcw6z3WiDObBmbqZAPQqs1LtoY3BKwgoJi9pyoLXIr7gBXXtzO/TsOJX4c61awpMWqLQPBG8ztgUeW+lvvAQXF6q3Mb72TW3Hv3z3I5l+8UNF7WLeCJUv07x5kaNi/+faUSa5PPMh6P3kCti0701WqABtMTR+TlOqkdCa34n774/sZPh09SmoF25JVwmqsr17k+sTn9gS7Znbe7XSTKrLgbTA1GYIEvBC/dOjBY0OxN+qAHIt71JlczU0NPPPnCxIajcVSOUHlqydPbBz7w29uCw6gRqz3boOpZpQS8kKKhduUuBt1QI7FPWot96DbXYul2oT5w2+9sqhm0oINwdZ7xF6r9k72DGHzYzyiCngYcTcfyq24L790Fsu//1Qk18zN/XttYTFLJgkLpI4T37k9cGiH44Lx44m1Y8S9tbmJY0PjXTP16JIxFfA058fEWXoAcizu3sleWE6gtbmJN0+e4qSP4Oe1sJiltrm5f2/gnWW7349+4R3w1IP+mTPHxyYc9C6ezfLvPcVwgWI1NUhNu2RKuVGC6jlVi7hLD0COxR1Kz/AKq50RV2ExiyUO+ncPhqbzBv7oI+S9pzHlvRpEDWhWW8zTypYJbbOXBuW22fOjc+0PAzMDPm2bM1sywkVrfljSVeIxeWIj+9ZeFvwmvS3+6yZOhq+8WObosoepO6XapCbglbTZyyNB9ZKBUUvJCryl2gQJO5QIpJaiZfo4F8woAXnvWSYP7pTieTJZS7OuSXE3KU1g/e+WrPPpeR1m5+f8W0Ly3u8pmfeeVW7u38sDOw6Nq9qaFTHPmoj7UZPiDuGFxcD63y3VJSj9UYhwZxlWkgAdlzmTRYr7LVSDvAl4ECadmKYD9wHn4/zdm1T1LhFpAzYDM4ADQI+qHhURAe4CLgfeBD6rqk8mM3x/ujvb2XnwSGCwKqixh8WSNEHpj5GN1LDAqp/bJiPc3L83lTpRkF03StyYWO6ngD9T1SdF5O3ALhH5EfBZ4AlVXS8iK4GVwApgAfBu99/7ga+7j6njWT5BJ03v1n01++VasktYHRnf9Ec/TPLeK6gYmSQmGUOm+NWLqnUhL4VJJ6aXgJfc5/8mIs8A7cAVwCXuZvcCP8MR9yuA+9y+qTtEpFVEprrvkzrruufw0JODvv73Y0PDdnKTJXV6twYX8Sor53nhHcHiHrEkQVqEfRYmpNEhK29E8rmLyAyclns/B84vEOyXcdw24Ah/4T3gYXdZVcQdwv3vNnvGkjZh6Y9li1RY5kwGrfewjCGPerbCy8FY3EXkbOBvgaWq+hvHte6gqioikdyEIrIEWALQ0dERZdfImPjfbfaMJSsYpT/6EZY5k1Hr3Q8RuLPnIvu7LIMGk41EpAlH2B9Q1S3u4ldEZKq7firwqrt8EJhesPs0d9kYVHWTqnapatd5551X7viNWdc950w9bB9CGyVYLDEQliVTkZDN7YGmyf7rPes9I4QVTLPCXj6h4u5mv9wNPKOqhTMhtgLXus+vBR4uWH6NOMwDjlfL317M6kWz8WseD072zM39e1Mbj6U+iTVLphSLNgavf2xFHEeJhbAa9lbYy8fEcv8A8BngQyKyx/13ObAe+IiI/Ar4sPsa4AfAc8CzwDeBL8Q/7PLo7mznU/OCXUD37zhkBd6SGGUXCYtCmPU+dCQz1nvcZW4tZzDJltkOvgbv/BLbK/DFCseVGGHZM2ADrJZkqLhIWBTC8t4z4nuP2pfBYo6Rz73WMAlYWQveEjdhMZ2KsmSKmdsDXdf7r8+I7z3uMreWM9SluHd3tvPpEPcMOAJvO8Zb4iBs0hJUmCVTirBiYduWxnu8MrA+9eSoS3EHx+ViIvBxTLCwWMICh8ZFwqLS3Oa/LiPWu18WW1h2WyIM9MGdF0Jvq/OYgc+nXOpW3MFM4E0nWFgsQYQ1v04svrNgQ/D6DGTOrF40m6bGsWG9pkZh9aIUO0QN9MGGmU6c4vgLgDqPWz7vLM+hyNe1uIOZwFvfu6USIje/jpMcZM50d7Zz+yfeQ3trM4KTMXT7J96TnstmoA/6v+B8FqUYOuKIfG9Lrqz5muzEVA6zb/m7wAwa273JUi7/8f99LNDffmD9x5IdwEBfcOZMjXVrisyGmf7CXhKBrusy0QAlqBNT3VvuHmHWk82esZRDKnntYeQkc6ZqRBJ2AHUKtPW2ZNplY8XdpbuzPTSAYwXeEgWTGuWppQKGWZkZ8L3nklGXTasj9mvaMuO+seJeQFh5ArACbzHDZMJSrHntJgRlzkS2Xi1jcd3b6rp2vWBsFYXeinsBJuUJwAq8JRyTInSJBlJLEZY5U68EXfTiYFTo07Xu8yvuCeWjmua/W4G3+BHmZ4cE89qDCMqcSVrg0qBcTUjtolfKul8C25YlcrR8Nsge6INHboBhN3fYuzJuWQKo07Bg/i1l184wac9XuN5m0Vg8TNwxVc28WrTRSfsbKZi/0dCUbat+oM9p8H38BZBGRxyLH0cb7Lkcf8HRCAjXAZMWhQANE2HkZCV/SQkUdt4DHfNir/WTz1TIOy80b/hbgdCbNu21aZIWj7C0x8kTG9m39rIUR1SCUbE8DC3TKjKE4htLCeEuFuxyaJkONz5ttq1JSuTMP4CX98Yfo4gyzgKCUiHzabkfPxxhW/fW59COyHmp1oK3RMHEHZO6n70Uc3uSFfNCwS4UaGkAHfEXb89d4T3GUd0+ilYs2HDm7t+P5//eSStdeEfpC1Ma4zQkn+LeMs3ccgdG81LBCrwlEfp3D/KAgTsml4WyTNwivtZ2oXi7F744xTuMlmnm25q6Zwq1pPgiOeazajjzN8c5TkPyKe7zbxnrczelTN+WFXhLGL1b9wVKVaL1Y6JQkVAz3rpOwtqOi6ZmRyui4Bl/oQLvoyXFd0Um1n054zQgVNxF5B5gIfCqql7oLmsDNgMzgANAj6oedVvy3QVcDrwJfFZVn4x91N6H99iKiL4vdfYp45bUCrzFj/7dg6EF5hJ1x5QUkBLukDA3SJaFOirNbY6bpRz3k5HAG2pJKRdYSjGP0ICqiPw+8AZwX4G43wYcUdX1IrISmKKqK9z2e3+CI+7vB+5S1feHDaKi2jJj/HuGfPybZX+YNshqKSYsiBrpXBjoG2u0FPupkwg65omwz6PCTLkxbFsWbsFXoCVxEBRQNcqWEZEZwLYCcd8PXKKqL4nIVOBnqjpLRL7hPv9u8XZB7x9b4TBToa+wUJIVeItH2Llw23/4Z3qOf6t8N0g9ERRwrcQSr4QwgW+aDDdVr+haEuJ+TFVb3ecCHFXVVhHZBqx3+64iIk8AK1R1nHKLyBJgCUBHR8d7Dx48WM7f5k/Yl+JFvMvEVOCnTGpi9aLZ+QykWcZS5P5QPc1pbaCREU7jPI5wZmagAg1h9SzqCT+rO05rOwkS1pJKSDQVUlVVRCKbG6q6CdgEjuVe6TjGsfCO4C9k590VTRww9cEffXOYGzfvYefBI9aKzxKmfuqAtD0BJojjjpmA89hYcIia1PUwt0heBDsKJlribZchyhX3V0RkaoFb5lV3+SAwvWC7ae6y6tDcFhxwrbADvKnAKzbQmgqm/mq/wGK10/bSJoo/v1pukawQpiUZFPhyxX0rcC2w3n18uGD5l0TkQZyA6vEwf3uiLNgQ3KTAq2OdgsAXbmMFPoQo6XqBaXtFAl3LQu1RKjOmWMRryapOizAtgcwJvEkq5HeBS4BzReQwsBpH1PtE5HrgIOCdJT/AyZR5FicV8nMJjNkck0kJZaZGFuKJ9QM7DoXKRt0KfDn1QSA8Xa/WBbse3SBZJMoEpwTqxJRDPmvLROXWC2D4hP/6mNKZ+ncP0rt1n1FT7ZrKpAlzh9R7FoiHFer8Y5IemWIGTcXZMkmTuLin3EOyZlIly7W2axxVGEFoQEezZLxHlYI62p6YW7GuLTKU/157hcOiEnZLFYPvvZBczGYNyxYpppbdIQZ+6hFpQEZGGNRzue1UD1tHPjjubTJ/sbbEg8kM1hjcvZVSH5a7R2+L/7oEOsBnIhc+qojXEjHOZrxozQ8D3W2ZKOVrSZevXuAYhn6kkP9uLXePoHSmkyec260Yv4zUcuFNBTyP1rapnzpBf3XVa8dYssnCjcHu3ioHV+tL3MPSmRLoiBJLLnyUhgZ5EHCT/PMM5VWH9UPNbSlfS2WYZNA8UtlcmkqoL3Gf2+N82L6ZM+qIaMxfRpRc+N/803c4uu9vmTL8SoHoFQ4xBz7vvE4zL0FYAw7rZ69zFt4B+x7y9wgMx+8RMKW+xB2cHpJB1nukJiDmFOfCL27Yzpcn9HGBvM5IUV0S8TwAlXR2iZs0q/FlBJN+qFbYLeEegeq4Z+pP3E1upeK+0rpulXXHX2BtcwOiI6AgbvGRhhJ1SVIlKFukBkXblDB3zJRJTSmNxJJp5vY4pUyCgqtVyJ6pP3GHZIuKFU/oKaLBmxJfjapSdhq6Mf27B0P7oa5eNDul0VgyT1hwNe6G2gbUp7iDI2xBLpiwomJZTTEsZYVnKDiZF25/fH/gehtEtYyhGh6BEOpX3OffEtzpvDA10q+bu0c1gpt14POuJoPH/PvzZqYfqiVbLLwDBh70d8+k7HuvX3E3udLuvLvE+nQEvNQU90E9l3+Y8QV6rvuzVMZQzwTdg9mcdosvYe6ZFH3v9Sfuxe6UjKAw2tUnaIo7/wID/Xut5ZgwQZdw646x+BKWbp2i7722xd3YnZIiPkFNmdvDNsOqknVbNjgl+ndXr7+MpQY4HV4VNg1qR9xDslSqFuiMkFLY3dlOd2e7UU2a+3cc4v4dh2yP1gTo3bqv2kOw5JWBPhg56b++uS21oeRf3ENFPQViTjGMMqP16JvDLLU9WmMl6M7J5rbXCSblrkv9zh9bEf7evS2pJEQkIu4ichlwF868nL9R1fVJHIeBPnjkBhj2z2xIlARTDKMIPDgzX7ve0WYt+ISxue11QLGu+JW7Pv6CEzx9bIWjAxBuZHrrS73XIzc4z2PSk9jFXUQagb8EPgIcBn4hIltV9ZdxH4sn1qYr7CkV4PeIIvCKk5ttxT1Z7OdbB0TVlaEjrjA3hG4ayPBQrLWtKhxNSd4HPKuqz6nqSeBB4IoEjgPHD1e2v7h/vpc1M3Fy8PZVyCFf1z2HT8/rMJrQ+mJAbrbFYjGkHF0ZHgpu5ZnksX1Iwi3TDhRO/TwMvL94IxFZAiwB6OjoKO9ILdPKK/QV5E7x67eaYiCkmHXdc+h6R1toJs0Frc0pjqp2mTKpiaNvjv+crb+9TihXV+I6dkwkYbkboaqbVLVLVbvOO++88t5k/i3Q5CNonlXeMt1xp/QeP/NvxfP+VviijdBQ9CNuaDrjU6sS3Z3t7Fn9UTZedRHNTeO/tuamRpZfOqsKI6s9Vi+aTVPj2Hulpkax/vZ6IUhXgpAK5bSp2Tl2TCRhuQ8C0wteT3OXxY8n0E+sdW5nWqZVHnFO4j1jxEuX7N89yO2P7+fFY0Nc0NrM8ktnWX9wTHifo/1865QxGmDQIAccYX7PJ2H3t+F0QCqkRwpF/GLvoSoiE4B/AebjiPovgE+qqm/ycGo9VC0WiyUORlMliwzAwuXNU5xth44kJuJBPVQTaZAtIpcDG3FSIe9R1VuDtrfibrFYLNFJvUG2qv4A+EES722xWCyWcKoWULVYLBZLclhxt1gslhrEirvFYrHUIFbcLRaLpQZJJFsm8iBEXgMOlrn7ucDrMQ4nLuy4opHVcUF2x2bHFY1aHNc7VLXkLNBMiHsliMhOv1SgamLHFY2sjguyOzY7rmjU27isW8ZisVhqECvuFovFUoPUgrhvqvYAfLDjikZWxwXZHZsdVzTqaly597lbLBaLZTy1YLlbLBaLpQgr7haLxVKD5FrcReQyEdkvIs+KyMqUj32PiLwqIk8XLGsTkR+JyK/cxynuchGRr7njHBCRixMc13QR+amI/FJE9onIn2ZhbCLyNhH5JxF5yh3XGnf5TBH5uXv8zSIy0V1+lvv6WXf9jCTGVTC+RhHZLSLbsjIuETkgIntFZI+I7HSXZeEcaxWR74vIP4vIMyLye9Uel4jMcj8n799vRGRptcflHutG95x/WkS+6/4Wkj+/VDWX/3DKCf8r8E5gIvAU8J9SPP7vAxcDTxcsuw1Y6T5fCWxwn18OPIZT5X8e8PMExzUVuNh9/nac2vr/qdpjc9//bPd5E/Bz93h9wNXu8r8G/m/3+ReAv3afXw1sTvj7XAZ8B9jmvq76uIADwLlFy7Jwjt0L/LH7fCLQmoVxFYyvEXgZeEe1x4XTdvR5oLngvPpsGudXoh9ywl/g7wGPF7xeBaxKeQwzGCvu+4Gp7vOpwH73+TeAPyq1XQpjfBj4SJbGBkwCnsTprfs6MKH4OwUeB37PfT7B3U4SGs804AngQ8A29wefhXEdYLy4V/V7BFpcsZIsjatoLB8F/ncWxsWZntJt7vmyDbg0jfMrz26ZUo24q90H7XxVfcl9/jJwvvu8KmN1b+k6cazkqo/NdX3sAV4FfoRz53VMVU+VOPbouNz1x4FzkhgXTmOZLwMj7utzMjIuBX4oIrvEaSgP1f8eZwKvAd9y3Vh/IyKTMzCuQq4Gvus+r+q4VHUQ+B/AIeAlnPNlFymcX3kW90yjzqW3anmmInI28LfAUlX9TeG6ao1NVU+r6kU4lvL7gN9NewzFiMhC4FVV3VXtsZTgg6p6MbAA+KKI/H7hyip9jxNw3JFfV9VO4ASOu6Pa4wLA9V0vBr5XvK4a43J9/FfgXBQvACYDl6Vx7DyLe3qNuM15RUSmAriPr7rLUx2riDThCPsDqrolS2MDUNVjwE9xbkdbxem7W3zs0XG561uAXycwnA8Ai0XkAPAgjmvmrgyMy7P6UNVXgYdwLojV/h4PA4dV9efu6+/jiH21x+WxAHhSVV9xX1d7XB8GnlfV11R1GNiCc84lfn7lWdx/AbzbjTpPxLkV21rlMW0FrnWfX4vj7/aWX+NG6OcBxwtuFWNFRAS4G3hGVe/IythE5DwRaXWfN+PEAZ7BEflP+IzLG+8ngJ+4llesqOoqVZ2mqjNwzqGfqOqnqj0uEZksIm/3nuP4kZ+myt+jqr4MvCAis9xF84FfVntcBfwRZ1wy3vGrOa5DwDwRmeT+Nr3PK/nzK8nARtL/cCLe/4Lju70p5WN/F8eHNoxjzVyP4xt7AvgV8GOgzd1WgL90x7kX6EpwXB/EufUcAPa4/y6v9tiAucBud1xPA7e4y98J/BPwLM6t9Fnu8re5r591178zhe/0Es5ky1R1XO7xn3L/7fPO72p/j+6xLgJ2ut9lPzAlI+OajGPlthQsy8K41gD/7J733wbOSuP8suUHLBaLpQbJs1vGYrFYLD5YcbdYLJYaxIq7xWKx1CBW3C0Wi6UGseJusVgsNYgVd4vFYqlBrLhbLBZLDfL/AyNubM+n0q5uAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functions**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "AW48_5_1hIIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_scheduler(opt, params):\n",
        "    lr_decay_factor = params.get('lr_decay_factor')\n",
        "    lr_decay_steps = params.get('lr_decay_steps')\n",
        "    if lr_decay_factor:\n",
        "        return torch.optim.lr_scheduler.StepLR(opt, lr_decay_steps, lr_decay_factor)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "class build_writers:\n",
        "    def __init__(self, working_dir, is_test=False):\n",
        "        self.writer_dir = os.path.join(working_dir, 'logs/')\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __enter__(self):\n",
        "        train_writer_dir = os.path.join(self.writer_dir, 'train')\n",
        "        val_writer_dir = os.path.join(self.writer_dir, 'val')\n",
        "        self.train_writer = SummaryWriter(train_writer_dir)\n",
        "        self.val_writer = SummaryWriter(val_writer_dir)\n",
        "        if self.is_test:\n",
        "            test_writer_dir = os.path.join(self.writer_dir, 'test')\n",
        "            self.test_writer = SummaryWriter(test_writer_dir)\n",
        "            return self.train_writer, self.val_writer, self.test_writer\n",
        "        else:\n",
        "            return self.train_writer, self.val_writer\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        self.train_writer.close()\n",
        "        self.val_writer.close()\n",
        "        if self.is_test:\n",
        "            self.test_writer.close()"
      ],
      "metadata": {
        "id": "HFpOptCThGhr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed(seed_val):\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    random.seed(seed_val)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "vFsuAoAQhS1G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "\n",
        "\n",
        "class RefNRIMLP(nn.Module):\n",
        "    \"\"\"Two-layer fully-connected ELU net with batch norm.\"\"\"\n",
        "\n",
        "    def __init__(self, n_in, n_hid, n_out, do_prob=0., no_bn=False):\n",
        "        super(RefNRIMLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(n_in, n_hid).to(device),\n",
        "            nn.ELU(inplace=True).to(device),\n",
        "            nn.Dropout(do_prob).to(device),\n",
        "            nn.Linear(n_hid, n_out).to(device),\n",
        "            nn.ELU(inplace=True).to(device)\n",
        "        )\n",
        "        if no_bn:\n",
        "            self.bn = None\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm1d(n_out)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def batch_norm(self, inputs):\n",
        "        orig_shape = inputs.shape\n",
        "        x = inputs.view(-1, inputs.size(-1))\n",
        "        x = self.bn(x)\n",
        "        return x.view(orig_shape)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Input shape: [num_sims, num_things, num_features]\n",
        "        x = self.model(inputs)\n",
        "        if self.bn is not None:\n",
        "            return self.batch_norm(x)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "\n",
        "def sample_gumbel(shape, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Sample from Gumbel(0, 1)\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    U = torch.rand(shape).float()\n",
        "    return - torch.log(eps - torch.log(U + eps))\n",
        "\n",
        "\n",
        "def gumbel_softmax_sample(logits, tau=1, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Draw a sample from the Gumbel-Softmax distribution\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    gumbel_noise = sample_gumbel(logits.size(), eps=eps)\n",
        "    if logits.is_cuda:\n",
        "        gumbel_noise = gumbel_noise.cuda()\n",
        "    y = logits + gumbel_noise\n",
        "    return F.softmax(y, dim=-1)\n",
        "\n",
        "\n",
        "def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
        "    Args:\n",
        "      logits: [batch_size, n_class] unnormalized log-probs\n",
        "      tau: non-negative scalar temperature\n",
        "      hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
        "    Returns:\n",
        "      [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
        "      If hard=True, then the returned sample will be one-hot, otherwise it will\n",
        "      be a probability distribution that sums to 1 across classes\n",
        "    Constraints:\n",
        "    - this implementation only works on batch_size x num_features tensor for now\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    y_soft = gumbel_softmax_sample(logits, tau=tau, eps=eps)\n",
        "    if hard:\n",
        "        shape = logits.size()\n",
        "        _, k = y_soft.data.max(-1)\n",
        "        # this bit is based on\n",
        "        # https://discuss.pytorch.org/t/stop-gradients-for-st-gumbel-softmax/530/5\n",
        "        y_hard = torch.zeros(*shape)\n",
        "        if y_soft.is_cuda:\n",
        "            y_hard = y_hard.cuda()\n",
        "        y_hard = y_hard.zero_().scatter_(-1, k.view(shape[:-1] + (1,)), 1.0)\n",
        "        # this cool bit of code achieves two things:\n",
        "        # - makes the output value exactly one-hot (since we add then\n",
        "        #   subtract y_soft value)\n",
        "        # - makes the gradient equal to y_soft gradient (since we strip\n",
        "        #   all other gradients)\n",
        "        y = y_hard - y_soft.data + y_soft\n",
        "    else:\n",
        "        y = y_soft\n",
        "    return y\n",
        "\n",
        "\n",
        "def get_graph_info(masks, num_vars, use_edge2node=True):\n",
        "    if num_vars == 1:\n",
        "        return None, None, None\n",
        "    edges = torch.ones(num_vars, device=masks.device) - torch.eye(num_vars, device=masks.device)\n",
        "    tmp = torch.where(edges)\n",
        "    send_edges = tmp[0]\n",
        "    recv_edges = tmp[1]\n",
        "    tmp_inds = torch.tensor(list(range(num_vars)), device=masks.device, dtype=torch.long).unsqueeze_(1)\n",
        "    if use_edge2node:\n",
        "        edge2node_inds = (tmp_inds == recv_edges.unsqueeze(0)).nonzero()[:, 1].contiguous().view(-1, num_vars-1)\n",
        "        return send_edges, recv_edges, edge2node_inds\n",
        "    else:\n",
        "        return send_edges, recv_edges"
      ],
      "metadata": {
        "id": "WwFdE2-QlTs0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Definitions**\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wtvRAkXlhVDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters"
      ],
      "metadata": {
        "id": "SP9G-3oMjCIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {}\n",
        "params['num_epochs'] = 10\n",
        "params['num_vars'] = params['num_agents'] = 50\n",
        "params['input_noise_type'] = 'none'\n",
        "params['input_size'] = params['num_agents']*2\n",
        "params['nll_loss_type'] = 'gaussian'\n",
        "params['prior_variance'] = 5e-5\n",
        "params['batch_size'] = 10\n",
        "params['val_batch_size'] = 10\n",
        "params['accumulate_steps'] = 1\n",
        "params['num_edge_types'] = 1\n",
        "params['encoder_dropout'] = 0.5\n",
        "params['encoder_hidden'] = 16\n",
        "params['encoder_rnn_hidden'] = 16\n",
        "params['encoder_rnn_type'] = 'lstm'\n",
        "params['encoder_mlp_num_layers'] = 2\n",
        "params['encoder_mlp_hidden'] = 2\n",
        "params['prior_num_layers'] = 2\n",
        "params['prior_hidden_size'] = 16\n",
        "params['gpu'] = False\n",
        "params['decoder_hidden'] = 16\n",
        "params['skip_first'] = True\n",
        "params['decoder_dropout'] = 0.5\n",
        "params['decoder_type'] = None\n",
        "params['lr'] = 5e-4\n",
        "params['working_dir'] = ('/content/MyDrive/GNNs')"
      ],
      "metadata": {
        "id": "OOtlj23sjEG5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import math\n",
        "import networkx as nx\n",
        "\n",
        "data = []\n",
        "for w in range(len(dataframe)):\n",
        "  \n",
        "  state = np.array(dataframe.R[w])\n",
        "  D = list()\n",
        "  for a,i in enumerate(state):\n",
        "    d= []\n",
        "    for b,j in enumerate(state):\n",
        "      eDistance = math.hypot(i[0] - j[0], i[1] - j[1])\n",
        "      if a == b:\n",
        "        d.append(0)\n",
        "      elif int(eDistance) <= 100:\n",
        "        d.append(1)\n",
        "      else:\n",
        "        d.append(0)\n",
        "    D.append(d)\n",
        "\n",
        "  data.append(np.array(D))"
      ],
      "metadata": {
        "id": "b_xStt0bn--l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = np.array(data)\n",
        "#dataset.shape"
      ],
      "metadata": {
        "id": "bzL4YO2Xh0ah"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#del data\n",
        "#del dataframe"
      ],
      "metadata": {
        "id": "R03iQEoPMhKy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_graph_with_labels(adjacency_matrix, mylabels):\n",
        "    rows, cols = np.where(adjacency_matrix == 1)\n",
        "    edges = zip(rows.tolist(), cols.tolist())\n",
        "    gr = nx.Graph()\n",
        "    gr.add_edges_from(edges)\n",
        "    nx.draw(gr, node_size=30, labels=mylabels, with_labels=False)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NSkdTw-ihcgk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import figure\n",
        "\n",
        "figure(figsize=(100,100), dpi=80)"
      ],
      "metadata": {
        "id": "2Tk0uSY0gzed",
        "outputId": "3536b1b5-e422-4d44-d4f5-cba85d1c817c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 8000x8000 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 8000x8000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [str(i) for i in range(0,50)]\n",
        "show_graph_with_labels(data[700],x)"
      ],
      "metadata": {
        "id": "1st8YzGRtRrB",
        "outputId": "30d728b8-81a5-456c-ec79-e1bcbede816c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder"
      ],
      "metadata": {
        "id": "JQRlVaAAha3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNRI_Encoder(nn.Module):\n",
        "    # Here, encoder also produces prior\n",
        "    def __init__(self, params):\n",
        "        super(DNRI_Encoder, self).__init__()\n",
        "        num_vars = params['num_vars']\n",
        "        self.num_edges = params['num_edge_types']\n",
        "        self.sepaate_prior_encoder = params.get('separate_prior_encoder', False)\n",
        "        no_bn = False\n",
        "        dropout = params['encoder_dropout']\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = nn.Parameter(torch.FloatTensor(encode_onehot(self.recv_edges).transpose()), requires_grad=False)\n",
        "        self.save_eval_memory = params.get('encoder_save_eval_memory', False)\n",
        "\n",
        "\n",
        "        hidden_size = params['encoder_hidden']\n",
        "        rnn_hidden_size = params['encoder_rnn_hidden']\n",
        "        rnn_type = params['encoder_rnn_type']\n",
        "        inp_size = params['input_size']\n",
        "        self.mlp1 = RefNRIMLP(inp_size, hidden_size*16, hidden_size*8, dropout, no_bn=no_bn).to(device)\n",
        "        self.mlp2 = RefNRIMLP(hidden_size*8, hidden_size*4, hidden_size*2, dropout, no_bn=no_bn).to(device)\n",
        "        self.mlp3 = RefNRIMLP(hidden_size*2, hidden_size, int(hidden_size*0.5), dropout, no_bn=no_bn).to(device)\n",
        "        self.mlp4 = RefNRIMLP(int(hidden_size*0.5), int(hidden_size*0.25), int(hidden_size*0.25), dropout, no_bn=no_bn).to(device)\n",
        "\n",
        "        if rnn_hidden_size is None:\n",
        "            rnn_hidden_size = hidden_size\n",
        "        if rnn_type == 'lstm':\n",
        "            self.forward_rnn = nn.LSTM(int(hidden_size*0.25), rnn_hidden_size, batch_first=True)\n",
        "            self.reverse_rnn = nn.LSTM(int(hidden_size*0.25), rnn_hidden_size, batch_first=True)\n",
        "        elif rnn_type == 'gru':\n",
        "            self.forward_rnn = nn.GRU(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "            self.reverse_rnn = nn.GRU(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "        out_hidden_size = 2*rnn_hidden_size\n",
        "        num_layers = params['encoder_mlp_num_layers']\n",
        "        if num_layers == 1:\n",
        "            self.encoder_fc_out = nn.Linear(out_hidden_size, self.num_edges)\n",
        "        else:\n",
        "            tmp_hidden_size = params['encoder_mlp_hidden']\n",
        "            layers = [nn.Linear(out_hidden_size, tmp_hidden_size), nn.ELU(inplace=True)]\n",
        "            for _ in range(num_layers - 2):\n",
        "                layers.append(nn.Linear(tmp_hidden_size, tmp_hidden_size))\n",
        "                layers.append(nn.ELU(inplace=True))\n",
        "            layers.append(nn.Linear(tmp_hidden_size, self.num_edges))\n",
        "            self.encoder_fc_out = nn.Sequential(*layers)\n",
        "\n",
        "        num_layers = params['prior_num_layers']\n",
        "        if num_layers == 1:\n",
        "            self.prior_fc_out = nn.Linear(rnn_hidden_size, self.num_edges)\n",
        "        else:\n",
        "            tmp_hidden_size = params['prior_hidden_size']\n",
        "            layers = [nn.Linear(rnn_hidden_size, tmp_hidden_size), nn.ELU(inplace=True)]\n",
        "            for _ in range(num_layers - 2):\n",
        "                layers.append(nn.Linear(tmp_hidden_size, tmp_hidden_size))\n",
        "                layers.append(nn.ELU(inplace=True))\n",
        "            layers.append(nn.Linear(tmp_hidden_size, self.num_edges))\n",
        "            self.prior_fc_out = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "\n",
        "    def node2edge(self, node_embeddings):\n",
        "        # Input size: [batch, num_vars, num_timesteps, embed_size]\n",
        "        if len(node_embeddings.shape) == 4:\n",
        "            send_embed = node_embeddings[:, self.send_edges, :, :]\n",
        "            recv_embed = node_embeddings[:, self.recv_edges, :, :]\n",
        "        else:\n",
        "\n",
        "            send_embed = node_embeddings[:, self.send_edges, :]\n",
        "            recv_embed = node_embeddings[:, self.recv_edges, :]\n",
        "            #send_embed = node_embeddings[:, self.send_edges, :]\n",
        "            #recv_embed = node_embeddings[:, self.recv_edges, :]\n",
        "        return torch.cat([send_embed, recv_embed], dim=-1)\n",
        "\n",
        "    def edge2node(self, edge_embeddings):\n",
        "        if len(edge_embeddings.shape) == 4:\n",
        "            old_shape = edge_embeddings.shape\n",
        "            tmp_embeddings = edge_embeddings.view(old_shape[0], old_shape[1], -1)\n",
        "            incoming = torch.matmul(self.edge2node_mat, tmp_embeddings).view(old_shape[0], -1, old_shape[2], old_shape[3])\n",
        "        else:\n",
        "            incoming = torch.matmul(self.edge2node_mat, edge_embeddings)\n",
        "        return incoming/(self.num_vars-1) #TODO: do we want this average?\n",
        "\n",
        "\n",
        "    def copy_states(self, prior_state):\n",
        "        if isinstance(prior_state, tuple) or isinstance(prior_state, list):\n",
        "            current_prior_state = (prior_state[0].clone(), prior_state[1].clone())\n",
        "        else:\n",
        "            current_prior_state = prior_state.clone()\n",
        "        return current_prior_state\n",
        "\n",
        "    def merge_hidden(self, hidden):\n",
        "        if isinstance(hidden[0], tuple) or isinstance(hidden[0], list):\n",
        "            result0 = torch.cat([x[0] for x in hidden], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in hidden], dim=0)\n",
        "            result = (result0, result1)\n",
        "        else:\n",
        "            result = torch.cat(hidden, dim=0)\n",
        "        return result\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if self.training or not self.save_eval_memory:\n",
        "            # Inputs is shape [batch, num_timesteps, num_vars, input_size]\n",
        "            num_timesteps = inputs.size(1)\n",
        "            x = inputs.contiguous().to(inputs.device)\n",
        "            # New shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
        "            x = self.mlp1(x)  # 2-layer ELU net per node\n",
        "            #x = self.node2edge(x)\n",
        "            x = self.mlp2(x)\n",
        "            #x_skip = x\n",
        "            #x = self.edge2node(x)\n",
        "            x = self.mlp3(x)\n",
        "            #x = self.node2edge(x)\n",
        "            #x = torch.cat((x, x_skip), dim=-1)  # Skip connection\n",
        "            x = self.mlp4(x)\n",
        "        \n",
        "            \n",
        "            # At this point, x should be [batch, num_edges, num_timesteps, hidden_size]\n",
        "            # RNN aggregation\n",
        "            old_shape = x.shape\n",
        "\n",
        "            x = x.contiguous().view(-1, old_shape[0], old_shape[1])\n",
        "            forward_x, prior_state = self.forward_rnn(x)\n",
        "            timesteps = old_shape[1]\n",
        "            reverse_x = x.flip(1)\n",
        "            reverse_x, _ = self.reverse_rnn(reverse_x)\n",
        "            reverse_x = reverse_x.flip(1)\n",
        "            \n",
        "            #x: [batch*num_edges, num_timesteps, hidden_size]\n",
        "\n",
        "            #timesteps = 2\n",
        "            #self.num_edges = 1\n",
        "            prior_result = self.prior_fc_out(forward_x).view(old_shape[0]).contiguous()\n",
        "            combined_x = torch.cat([forward_x, reverse_x], dim=-1)\n",
        "            encoder_result = self.encoder_fc_out(combined_x).view(old_shape[0]).contiguous()\n",
        "            return prior_result, encoder_result, prior_state\n",
        "        else:\n",
        "            # Inputs is shape [batch, num_timesteps, num_vars, input_size]\n",
        "            num_timesteps = inputs.size(1)\n",
        "            all_x = []\n",
        "            all_forward_x = []\n",
        "            all_prior_result = []\n",
        "            prior_state = None\n",
        "            for timestep in range(num_timesteps):\n",
        "                x = inputs[:, timestep]\n",
        "                #x = inputs.transpose(2, 1).contiguous()\n",
        "                x = self.mlp1(x)  # 2-layer ELU net per node\n",
        "                x = self.node2edge(x)\n",
        "                x = self.mlp2(x)\n",
        "                x_skip = x\n",
        "                x = self.edge2node(x)\n",
        "                x = self.mlp3(x)\n",
        "                x = self.node2edge(x)\n",
        "                x = torch.cat((x, x_skip), dim=-1)  # Skip connection\n",
        "                x = self.mlp4(x)\n",
        "            \n",
        "                \n",
        "                # At this point, x should be [batch, num_edges, num_timesteps, hidden_size]\n",
        "                # RNN aggregation\n",
        "                old_shape = x.shape\n",
        "                x = x.contiguous().view(-1, 1, old_shape[-1])\n",
        "                forward_x, prior_state = self.forward_rnn(x, prior_state)\n",
        "                all_x.append(x.cpu())\n",
        "                all_forward_x.append(forward_x.cpu())\n",
        "                all_prior_result.append(self.prior_fc_out(forward_x).view(old_shape[0], 1, old_shape[1], self.num_edges).cpu())\n",
        "            reverse_state = None\n",
        "            all_encoder_result = []\n",
        "            for timestep in range(num_timesteps-1, -1, -1):\n",
        "                x = all_x[timestep].cuda()\n",
        "                reverse_x, reverse_state = self.reverse_rnn(x, reverse_state)\n",
        "                forward_x = all_forward_x[timestep].cuda()\n",
        "                \n",
        "                #x: [batch*num_edges, num_timesteps, hidden_size]\n",
        "                combined_x = torch.cat([forward_x, reverse_x], dim=-1)\n",
        "                all_encoder_result.append(self.encoder_fc_out(combined_x).view(inputs.size(0), 1, -1, self.num_edges))\n",
        "            prior_result = torch.cat(all_prior_result, dim=1).cuda(non_blocking=True)\n",
        "            encoder_result = torch.cat(all_encoder_result, dim=1).cuda(non_blocking=True)\n",
        "            return prior_result, encoder_result, prior_state\n",
        "\n",
        "    def single_step_forward(self, inputs, prior_state):\n",
        "        # Inputs is shape [batch, num_vars, input_size]\n",
        "        x = self.mlp1(inputs)  # 2-layer ELU net per node\n",
        "        x = self.node2edge(x)\n",
        "        x = self.mlp2(x)\n",
        "        x_skip = x\n",
        "        x = self.edge2node(x)\n",
        "        x = self.mlp3(x)\n",
        "        x = self.node2edge(x)\n",
        "        x = torch.cat((x, x_skip), dim=-1)  # Skip connection\n",
        "        x = self.mlp4(x)\n",
        "\n",
        "        old_shape = x.shape\n",
        "        x  = x.contiguous().view(-1, 1, old_shape[-1])\n",
        "        old_prior_shape = prior_state[0].shape\n",
        "        prior_state = (prior_state[0].view(-1, old_prior_shape[0]*old_prior_shape[1], old_prior_shape[2]),\n",
        "                       prior_state[1].view(-1, old_prior_shape[0]*old_prior_shape[1], old_prior_shape[2]))\n",
        "\n",
        "        x, prior_state = self.forward_rnn(x, prior_state)\n",
        "        prior_result = self.prior_fc_out(x).view(old_shape[0], old_shape[1], self.num_edges)\n",
        "        prior_state = (prior_state[0].view(old_prior_shape), prior_state[1].view(old_prior_shape))\n",
        "        return prior_result, prior_state"
      ],
      "metadata": {
        "id": "2_bOioDJhY6K"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder = DNRI_Encoder(params)"
      ],
      "metadata": {
        "id": "Eud6aKEfh5Gk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder"
      ],
      "metadata": {
        "id": "CPCejo-niE0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNRI_Decoder(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(DNRI_Decoder, self).__init__()\n",
        "        self.num_vars = num_vars =  params['num_vars']\n",
        "        input_size = params['input_size']\n",
        "        self.gpu = params['gpu']\n",
        "        n_hid = params['decoder_hidden']\n",
        "        edge_types = params['num_edge_types']\n",
        "        skip_first = params['skip_first']\n",
        "        out_size = params['input_size']\n",
        "        do_prob = params['decoder_dropout']\n",
        "\n",
        "        self.msg_fc1 = nn.ModuleList(\n",
        "            [nn.Linear(2*n_hid, n_hid) for _ in range(edge_types)]\n",
        "        )\n",
        "        self.msg_fc2 = nn.ModuleList(\n",
        "            [nn.Linear(n_hid, n_hid) for _ in range(edge_types)]\n",
        "        )\n",
        "        self.msg_out_shape = n_hid\n",
        "        self.skip_first_edge_type = skip_first\n",
        "        '''\n",
        "        self.hidden_r = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_i = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_h = nn.Linear(n_hid, n_hid, bias=False)\n",
        "\n",
        "        self.input_r = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_i = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_n = nn.Linear(input_size, n_hid, bias=True)\n",
        "        '''\n",
        "        self.out_fc1 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc3 = nn.Linear(n_hid, out_size)\n",
        "\n",
        "        print('Using learned recurrent interaction net decoder.')\n",
        "\n",
        "        self.dropout_prob = do_prob\n",
        "\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = nn.Parameter(torch.FloatTensor(encode_onehot(self.recv_edges)), requires_grad=False)\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return torch.zeros(inputs.size(0), inputs.size(1), self.msg_out_shape, device=inputs.device)\n",
        "        \n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "\n",
        "    def forward(self, inputs, hidden, edges):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        # Edges size: [batch, num_edges, num_edge_types]\n",
        "        if self.training:\n",
        "            dropout_prob = self.dropout_prob\n",
        "        else:\n",
        "            dropout_prob = 0.\n",
        "        '''\n",
        "        # node2edge\n",
        "        print(hidden.shape)\n",
        "        #receivers = hidden[:, self.recv_edges, :]\n",
        "        #senders = hidden[:, self.send_edges, :]\n",
        "        receivers = hidden\n",
        "        senders = hidden\n",
        "\n",
        "        # pre_msg: [batch, num_edges, 2*msg_out]\n",
        "        pre_msg = torch.cat([receivers, senders], dim=-1)\n",
        "\n",
        "        all_msgs = torch.zeros(pre_msg.size(0), pre_msg.size(1),\n",
        "                                        self.msg_out_shape, device=inputs.device)\n",
        "        \n",
        "        if self.skip_first_edge_type:\n",
        "            start_idx = 1\n",
        "            norm = float(len(self.msg_fc2)) - 1\n",
        "        else:\n",
        "            start_idx = 0\n",
        "            norm = float(len(self.msg_fc2))\n",
        "\n",
        "        # Run separate MLP for every edge type\n",
        "        # NOTE: to exclude one edge type, simply offset range by 1\n",
        "        for i in range(start_idx, len(self.msg_fc2)):\n",
        "            msg = torch.tanh(self.msg_fc1[i](pre_msg))\n",
        "            msg = F.dropout(msg, p=dropout_prob)\n",
        "            msg = torch.tanh(self.msg_fc2[i](msg))\n",
        "            msg = msg * edges[:, i:i+1]\n",
        "\n",
        "            all_msgs += msg/norm\n",
        "\n",
        "        # This step sums all of the messages per node\n",
        "        agg_msgs = all_msgs.transpose(-2, -1).matmul(self.edge2node_mat).transpose(-2, -1)\n",
        "        agg_msgs = agg_msgs.contiguous() / (self.num_vars - 1) # Average\n",
        "        '''\n",
        "        # Output MLP\n",
        "        pred = F.dropout(F.relu(self.out_fc1(hidden)), p=dropout_prob)\n",
        "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=dropout_prob)\n",
        "        pred = F.dropout(F.relu(self.out_fc3(pred)), p=dropout_prob)\n",
        "\n",
        "        #pred = inputs + pred\n",
        "        pred = pred[0][0][:]\n",
        "        #print('pred size', pred.shape)\n",
        "        #print('input_size', inputs.shape)\n",
        "\n",
        "        return pred, hidden"
      ],
      "metadata": {
        "id": "Go9WhD0QiHar"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNRI"
      ],
      "metadata": {
        "id": "L4P7pl1PiPGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNRI(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(DNRI, self).__init__()\n",
        "        # Model Params\n",
        "        self.num_vars = params['num_vars']\n",
        "        self.encoder = DNRI_Encoder(params)\n",
        "        self.decoder = DNRI_Decoder(params)\n",
        "        self.num_edge_types = params.get('num_edge_types')\n",
        "\n",
        "        # Training params\n",
        "        self.gumbel_temp = params.get('gumbel_temp')\n",
        "        self.train_hard_sample = params.get('train_hard_sample')\n",
        "        self.teacher_forcing_steps = params.get('teacher_forcing_steps', -1)\n",
        "        \n",
        "        self.normalize_kl = params.get('normalize_kl', False)\n",
        "        self.normalize_kl_per_var = params.get('normalize_kl_per_var', False)\n",
        "        self.normalize_nll = params.get('normalize_nll', False)\n",
        "        self.normalize_nll_per_var = params.get('normalize_nll_per_var', False)\n",
        "        self.kl_coef = params.get('kl_coef', 1.)\n",
        "        self.nll_loss_type = params.get('nll_loss_type', 'crossent')\n",
        "        self.prior_variance = params.get('prior_variance')\n",
        "        self.timesteps = params.get('timesteps', 0)\n",
        "        self.burn_in_steps = params.get('train_burn_in_steps')\n",
        "        self.teacher_forcing_prior = params.get('teacher_forcing_prior', False)\n",
        "        self.val_teacher_forcing_steps = params.get('val_teacher_forcing_steps', -1)\n",
        "        self.add_uniform_prior = params.get('add_uniform_prior')\n",
        "        if self.add_uniform_prior:\n",
        "            if params.get('no_edge_prior') is not None:\n",
        "                prior = np.zeros(self.num_edge_types)\n",
        "                prior.fill((1 - params['no_edge_prior'])/(self.num_edge_types - 1))\n",
        "                prior[0] = params['no_edge_prior']\n",
        "                log_prior = torch.FloatTensor(np.log(prior))\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                if params['gpu']:\n",
        "                    log_prior = log_prior.cuda(non_blocking=True)\n",
        "                self.log_prior = log_prior\n",
        "                print(\"USING NO EDGE PRIOR: \",self.log_prior)\n",
        "            else:\n",
        "                print(\"USING UNIFORM PRIOR\")\n",
        "                prior = np.zeros(self.num_edge_types)\n",
        "                prior.fill(1.0/self.num_edge_types)\n",
        "                log_prior = torch.FloatTensor(np.log(prior))\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                if params['gpu']:\n",
        "                    log_prior = log_prior.cuda(non_blocking=True)\n",
        "                self.log_prior = log_prior\n",
        "\n",
        "    def single_step_forward(self, inputs, decoder_hidden, edge_logits, hard_sample):\n",
        "        old_shape = edge_logits.shape\n",
        "        edges = gumbel_softmax(\n",
        "            edge_logits.reshape(-1, self.num_edge_types), \n",
        "            tau=self.gumbel_temp, \n",
        "            hard=hard_sample).view(old_shape)\n",
        "        predictions, decoder_hidden = self.decoder(inputs, decoder_hidden, edges)\n",
        "        return predictions, decoder_hidden, edges\n",
        "\n",
        "    def calculate_loss(self, inputs, is_train=False, teacher_forcing=True, return_edges=False, return_logits=False, use_prior_logits=False):\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        num_time_steps = inputs.size(0)\n",
        "        all_edges = []\n",
        "        all_predictions = []\n",
        "        all_priors = []\n",
        "        hard_sample = (not is_train) or self.train_hard_sample\n",
        "        prior_logits, posterior_logits, _ = self.encoder(inputs[:, :])\n",
        "        if not is_train:\n",
        "            teacher_forcing_steps = self.val_teacher_forcing_steps\n",
        "        else:\n",
        "            teacher_forcing_steps = self.teacher_forcing_steps\n",
        "        for step in range(num_time_steps):\n",
        "            if (teacher_forcing and (teacher_forcing_steps == -1 or step < teacher_forcing_steps)) or step == 0:\n",
        "                current_inputs = inputs[step]\n",
        "            else:\n",
        "                current_inputs = predictions\n",
        "            if not use_prior_logits:\n",
        "                current_p_logits = posterior_logits[step]\n",
        "            else:\n",
        "                current_p_logits = prior_logits[step]\n",
        "            predictions, decoder_hidden, edges = self.single_step_forward(current_inputs, decoder_hidden, current_p_logits, hard_sample)\n",
        "            all_predictions.append(predictions)\n",
        "            all_edges.append(edges)\n",
        "        \n",
        "        all_predictions = torch.stack(all_predictions, dim=0)\n",
        "        target = inputs[:,:]\n",
        "        loss_nll = self.nll(all_predictions, target)\n",
        "        prob = F.softmax(posterior_logits, dim=-1)\n",
        "        loss_kl = self.kl_categorical_learned(prob, prior_logits)\n",
        "        if self.add_uniform_prior:\n",
        "            loss_kl = 0.5*loss_kl + 0.5*self.kl_categorical_avg(prob)\n",
        "        loss = loss_nll + self.kl_coef*loss_kl\n",
        "        loss = loss.mean()\n",
        "\n",
        "        if return_edges:\n",
        "            return loss, loss_nll, loss_kl, edges\n",
        "        elif return_logits:\n",
        "            return loss, loss_nll, loss_kl, posterior_logits, all_predictions\n",
        "        else:\n",
        "            return loss, loss_nll, loss_kl\n",
        "\n",
        "    def predict_future(self, inputs, prediction_steps, return_edges=False, return_everything=False):\n",
        "        burn_in_timesteps = inputs.size(0)\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        all_predictions = []\n",
        "        all_edges = []\n",
        "        prior_logits, _, prior_hidden = self.encoder(inputs[:, :])\n",
        "        for step in range(burn_in_timesteps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            current_edge_logits = prior_logits[:, step]\n",
        "            predictions, decoder_hidden, edges = self.single_step_forward(current_inputs, decoder_hidden, current_edge_logits, True)\n",
        "            if return_everything:\n",
        "                all_edges.append(edges)\n",
        "                all_predictions.append(predictions)\n",
        "        predictions = inputs[:, burn_in_timesteps-1]\n",
        "        for step in range(prediction_steps):\n",
        "            current_edge_logits, prior_hidden = self.encoder.single_step_forward(predictions, prior_hidden)\n",
        "            predictions, decoder_hidden, edges = self.single_step_forward(predictions, decoder_hidden, current_edge_logits, True)\n",
        "            all_predictions.append(predictions)\n",
        "            all_edges.append(edges)\n",
        "        \n",
        "        predictions = torch.stack(all_predictions, dim=1)\n",
        "        if return_edges:\n",
        "            edges = torch.stack(all_edges, dim=1)\n",
        "            return predictions, edges\n",
        "        else:\n",
        "            return predictions\n",
        "\n",
        "    def copy_states(self, state):\n",
        "        if isinstance(state, tuple) or isinstance(state, list):\n",
        "            current_state = (state[0].clone(), state[1].clone())\n",
        "        else:\n",
        "            current_state = state.clone()\n",
        "        return current_state\n",
        "\n",
        "    def merge_hidden(self, hidden):\n",
        "        if isinstance(hidden[0], tuple) or isinstance(hidden[0], list):\n",
        "            result0 = torch.cat([x[0] for x in hidden], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in hidden], dim=0)\n",
        "            return (result0, result1)\n",
        "        else:\n",
        "            return torch.cat(hidden, dim=0)\n",
        "\n",
        "    def predict_future_fixedwindow(self, inputs, burn_in_steps, prediction_steps, batch_size, return_edges=False):\n",
        "        print(\"INPUT SHAPE: \",inputs.shape)\n",
        "        prior_logits, _, prior_hidden = self.encoder(inputs[:, :])\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        for step in range(burn_in_steps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            current_edge_logits = prior_logits[:, step]\n",
        "            predictions, decoder_hidden, _ = self.single_step_forward(current_inputs, decoder_hidden, current_edge_logits, True)\n",
        "        all_timestep_preds = []\n",
        "        all_timestep_edges = []\n",
        "        for window_ind in range(burn_in_steps - 1, inputs.size(1)-1, batch_size):\n",
        "            current_batch_preds = []\n",
        "            current_batch_edges = []\n",
        "            prior_states = []\n",
        "            decoder_states = []\n",
        "            for step in range(batch_size):\n",
        "                if window_ind + step >= inputs.size(1):\n",
        "                    break\n",
        "                predictions = inputs[:, window_ind + step] \n",
        "                current_edge_logits, prior_hidden = self.encoder.single_step_forward(predictions, prior_hidden)\n",
        "                predictions, decoder_hidden, _ = self.single_step_forward(predictions, decoder_hidden, current_edge_logits, True)\n",
        "                current_batch_preds.append(predictions)\n",
        "                tmp_prior = self.encoder.copy_states(prior_hidden)\n",
        "                tmp_decoder = self.copy_states(decoder_hidden)\n",
        "                prior_states.append(tmp_prior)\n",
        "                decoder_states.append(tmp_decoder)\n",
        "                if return_edges:\n",
        "                    current_batch_edges.append(current_edge_logits.cpu())\n",
        "            batch_prior_hidden = self.encoder.merge_hidden(prior_states)\n",
        "            batch_decoder_hidden = self.merge_hidden(decoder_states)\n",
        "            current_batch_preds = torch.cat(current_batch_preds, 0)\n",
        "            current_timestep_preds = [current_batch_preds]\n",
        "            if return_edges:\n",
        "                current_batch_edges = torch.cat(current_batch_edges, 0)\n",
        "                current_timestep_edges = [current_batch_edges]\n",
        "            for step in range(prediction_steps - 1):\n",
        "                current_batch_edge_logits, batch_prior_hidden = self.encoder.single_step_forward(current_batch_preds, batch_prior_hidden)\n",
        "                current_batch_preds, batch_decoder_hidden, _ = self.single_step_forward(current_batch_preds, batch_decoder_hidden, current_batch_edge_logits, True)\n",
        "                current_timestep_preds.append(current_batch_preds)\n",
        "                if return_edges:\n",
        "                    current_timestep_edges.append(current_batch_edge_logits.cpu())\n",
        "            all_timestep_preds.append(torch.stack(current_timestep_preds, dim=1))\n",
        "            if return_edges:\n",
        "                all_timestep_edges.append(torch.stack(current_timestep_edges, dim=1))\n",
        "        result =  torch.cat(all_timestep_preds, dim=0)\n",
        "        if return_edges:\n",
        "            edge_result = torch.cat(all_timestep_edges, dim=0)\n",
        "            return result.unsqueeze(0), edge_result.unsqueeze(0)\n",
        "        else:\n",
        "            return result.unsqueeze(0)\n",
        "\n",
        "    def nll(self, preds, target):\n",
        "        if self.nll_loss_type == 'crossent':\n",
        "            return self.nll_crossent(preds, target)\n",
        "        elif self.nll_loss_type == 'gaussian':\n",
        "            return self.nll_gaussian(preds, target)\n",
        "        elif self.nll_loss_type == 'poisson':\n",
        "            return self.nll_poisson(preds, target)\n",
        "\n",
        "    def nll_gaussian(self, preds, target, add_const=False):\n",
        "        #print(preds.shape,target.shape)\n",
        "        neg_log_p = ((preds - target) ** 2 / (2 * self.prior_variance))\n",
        "        const = 0.5 * np.log(2 * np.pi * self.prior_variance)\n",
        "        #neg_log_p += const\n",
        "        if self.normalize_nll_per_var:\n",
        "            return neg_log_p.sum() / (target.size(0) * target.size(2))\n",
        "        elif self.normalize_nll:\n",
        "            return (neg_log_p.sum(-1) + const).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return neg_log_p.view(target.size(0), -1).sum() / (target.size(1))\n",
        "\n",
        "\n",
        "    def nll_crossent(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def nll_poisson(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def kl_categorical_learned(self, preds, prior_logits):\n",
        "        log_prior = nn.LogSoftmax(dim=-1)(prior_logits)\n",
        "        kl_div = preds*(torch.log(preds + 1e-16) - log_prior)\n",
        "        if self.normalize_kl:     \n",
        "            return kl_div.sum(-1).view(preds.size(0), -1).mean(dim=1)\n",
        "        elif self.normalize_kl_per_var:\n",
        "            return kl_div.sum() / (self.num_vars * preds.size(0))\n",
        "        else:\n",
        "            return kl_div.view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def kl_categorical_avg(self, preds, eps=1e-16):\n",
        "        avg_preds = preds.mean(dim=2)\n",
        "        kl_div = avg_preds*(torch.log(avg_preds+eps) - self.log_prior)\n",
        "        if self.normalize_kl:     \n",
        "            return kl_div.sum(-1).view(preds.size(0), -1).mean(dim=1)\n",
        "        elif self.normalize_kl_per_var:\n",
        "            return kl_div.sum() / (self.num_vars * preds.size(0))\n",
        "        else:\n",
        "            return kl_div.view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "\n",
        "    def save(self, path):\n",
        "        #torch.save(self.state_dict(), path)\n",
        "        pass\n",
        "    def load(self, path):\n",
        "        self.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "7sDVnc-yiQss"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model"
      ],
      "metadata": {
        "id": "WPyOiuyfiVLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(params):        \n",
        "  model = DNRI(params)\n",
        "  print(\"dNRI MODEL: \",model)\n",
        "\n",
        "  #model.cuda()\n",
        "  return model"
      ],
      "metadata": {
        "id": "YYDNnt9AiXmv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(params)"
      ],
      "metadata": {
        "id": "DYzkGBEGia0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a886514a-999d-42e5-ac5c-6cbbcc09da8d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using learned recurrent interaction net decoder.\n",
            "dNRI MODEL:  DNRI(\n",
            "  (encoder): DNRI_Encoder(\n",
            "    (mlp1): RefNRIMLP(\n",
            "      (model): Sequential(\n",
            "        (0): Linear(in_features=100, out_features=256, bias=True)\n",
            "        (1): ELU(alpha=1.0, inplace=True)\n",
            "        (2): Dropout(p=0.5, inplace=False)\n",
            "        (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "        (4): ELU(alpha=1.0, inplace=True)\n",
            "      )\n",
            "      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mlp2): RefNRIMLP(\n",
            "      (model): Sequential(\n",
            "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
            "        (1): ELU(alpha=1.0, inplace=True)\n",
            "        (2): Dropout(p=0.5, inplace=False)\n",
            "        (3): Linear(in_features=64, out_features=32, bias=True)\n",
            "        (4): ELU(alpha=1.0, inplace=True)\n",
            "      )\n",
            "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mlp3): RefNRIMLP(\n",
            "      (model): Sequential(\n",
            "        (0): Linear(in_features=32, out_features=16, bias=True)\n",
            "        (1): ELU(alpha=1.0, inplace=True)\n",
            "        (2): Dropout(p=0.5, inplace=False)\n",
            "        (3): Linear(in_features=16, out_features=8, bias=True)\n",
            "        (4): ELU(alpha=1.0, inplace=True)\n",
            "      )\n",
            "      (bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mlp4): RefNRIMLP(\n",
            "      (model): Sequential(\n",
            "        (0): Linear(in_features=8, out_features=4, bias=True)\n",
            "        (1): ELU(alpha=1.0, inplace=True)\n",
            "        (2): Dropout(p=0.5, inplace=False)\n",
            "        (3): Linear(in_features=4, out_features=4, bias=True)\n",
            "        (4): ELU(alpha=1.0, inplace=True)\n",
            "      )\n",
            "      (bn): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (forward_rnn): LSTM(4, 16, batch_first=True)\n",
            "    (reverse_rnn): LSTM(4, 16, batch_first=True)\n",
            "    (encoder_fc_out): Sequential(\n",
            "      (0): Linear(in_features=32, out_features=2, bias=True)\n",
            "      (1): ELU(alpha=1.0, inplace=True)\n",
            "      (2): Linear(in_features=2, out_features=1, bias=True)\n",
            "    )\n",
            "    (prior_fc_out): Sequential(\n",
            "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
            "      (1): ELU(alpha=1.0, inplace=True)\n",
            "      (2): Linear(in_features=16, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (decoder): DNRI_Decoder(\n",
            "    (msg_fc1): ModuleList(\n",
            "      (0): Linear(in_features=32, out_features=16, bias=True)\n",
            "    )\n",
            "    (msg_fc2): ModuleList(\n",
            "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
            "    )\n",
            "    (out_fc1): Linear(in_features=16, out_features=16, bias=True)\n",
            "    (out_fc2): Linear(in_features=16, out_features=16, bias=True)\n",
            "    (out_fc3): Linear(in_features=16, out_features=100, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "FjnGUJxWiaQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, params, train_writer, val_writer):\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    val_batch_size = params.get('val_batch_size', batch_size)\n",
        "    if val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "    accumulate_steps = params.get('accumulate_steps')\n",
        "    training_scheduler = params.get('training_scheduler', None)\n",
        "    num_epochs = params.get('num_epochs', 2)\n",
        "    val_interval = params.get('val_interval', 1)\n",
        "    val_start = params.get('val_start', 0)\n",
        "    clip_grad = params.get('clip_grad', None)\n",
        "    clip_grad_norm = params.get('clip_grad_norm', None)\n",
        "    normalize_nll = params.get('normalize_nll', False)\n",
        "    normalize_kl = params.get('normalize_kl', False)\n",
        "    tune_on_nll = params.get('tune_on_nll', False)\n",
        "    verbose = params.get('verbose', False)\n",
        "    val_teacher_forcing = params.get('val_teacher_forcing', False)\n",
        "    continue_training = params.get('continue_training', False)\n",
        "    train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    val_data_loader = DataLoader(val_data, batch_size=val_batch_size)\n",
        "    lr = params['lr']\n",
        "    wd = params.get('wd', 0.)\n",
        "    mom = params.get('mom', 0.)\n",
        "    \n",
        "    model_params = [param for param in model.parameters() if param.requires_grad]\n",
        "    if params.get('use_adam', False):\n",
        "        opt = torch.optim.Adam(model_params, lr=lr, weight_decay=wd)\n",
        "    else:\n",
        "        opt = torch.optim.SGD(model_params, lr=lr, weight_decay=wd, momentum=mom)\n",
        "\n",
        "    working_dir = params['working_dir']\n",
        "    best_path = os.path.join(working_dir, 'best_model')\n",
        "    checkpoint_dir = os.path.join(working_dir, '')\n",
        "    training_path = os.path.join(working_dir, '')\n",
        "    if continue_training:\n",
        "        print(\"RESUMING TRAINING\")\n",
        "        model.load(checkpoint_dir)\n",
        "        train_params = torch.load(training_path)\n",
        "        start_epoch = train_params['epoch']\n",
        "        opt.load_state_dict(train_params['optimizer'])\n",
        "        best_val_result = train_params['best_val_result']\n",
        "        best_val_epoch = train_params['best_val_epoch']\n",
        "        print(\"STARTING EPOCH: \",start_epoch)\n",
        "    else:\n",
        "        start_epoch = 1\n",
        "        best_val_epoch = -1\n",
        "        best_val_result = 10000000\n",
        "    \n",
        "    training_scheduler = build_scheduler(opt, params)\n",
        "    end = start = 0 \n",
        "    seed(1)\n",
        "    for epoch in range(start_epoch, num_epochs+1):\n",
        "        print(\"EPOCH\", epoch, (end-start))\n",
        "        model.train()\n",
        "        model.train_percent = epoch / num_epochs\n",
        "        start = time.time() \n",
        "        for batch_ind, batch in enumerate(train_data_loader):\n",
        "            inputs = batch.to(device)\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "            loss, loss_nll, loss_kl, logits, _ = model.calculate_loss(inputs, is_train=True, return_logits=True)\n",
        "            loss.backward()\n",
        "            if verbose:\n",
        "                print(\"\\tBATCH %d OF %d: %f, %f, %f\"%(batch_ind+1, len(train_data_loader), loss.item(), loss_nll.mean().item(), loss_kl.mean().item()))\n",
        "            if accumulate_steps == -1 or (batch_ind+1)%accumulate_steps == 0:\n",
        "                if verbose and accumulate_steps > 0:\n",
        "                    print(\"\\tUPDATING WEIGHTS\")\n",
        "                if clip_grad is not None:\n",
        "                    nn.utils.clip_grad_value_(model.parameters(), clip_grad)\n",
        "                elif clip_grad_norm is not None:\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)        \n",
        "                opt.step()\n",
        "                opt.zero_grad()\n",
        "                if accumulate_steps > 0 and accumulate_steps > len(train_data_loader) - batch_ind - 1:\n",
        "                    break\n",
        "            \n",
        "        if training_scheduler is not None:\n",
        "            training_scheduler.step()\n",
        "        \n",
        "        if train_writer is not None:\n",
        "            train_writer.add_scalar('loss', loss.item(), global_step=epoch)\n",
        "            if normalize_nll:\n",
        "                train_writer.add_scalar('NLL', loss_nll.mean().item(), global_step=epoch)\n",
        "            else:\n",
        "                train_writer.add_scalar('NLL', loss_nll.mean().item()/(inputs.size(1)*inputs.size(2)), global_step=epoch)\n",
        "            \n",
        "            train_writer.add_scalar(\"KL Divergence\", loss_kl.mean().item(), global_step=epoch)\n",
        "        model.eval()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        total_nll = 0\n",
        "        total_kl = 0\n",
        "        if verbose:\n",
        "            print(\"COMPUTING VAL LOSSES\")\n",
        "        with torch.no_grad():\n",
        "            for batch_ind, batch in enumerate(val_data_loader):\n",
        "                inputs = batch\n",
        "                if gpu:\n",
        "                    inputs = inputs.cuda(non_blocking=True)\n",
        "                loss, loss_nll, loss_kl, logits, _ = model.calculate_loss(inputs, is_train=False, teacher_forcing=val_teacher_forcing, return_logits=True)\n",
        "                total_kl += loss_kl.sum().item()\n",
        "                total_nll += loss_nll.sum().item()\n",
        "                if verbose:\n",
        "                    print(\"\\tVAL BATCH %d of %d: %f, %f\"%(batch_ind+1, len(val_data_loader), loss_nll.mean(), loss_kl.mean()))\n",
        "            \n",
        "        total_kl /= len(val_data)\n",
        "        total_nll /= len(val_data)\n",
        "        total_loss = model.kl_coef*total_kl + total_nll #TODO: this is a thing you fixed\n",
        "        if val_writer is not None:\n",
        "            val_writer.add_scalar('loss', total_loss, global_step=epoch)\n",
        "            val_writer.add_scalar(\"NLL\", total_nll, global_step=epoch)\n",
        "            val_writer.add_scalar(\"KL Divergence\", total_kl, global_step=epoch)\n",
        "        if tune_on_nll:\n",
        "            tuning_loss = total_nll\n",
        "        else:\n",
        "            tuning_loss = total_loss\n",
        "        if tuning_loss < best_val_result:\n",
        "            best_val_epoch = epoch\n",
        "            best_val_result = tuning_loss\n",
        "            print(\"BEST VAL RESULT. SAVING MODEL...\")\n",
        "            model.save(best_path)\n",
        "        model.save(checkpoint_dir)\n",
        "        '''\n",
        "        torch.save({\n",
        "                    'epoch':epoch+1,\n",
        "                    'optimizer':opt.state_dict(),\n",
        "                    'best_val_result':best_val_result,\n",
        "                    'best_val_epoch':best_val_epoch,\n",
        "                   }, training_path)\n",
        "        '''\n",
        "        print(\"EPOCH %d EVAL: \"%epoch)\n",
        "        print(\"\\tCURRENT VAL LOSS: %f\"%tuning_loss)\n",
        "        print(\"\\tBEST VAL LOSS:    %f\"%best_val_result)\n",
        "        print(\"\\tBEST VAL EPOCH:   %d\"%best_val_epoch)\n",
        "        end = time.time()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "gFAiV2h8iiBK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = np.array([np.array(i) for i in dataframe[:100].R])\n",
        "test_dataset = np.array([np.array(i) for i in dataframe[100:150].R])"
      ],
      "metadata": {
        "id": "u7atlPZom9CC"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ((train_dataset - train_dataset.min()) / (train_dataset.max() - train_dataset.min())).reshape(100,100)"
      ],
      "metadata": {
        "id": "_FggcT_4Et2C"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = (test_dataset - train_dataset.min() / (train_dataset.max() - train_dataset.min())).reshape(50,100)"
      ],
      "metadata": {
        "id": "eWLgYz5QF9mM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset = np.split(dataset,2)[0].astype(np.float32)\n",
        "#test_dataset = np.split(dataset,2)[1].astype(np.float32)"
      ],
      "metadata": {
        "id": "DybfUrKvi3vr"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.shape"
      ],
      "metadata": {
        "id": "bPjJ79CgoU-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62a548c-218f-410c-e201-7b2f993b474b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = train(model,train_dataset,test_dataset, params, None, None)"
      ],
      "metadata": {
        "id": "hmt2pLjOmop7",
        "outputId": "ce47e30e-0127-45db-fb5b-974fca301cd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1 0\n",
            "EPOCH 1 EVAL: \n",
            "\tCURRENT VAL LOSS: 2320879001.602958\n",
            "\tBEST VAL LOSS:    10000000.000000\n",
            "\tBEST VAL EPOCH:   -1\n",
            "EPOCH 2 0.5956423282623291\n",
            "EPOCH 2 EVAL: \n",
            "\tCURRENT VAL LOSS: 2320975462.402557\n",
            "\tBEST VAL LOSS:    10000000.000000\n",
            "\tBEST VAL EPOCH:   -1\n",
            "EPOCH 3 0.3588981628417969\n",
            "EPOCH 3 EVAL: \n",
            "\tCURRENT VAL LOSS: 2321100390.400418\n",
            "\tBEST VAL LOSS:    10000000.000000\n",
            "\tBEST VAL EPOCH:   -1\n",
            "EPOCH 4 0.3518331050872803\n",
            "EPOCH 4 EVAL: \n",
            "\tCURRENT VAL LOSS: 2321102192.640502\n",
            "\tBEST VAL LOSS:    10000000.000000\n",
            "\tBEST VAL EPOCH:   -1\n",
            "EPOCH 5 0.3522074222564697\n",
            "EPOCH 5 EVAL: \n",
            "\tCURRENT VAL LOSS: 2321090437.120443\n",
            "\tBEST VAL LOSS:    10000000.000000\n",
            "\tBEST VAL EPOCH:   -1\n",
            "EPOCH 6 0.35758495330810547\n",
            "EPOCH 6 EVAL: \n",
            "\tCURRENT VAL LOSS: 2321112965.120431\n",
            "\tBEST VAL LOSS:    10000000.000000\n",
            "\tBEST VAL EPOCH:   -1\n",
            "EPOCH 7 0.3414735794067383\n",
            "EPOCH 7 EVAL: \n",
            "\tCURRENT VAL LOSS: 2321133281.280542\n",
            "\tBEST VAL LOSS:    10000000.000000\n",
            "\tBEST VAL EPOCH:   -1\n",
            "EPOCH 8 0.3439445495605469\n",
            "EPOCH 8 EVAL: \n",
            "\tCURRENT VAL LOSS: 2321139056.641934\n",
            "\tBEST VAL LOSS:    10000000.000000\n",
            "\tBEST VAL EPOCH:   -1\n",
            "EPOCH 9 0.33859848976135254\n",
            "EPOCH 9 EVAL: \n",
            "\tCURRENT VAL LOSS: 2321139056.643047\n",
            "\tBEST VAL LOSS:    10000000.000000\n",
            "\tBEST VAL EPOCH:   -1\n",
            "EPOCH 10 0.3703634738922119\n",
            "EPOCH 10 EVAL: \n",
            "\tCURRENT VAL LOSS: 2321139056.640490\n",
            "\tBEST VAL LOSS:    10000000.000000\n",
            "\tBEST VAL EPOCH:   -1\n"
          ]
        }
      ]
    }
  ]
}