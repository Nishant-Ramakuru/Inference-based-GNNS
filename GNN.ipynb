{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNN.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/Nishant-Ramakuru/Inference-based-GNNS/blob/main/GNN.ipynb",
      "authorship_tag": "ABX9TyOWoc62Q/rMdFuPgO+3937B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nishant-Ramakuru/Inference-based-GNNS/blob/main/GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sho3YQ82-xwt"
      },
      "outputs": [],
      "source": [
        "import time \n",
        "import numpy\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "#from future import division\n",
        "#from future import print_function\n",
        "import time\n",
        "import argparse\n",
        "import pickle\n",
        "import os\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "#from utils import\n",
        "#from models_utils import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import time, os\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import time, os\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "!pip install patool\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"/content/drive/MyDrive/boids_buffer.rar\", outdir=\"/content/drive/MyDrive\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "eyPvTxTIouBF",
        "outputId": "c52a0959-92d8-403e-a565-9817925e1521"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!pip install patool\\nimport patoolib\\npatoolib.extract_archive(\"/content/drive/MyDrive/boids_buffer.rar\", outdir=\"/content/drive/MyDrive\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_pickle('/content/drive/MyDrive/GNNs/boids_buffer.csv')"
      ],
      "metadata": {
        "id": "pb51ZO2Sw3vu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.index.rename('Time_Step',inplace = True)"
      ],
      "metadata": {
        "id": "U4DeDtkxqC6u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Time steps:\", dataframe.shape[0])\n",
        "print(\"Number of Agents:\", len(dataframe.R[0]))\n"
      ],
      "metadata": {
        "id": "xR1jUFS6xFvk",
        "outputId": "4682fc64-8ae4-4a0b-e439-2771798644b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time steps: 800\n",
            "Number of Agents: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.head(1)"
      ],
      "metadata": {
        "id": "xDnJ8Ss5xlAq",
        "outputId": "fafe3fed-29cd-4c2d-b322-0ae875b10cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                           R  \\\n",
              "Time_Step                                                      \n",
              "0          [[539.74475, 245.03323], [543.6497, 141.5064],...   \n",
              "\n",
              "                                                       theta  \n",
              "Time_Step                                                     \n",
              "0          [1.4382355, 1.8777844, 1.0181143, 2.6681843, 0...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c877aad0-f25b-46eb-aae2-0acc3e86f983\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R</th>\n",
              "      <th>theta</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time_Step</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[539.74475, 245.03323], [543.6497, 141.5064],...</td>\n",
              "      <td>[1.4382355, 1.8777844, 1.0181143, 2.6681843, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c877aad0-f25b-46eb-aae2-0acc3e86f983')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c877aad0-f25b-46eb-aae2-0acc3e86f983 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c877aad0-f25b-46eb-aae2-0acc3e86f983');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traj_1 = []\n",
        "traj_2 = []\n",
        "for i in range(len(dataframe)):\n",
        "  traj_1.append(dataframe.R[i][0])\n",
        "  traj_2.append(dataframe.R[i][1])\n",
        "x,y = zip(*traj_1)  \n",
        "p,q = zip(*traj_2)\n",
        "plt.scatter(x,y)\n",
        "plt.scatter(p,q)"
      ],
      "metadata": {
        "id": "6n5i67VEkMxz",
        "outputId": "f46ead84-f624-4e7f-b98c-c44ee1b52341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fef90f9c990>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functions**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "AW48_5_1hIIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_scheduler(opt, params):\n",
        "    lr_decay_factor = params.get('lr_decay_factor')\n",
        "    lr_decay_steps = params.get('lr_decay_steps')\n",
        "    if lr_decay_factor:\n",
        "        return torch.optim.lr_scheduler.StepLR(opt, lr_decay_steps, lr_decay_factor)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "class build_writers:\n",
        "    def __init__(self, working_dir, is_test=False):\n",
        "        self.writer_dir = os.path.join(working_dir, 'logs/')\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __enter__(self):\n",
        "        train_writer_dir = os.path.join(self.writer_dir, 'train')\n",
        "        val_writer_dir = os.path.join(self.writer_dir, 'val')\n",
        "        self.train_writer = SummaryWriter(train_writer_dir)\n",
        "        self.val_writer = SummaryWriter(val_writer_dir)\n",
        "        if self.is_test:\n",
        "            test_writer_dir = os.path.join(self.writer_dir, 'test')\n",
        "            self.test_writer = SummaryWriter(test_writer_dir)\n",
        "            return self.train_writer, self.val_writer, self.test_writer\n",
        "        else:\n",
        "            return self.train_writer, self.val_writer\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        self.train_writer.close()\n",
        "        self.val_writer.close()\n",
        "        if self.is_test:\n",
        "            self.test_writer.close()"
      ],
      "metadata": {
        "id": "HFpOptCThGhr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed(seed_val):\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    random.seed(seed_val)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "vFsuAoAQhS1G"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "\n",
        "\n",
        "class RefNRIMLP(nn.Module):\n",
        "    \"\"\"Two-layer fully-connected ELU net with batch norm.\"\"\"\n",
        "\n",
        "    def __init__(self, n_in, n_hid, n_out, do_prob=0., no_bn=False):\n",
        "        super(RefNRIMLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(n_in, n_hid),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, n_out),\n",
        "            nn.ELU(inplace=True)\n",
        "        )\n",
        "        if no_bn:\n",
        "            self.bn = None\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm1d(n_out)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def batch_norm(self, inputs):\n",
        "        orig_shape = inputs.shape\n",
        "        x = inputs.view(-1, inputs.size(-1))\n",
        "        x = self.bn(x)\n",
        "        return x.view(orig_shape)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Input shape: [num_sims, num_things, num_features]\n",
        "        x = self.model(inputs)\n",
        "        if self.bn is not None:\n",
        "            return self.batch_norm(x)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "\n",
        "def sample_gumbel(shape, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Sample from Gumbel(0, 1)\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    U = torch.rand(shape).float()\n",
        "    return - torch.log(eps - torch.log(U + eps))\n",
        "\n",
        "\n",
        "def gumbel_softmax_sample(logits, tau=1, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Draw a sample from the Gumbel-Softmax distribution\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    gumbel_noise = sample_gumbel(logits.size(), eps=eps)\n",
        "    if logits.is_cuda:\n",
        "        gumbel_noise = gumbel_noise.cuda()\n",
        "    y = logits + gumbel_noise\n",
        "    return F.softmax(y / tau, dim=-1)\n",
        "\n",
        "\n",
        "def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
        "    Args:\n",
        "      logits: [batch_size, n_class] unnormalized log-probs\n",
        "      tau: non-negative scalar temperature\n",
        "      hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
        "    Returns:\n",
        "      [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
        "      If hard=True, then the returned sample will be one-hot, otherwise it will\n",
        "      be a probability distribution that sums to 1 across classes\n",
        "    Constraints:\n",
        "    - this implementation only works on batch_size x num_features tensor for now\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    y_soft = gumbel_softmax_sample(logits, tau=tau, eps=eps)\n",
        "    if hard:\n",
        "        shape = logits.size()\n",
        "        _, k = y_soft.data.max(-1)\n",
        "        # this bit is based on\n",
        "        # https://discuss.pytorch.org/t/stop-gradients-for-st-gumbel-softmax/530/5\n",
        "        y_hard = torch.zeros(*shape)\n",
        "        if y_soft.is_cuda:\n",
        "            y_hard = y_hard.cuda()\n",
        "        y_hard = y_hard.zero_().scatter_(-1, k.view(shape[:-1] + (1,)), 1.0)\n",
        "        # this cool bit of code achieves two things:\n",
        "        # - makes the output value exactly one-hot (since we add then\n",
        "        #   subtract y_soft value)\n",
        "        # - makes the gradient equal to y_soft gradient (since we strip\n",
        "        #   all other gradients)\n",
        "        y = y_hard - y_soft.data + y_soft\n",
        "    else:\n",
        "        y = y_soft\n",
        "    return y\n",
        "\n",
        "\n",
        "def get_graph_info(masks, num_vars, use_edge2node=True):\n",
        "    if num_vars == 1:\n",
        "        return None, None, None\n",
        "    edges = torch.ones(num_vars, device=masks.device) - torch.eye(num_vars, device=masks.device)\n",
        "    tmp = torch.where(edges)\n",
        "    send_edges = tmp[0]\n",
        "    recv_edges = tmp[1]\n",
        "    tmp_inds = torch.tensor(list(range(num_vars)), device=masks.device, dtype=torch.long).unsqueeze_(1)\n",
        "    if use_edge2node:\n",
        "        edge2node_inds = (tmp_inds == recv_edges.unsqueeze(0)).nonzero()[:, 1].contiguous().view(-1, num_vars-1)\n",
        "        return send_edges, recv_edges, edge2node_inds\n",
        "    else:\n",
        "        return send_edges, recv_edges"
      ],
      "metadata": {
        "id": "WwFdE2-QlTs0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Definitions**\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wtvRAkXlhVDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters"
      ],
      "metadata": {
        "id": "SP9G-3oMjCIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {}\n",
        "params['num_vars'] = params['num_agents'] = 5\n",
        "params['input_noise_type'] = 'none'\n",
        "params['input_size'] = 4\n",
        "params['input_time_steps'] = 40\n",
        "params['nll_loss_type'] = 'gaussian'\n",
        "params['prior_variance'] = 5e-5\n",
        "params['batch_size'] = 10\n",
        "params['val_batch_size'] = 10\n",
        "params['accumulate_steps'] = 0\n",
        "params['num_edge_types'] = 2\n",
        "params['encoder_dropout'] = 0.5\n",
        "params['encoder_hidden'] = 10\n",
        "params['encoder_rnn_hidden'] = 10\n",
        "params['encoder_rnn_type'] = 'lstm'\n",
        "params['encoder_mlp_num_layers'] = 10\n",
        "params['encoder_mlp_hidden'] = 10\n",
        "params['prior_num_layers'] = 10\n",
        "params['prior_hidden_size'] = 10\n",
        "params['gpu'] = True\n",
        "params['decoder_hidden'] = 10\n",
        "params['skip_first'] = False\n",
        "params['decoder_dropout'] = 0.5\n",
        "params['decoder_type'] = None\n",
        "params['lr'] = 5e-4\n",
        "params['working_dir'] = ('/content/MyDrive/GNNs')"
      ],
      "metadata": {
        "id": "OOtlj23sjEG5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder"
      ],
      "metadata": {
        "id": "JQRlVaAAha3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNRI_Encoder(nn.Module):\n",
        "    # Here, encoder also produces prior\n",
        "    def __init__(self, params):\n",
        "        super(DNRI_Encoder, self).__init__()\n",
        "        num_vars = params['num_vars']\n",
        "        self.num_edges = params['num_edge_types']\n",
        "        self.sepaate_prior_encoder = params.get('separate_prior_encoder', False)\n",
        "        no_bn = False\n",
        "        dropout = params['encoder_dropout']\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = nn.Parameter(torch.FloatTensor(encode_onehot(self.recv_edges).transpose()), requires_grad=False)\n",
        "        self.save_eval_memory = params.get('encoder_save_eval_memory', False)\n",
        "\n",
        "\n",
        "        hidden_size = params['encoder_hidden']\n",
        "        rnn_hidden_size = params['encoder_rnn_hidden']\n",
        "        rnn_type = params['encoder_rnn_type']\n",
        "        inp_size = params['input_size']\n",
        "        self.mlp1 = RefNRIMLP(inp_size, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.mlp2 = RefNRIMLP(hidden_size * 2, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.mlp3 = RefNRIMLP(hidden_size, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.mlp4 = RefNRIMLP(hidden_size * 3, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "\n",
        "        if rnn_hidden_size is None:\n",
        "            rnn_hidden_size = hidden_size\n",
        "        if rnn_type == 'lstm':\n",
        "            self.forward_rnn = nn.LSTM(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "            self.reverse_rnn = nn.LSTM(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "        elif rnn_type == 'gru':\n",
        "            self.forward_rnn = nn.GRU(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "            self.reverse_rnn = nn.GRU(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "        out_hidden_size = 2*rnn_hidden_size\n",
        "        num_layers = params['encoder_mlp_num_layers']\n",
        "        if num_layers == 1:\n",
        "            self.encoder_fc_out = nn.Linear(out_hidden_size, self.num_edges)\n",
        "        else:\n",
        "            tmp_hidden_size = params['encoder_mlp_hidden']\n",
        "            layers = [nn.Linear(out_hidden_size, tmp_hidden_size), nn.ELU(inplace=True)]\n",
        "            for _ in range(num_layers - 2):\n",
        "                layers.append(nn.Linear(tmp_hidden_size, tmp_hidden_size))\n",
        "                layers.append(nn.ELU(inplace=True))\n",
        "            layers.append(nn.Linear(tmp_hidden_size, self.num_edges))\n",
        "            self.encoder_fc_out = nn.Sequential(*layers)\n",
        "\n",
        "        num_layers = params['prior_num_layers']\n",
        "        if num_layers == 1:\n",
        "            self.prior_fc_out = nn.Linear(rnn_hidden_size, self.num_edges)\n",
        "        else:\n",
        "            tmp_hidden_size = params['prior_hidden_size']\n",
        "            layers = [nn.Linear(rnn_hidden_size, tmp_hidden_size), nn.ELU(inplace=True)]\n",
        "            for _ in range(num_layers - 2):\n",
        "                layers.append(nn.Linear(tmp_hidden_size, tmp_hidden_size))\n",
        "                layers.append(nn.ELU(inplace=True))\n",
        "            layers.append(nn.Linear(tmp_hidden_size, self.num_edges))\n",
        "            self.prior_fc_out = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "\n",
        "    def node2edge(self, node_embeddings):\n",
        "        # Input size: [batch, num_vars, num_timesteps, embed_size]\n",
        "        if len(node_embeddings.shape) == 4:\n",
        "            send_embed = node_embeddings[:, self.send_edges, :, :]\n",
        "            recv_embed = node_embeddings[:, self.recv_edges, :, :]\n",
        "        else:\n",
        "            send_embed = node_embeddings[:, self.send_edges, :]\n",
        "            recv_embed = node_embeddings[:, self.recv_edges, :]\n",
        "        return torch.cat([send_embed, recv_embed], dim=-1)\n",
        "\n",
        "    def edge2node(self, edge_embeddings):\n",
        "        if len(edge_embeddings.shape) == 4:\n",
        "            old_shape = edge_embeddings.shape\n",
        "            tmp_embeddings = edge_embeddings.view(old_shape[0], old_shape[1], -1)\n",
        "            incoming = torch.matmul(self.edge2node_mat, tmp_embeddings).view(old_shape[0], -1, old_shape[2], old_shape[3])\n",
        "        else:\n",
        "            incoming = torch.matmul(self.edge2node_mat, edge_embeddings)\n",
        "        return incoming/(self.num_vars-1) #TODO: do we want this average?\n",
        "\n",
        "\n",
        "    def copy_states(self, prior_state):\n",
        "        if isinstance(prior_state, tuple) or isinstance(prior_state, list):\n",
        "            current_prior_state = (prior_state[0].clone(), prior_state[1].clone())\n",
        "        else:\n",
        "            current_prior_state = prior_state.clone()\n",
        "        return current_prior_state\n",
        "\n",
        "    def merge_hidden(self, hidden):\n",
        "        if isinstance(hidden[0], tuple) or isinstance(hidden[0], list):\n",
        "            result0 = torch.cat([x[0] for x in hidden], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in hidden], dim=0)\n",
        "            result = (result0, result1)\n",
        "        else:\n",
        "            result = torch.cat(hidden, dim=0)\n",
        "        return result\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if self.training or not self.save_eval_memory:\n",
        "            # Inputs is shape [batch, num_timesteps, num_vars, input_size]\n",
        "            num_timesteps = inputs.size(1)\n",
        "            x = inputs.transpose(2, 1).contiguous()\n",
        "            # New shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
        "            x = self.mlp1(x)  # 2-layer ELU net per node\n",
        "            x = self.node2edge(x)\n",
        "            x = self.mlp2(x)\n",
        "            x_skip = x\n",
        "            x = self.edge2node(x)\n",
        "            x = self.mlp3(x)\n",
        "            x = self.node2edge(x)\n",
        "            x = torch.cat((x, x_skip), dim=-1)  # Skip connection\n",
        "            x = self.mlp4(x)\n",
        "        \n",
        "            \n",
        "            # At this point, x should be [batch, num_edges, num_timesteps, hidden_size]\n",
        "            # RNN aggregation\n",
        "            old_shape = x.shape\n",
        "            x = x.contiguous().view(-1, old_shape[2], old_shape[3])\n",
        "            forward_x, prior_state = self.forward_rnn(x)\n",
        "            timesteps = old_shape[2]\n",
        "            reverse_x = x.flip(1)\n",
        "            reverse_x, _ = self.reverse_rnn(reverse_x)\n",
        "            reverse_x = reverse_x.flip(1)\n",
        "            \n",
        "            #x: [batch*num_edges, num_timesteps, hidden_size]\n",
        "            prior_result = self.prior_fc_out(forward_x).view(old_shape[0], old_shape[1], timesteps, self.num_edges).transpose(1,2).contiguous()\n",
        "            combined_x = torch.cat([forward_x, reverse_x], dim=-1)\n",
        "            encoder_result = self.encoder_fc_out(combined_x).view(old_shape[0], old_shape[1], timesteps, self.num_edges).transpose(1,2).contiguous()\n",
        "            return prior_result, encoder_result, prior_state\n",
        "        else:\n",
        "            # Inputs is shape [batch, num_timesteps, num_vars, input_size]\n",
        "            num_timesteps = inputs.size(1)\n",
        "            all_x = []\n",
        "            all_forward_x = []\n",
        "            all_prior_result = []\n",
        "            prior_state = None\n",
        "            for timestep in range(num_timesteps):\n",
        "                x = inputs[:, timestep]\n",
        "                #x = inputs.transpose(2, 1).contiguous()\n",
        "                x = self.mlp1(x)  # 2-layer ELU net per node\n",
        "                x = self.node2edge(x)\n",
        "                x = self.mlp2(x)\n",
        "                x_skip = x\n",
        "                x = self.edge2node(x)\n",
        "                x = self.mlp3(x)\n",
        "                x = self.node2edge(x)\n",
        "                x = torch.cat((x, x_skip), dim=-1)  # Skip connection\n",
        "                x = self.mlp4(x)\n",
        "            \n",
        "                \n",
        "                # At this point, x should be [batch, num_edges, num_timesteps, hidden_size]\n",
        "                # RNN aggregation\n",
        "                old_shape = x.shape\n",
        "                x = x.contiguous().view(-1, 1, old_shape[-1])\n",
        "                forward_x, prior_state = self.forward_rnn(x, prior_state)\n",
        "                all_x.append(x.cpu())\n",
        "                all_forward_x.append(forward_x.cpu())\n",
        "                all_prior_result.append(self.prior_fc_out(forward_x).view(old_shape[0], 1, old_shape[1], self.num_edges).cpu())\n",
        "            reverse_state = None\n",
        "            all_encoder_result = []\n",
        "            for timestep in range(num_timesteps-1, -1, -1):\n",
        "                x = all_x[timestep].cuda()\n",
        "                reverse_x, reverse_state = self.reverse_rnn(x, reverse_state)\n",
        "                forward_x = all_forward_x[timestep].cuda()\n",
        "                \n",
        "                #x: [batch*num_edges, num_timesteps, hidden_size]\n",
        "                combined_x = torch.cat([forward_x, reverse_x], dim=-1)\n",
        "                all_encoder_result.append(self.encoder_fc_out(combined_x).view(inputs.size(0), 1, -1, self.num_edges))\n",
        "            prior_result = torch.cat(all_prior_result, dim=1).cuda(non_blocking=True)\n",
        "            encoder_result = torch.cat(all_encoder_result, dim=1).cuda(non_blocking=True)\n",
        "            return prior_result, encoder_result, prior_state\n",
        "\n",
        "    def single_step_forward(self, inputs, prior_state):\n",
        "        # Inputs is shape [batch, num_vars, input_size]\n",
        "        x = self.mlp1(inputs)  # 2-layer ELU net per node\n",
        "        x = self.node2edge(x)\n",
        "        x = self.mlp2(x)\n",
        "        x_skip = x\n",
        "        x = self.edge2node(x)\n",
        "        x = self.mlp3(x)\n",
        "        x = self.node2edge(x)\n",
        "        x = torch.cat((x, x_skip), dim=-1)  # Skip connection\n",
        "        x = self.mlp4(x)\n",
        "\n",
        "        old_shape = x.shape\n",
        "        x  = x.contiguous().view(-1, 1, old_shape[-1])\n",
        "        old_prior_shape = prior_state[0].shape\n",
        "        prior_state = (prior_state[0].view(1, old_prior_shape[0]*old_prior_shape[1], old_prior_shape[2]),\n",
        "                       prior_state[1].view(1, old_prior_shape[0]*old_prior_shape[1], old_prior_shape[2]))\n",
        "\n",
        "        x, prior_state = self.forward_rnn(x, prior_state)\n",
        "        prior_result = self.prior_fc_out(x).view(old_shape[0], old_shape[1], self.num_edges)\n",
        "        prior_state = (prior_state[0].view(old_prior_shape), prior_state[1].view(old_prior_shape))\n",
        "        return prior_result, prior_state"
      ],
      "metadata": {
        "id": "2_bOioDJhY6K"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = DNRI_Encoder(params)"
      ],
      "metadata": {
        "id": "Eud6aKEfh5Gk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder"
      ],
      "metadata": {
        "id": "CPCejo-niE0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNRI_Decoder(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(DNRI_Decoder, self).__init__()\n",
        "        self.num_vars = num_vars =  params['num_vars']\n",
        "        input_size = params['input_size']\n",
        "        self.gpu = params['gpu']\n",
        "        n_hid = params['decoder_hidden']\n",
        "        edge_types = params['num_edge_types']\n",
        "        skip_first = params['skip_first']\n",
        "        out_size = params['input_size']\n",
        "        do_prob = params['decoder_dropout']\n",
        "\n",
        "        self.msg_fc1 = nn.ModuleList(\n",
        "            [nn.Linear(2*n_hid, n_hid) for _ in range(edge_types)]\n",
        "        )\n",
        "        self.msg_fc2 = nn.ModuleList(\n",
        "            [nn.Linear(n_hid, n_hid) for _ in range(edge_types)]\n",
        "        )\n",
        "        self.msg_out_shape = n_hid\n",
        "        self.skip_first_edge_type = skip_first\n",
        "\n",
        "        self.hidden_r = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_i = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_h = nn.Linear(n_hid, n_hid, bias=False)\n",
        "\n",
        "        self.input_r = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_i = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_n = nn.Linear(input_size, n_hid, bias=True)\n",
        "\n",
        "        self.out_fc1 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc3 = nn.Linear(n_hid, out_size)\n",
        "\n",
        "        print('Using learned recurrent interaction net decoder.')\n",
        "\n",
        "        self.dropout_prob = do_prob\n",
        "\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = nn.Parameter(torch.FloatTensor(encode_onehot(self.recv_edges)), requires_grad=False)\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return torch.zeros(inputs.size(0), inputs.size(2), self.msg_out_shape, device=inputs.device)\n",
        "        \n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "\n",
        "    def forward(self, inputs, hidden, edges):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        # Edges size: [batch, num_edges, num_edge_types]\n",
        "        if self.training:\n",
        "            dropout_prob = self.dropout_prob\n",
        "        else:\n",
        "            dropout_prob = 0.\n",
        "        \n",
        "        # node2edge\n",
        "        receivers = hidden[:, self.recv_edges, :]\n",
        "        senders = hidden[:, self.send_edges, :]\n",
        "\n",
        "        # pre_msg: [batch, num_edges, 2*msg_out]\n",
        "        pre_msg = torch.cat([receivers, senders], dim=-1)\n",
        "\n",
        "        all_msgs = torch.zeros(pre_msg.size(0), pre_msg.size(1),\n",
        "                                        self.msg_out_shape, device=inputs.device)\n",
        "        \n",
        "        if self.skip_first_edge_type:\n",
        "            start_idx = 1\n",
        "            norm = float(len(self.msg_fc2)) - 1\n",
        "        else:\n",
        "            start_idx = 0\n",
        "            norm = float(len(self.msg_fc2))\n",
        "\n",
        "        # Run separate MLP for every edge type\n",
        "        # NOTE: to exclude one edge type, simply offset range by 1\n",
        "        for i in range(start_idx, len(self.msg_fc2)):\n",
        "            msg = torch.tanh(self.msg_fc1[i](pre_msg))\n",
        "            msg = F.dropout(msg, p=dropout_prob)\n",
        "            msg = torch.tanh(self.msg_fc2[i](msg))\n",
        "            msg = msg * edges[:, :, i:i+1]\n",
        "            all_msgs += msg/norm\n",
        "\n",
        "        # This step sums all of the messages per node\n",
        "        agg_msgs = all_msgs.transpose(-2, -1).matmul(self.edge2node_mat).transpose(-2, -1)\n",
        "        agg_msgs = agg_msgs.contiguous() / (self.num_vars - 1) # Average\n",
        "\n",
        "        # GRU-style gated aggregation\n",
        "        inp_r = self.input_r(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_i = self.input_i(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_n = self.input_n(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        r = torch.sigmoid(inp_r + self.hidden_r(agg_msgs))\n",
        "        i = torch.sigmoid(inp_i + self.hidden_i(agg_msgs))\n",
        "        n = torch.tanh(inp_n + r*self.hidden_h(agg_msgs))\n",
        "        hidden = (1 - i)*n + i*hidden\n",
        "\n",
        "        # Output MLP\n",
        "        pred = F.dropout(F.relu(self.out_fc1(hidden)), p=dropout_prob)\n",
        "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=dropout_prob)\n",
        "        pred = self.out_fc3(pred)\n",
        "\n",
        "        pred = inputs + pred\n",
        "\n",
        "        return pred, hidden"
      ],
      "metadata": {
        "id": "Go9WhD0QiHar"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNRI"
      ],
      "metadata": {
        "id": "L4P7pl1PiPGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNRI(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(DNRI, self).__init__()\n",
        "        # Model Params\n",
        "        self.num_vars = params['num_vars']\n",
        "        self.encoder = DNRI_Encoder(params)\n",
        "        self.decoder = DNRI_Decoder(params)\n",
        "        self.num_edge_types = params.get('num_edge_types')\n",
        "\n",
        "        # Training params\n",
        "        self.gumbel_temp = params.get('gumbel_temp')\n",
        "        self.train_hard_sample = params.get('train_hard_sample')\n",
        "        self.teacher_forcing_steps = params.get('teacher_forcing_steps', -1)\n",
        "        \n",
        "        self.normalize_kl = params.get('normalize_kl', False)\n",
        "        self.normalize_kl_per_var = params.get('normalize_kl_per_var', False)\n",
        "        self.normalize_nll = params.get('normalize_nll', False)\n",
        "        self.normalize_nll_per_var = params.get('normalize_nll_per_var', False)\n",
        "        self.kl_coef = params.get('kl_coef', 1.)\n",
        "        self.nll_loss_type = params.get('nll_loss_type', 'crossent')\n",
        "        self.prior_variance = params.get('prior_variance')\n",
        "        self.timesteps = params.get('timesteps', 0)\n",
        "        self.burn_in_steps = params.get('train_burn_in_steps')\n",
        "        self.teacher_forcing_prior = params.get('teacher_forcing_prior', False)\n",
        "        self.val_teacher_forcing_steps = params.get('val_teacher_forcing_steps', -1)\n",
        "        self.add_uniform_prior = params.get('add_uniform_prior')\n",
        "        if self.add_uniform_prior:\n",
        "            if params.get('no_edge_prior') is not None:\n",
        "                prior = np.zeros(self.num_edge_types)\n",
        "                prior.fill((1 - params['no_edge_prior'])/(self.num_edge_types - 1))\n",
        "                prior[0] = params['no_edge_prior']\n",
        "                log_prior = torch.FloatTensor(np.log(prior))\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                if params['gpu']:\n",
        "                    log_prior = log_prior.cuda(non_blocking=True)\n",
        "                self.log_prior = log_prior\n",
        "                print(\"USING NO EDGE PRIOR: \",self.log_prior)\n",
        "            else:\n",
        "                print(\"USING UNIFORM PRIOR\")\n",
        "                prior = np.zeros(self.num_edge_types)\n",
        "                prior.fill(1.0/self.num_edge_types)\n",
        "                log_prior = torch.FloatTensor(np.log(prior))\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                if params['gpu']:\n",
        "                    log_prior = log_prior.cuda(non_blocking=True)\n",
        "                self.log_prior = log_prior\n",
        "\n",
        "    def single_step_forward(self, inputs, decoder_hidden, edge_logits, hard_sample):\n",
        "        old_shape = edge_logits.shape\n",
        "        edges = gumbel_softmax(\n",
        "            edge_logits.reshape(-1, self.num_edge_types), \n",
        "            tau=self.gumbel_temp, \n",
        "            hard=hard_sample).view(old_shape)\n",
        "        predictions, decoder_hidden = self.decoder(inputs, decoder_hidden, edges)\n",
        "        return predictions, decoder_hidden, edges\n",
        "\n",
        "    def calculate_loss(self, inputs, is_train=False, teacher_forcing=True, return_edges=False, return_logits=False, use_prior_logits=False):\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        num_time_steps = inputs.size(1)\n",
        "        all_edges = []\n",
        "        all_predictions = []\n",
        "        all_priors = []\n",
        "        hard_sample = (not is_train) or self.train_hard_sample\n",
        "        prior_logits, posterior_logits, _ = self.encoder(inputs[:, :-1])\n",
        "        if not is_train:\n",
        "            teacher_forcing_steps = self.val_teacher_forcing_steps\n",
        "        else:\n",
        "            teacher_forcing_steps = self.teacher_forcing_steps\n",
        "        for step in range(num_time_steps-1):\n",
        "            if (teacher_forcing and (teacher_forcing_steps == -1 or step < teacher_forcing_steps)) or step == 0:\n",
        "                current_inputs = inputs[:, step]\n",
        "            else:\n",
        "                current_inputs = predictions\n",
        "            if not use_prior_logits:\n",
        "                current_p_logits = posterior_logits[:, step]\n",
        "            else:\n",
        "                current_p_logits = prior_logits[:, step]\n",
        "            predictions, decoder_hidden, edges = self.single_step_forward(current_inputs, decoder_hidden, current_p_logits, hard_sample)\n",
        "            all_predictions.append(predictions)\n",
        "            all_edges.append(edges)\n",
        "        all_predictions = torch.stack(all_predictions, dim=1)\n",
        "        target = inputs[:, 1:, :, :]\n",
        "        loss_nll = self.nll(all_predictions, target)\n",
        "        prob = F.softmax(posterior_logits, dim=-1)\n",
        "        loss_kl = self.kl_categorical_learned(prob, prior_logits)\n",
        "        if self.add_uniform_prior:\n",
        "            loss_kl = 0.5*loss_kl + 0.5*self.kl_categorical_avg(prob)\n",
        "        loss = loss_nll + self.kl_coef*loss_kl\n",
        "        loss = loss.mean()\n",
        "\n",
        "        if return_edges:\n",
        "            return loss, loss_nll, loss_kl, edges\n",
        "        elif return_logits:\n",
        "            return loss, loss_nll, loss_kl, posterior_logits, all_predictions\n",
        "        else:\n",
        "            return loss, loss_nll, loss_kl\n",
        "\n",
        "    def predict_future(self, inputs, prediction_steps, return_edges=False, return_everything=False):\n",
        "        burn_in_timesteps = inputs.size(1)\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        all_predictions = []\n",
        "        all_edges = []\n",
        "        prior_logits, _, prior_hidden = self.encoder(inputs[:, :-1])\n",
        "        for step in range(burn_in_timesteps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            current_edge_logits = prior_logits[:, step]\n",
        "            predictions, decoder_hidden, edges = self.single_step_forward(current_inputs, decoder_hidden, current_edge_logits, True)\n",
        "            if return_everything:\n",
        "                all_edges.append(edges)\n",
        "                all_predictions.append(predictions)\n",
        "        predictions = inputs[:, burn_in_timesteps-1]\n",
        "        for step in range(prediction_steps):\n",
        "            current_edge_logits, prior_hidden = self.encoder.single_step_forward(predictions, prior_hidden)\n",
        "            predictions, decoder_hidden, edges = self.single_step_forward(predictions, decoder_hidden, current_edge_logits, True)\n",
        "            all_predictions.append(predictions)\n",
        "            all_edges.append(edges)\n",
        "        \n",
        "        predictions = torch.stack(all_predictions, dim=1)\n",
        "        if return_edges:\n",
        "            edges = torch.stack(all_edges, dim=1)\n",
        "            return predictions, edges\n",
        "        else:\n",
        "            return predictions\n",
        "\n",
        "    def copy_states(self, state):\n",
        "        if isinstance(state, tuple) or isinstance(state, list):\n",
        "            current_state = (state[0].clone(), state[1].clone())\n",
        "        else:\n",
        "            current_state = state.clone()\n",
        "        return current_state\n",
        "\n",
        "    def merge_hidden(self, hidden):\n",
        "        if isinstance(hidden[0], tuple) or isinstance(hidden[0], list):\n",
        "            result0 = torch.cat([x[0] for x in hidden], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in hidden], dim=0)\n",
        "            return (result0, result1)\n",
        "        else:\n",
        "            return torch.cat(hidden, dim=0)\n",
        "\n",
        "    def predict_future_fixedwindow(self, inputs, burn_in_steps, prediction_steps, batch_size, return_edges=False):\n",
        "        print(\"INPUT SHAPE: \",inputs.shape)\n",
        "        prior_logits, _, prior_hidden = self.encoder(inputs[:, :-1])\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        for step in range(burn_in_steps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            current_edge_logits = prior_logits[:, step]\n",
        "            predictions, decoder_hidden, _ = self.single_step_forward(current_inputs, decoder_hidden, current_edge_logits, True)\n",
        "        all_timestep_preds = []\n",
        "        all_timestep_edges = []\n",
        "        for window_ind in range(burn_in_steps - 1, inputs.size(1)-1, batch_size):\n",
        "            current_batch_preds = []\n",
        "            current_batch_edges = []\n",
        "            prior_states = []\n",
        "            decoder_states = []\n",
        "            for step in range(batch_size):\n",
        "                if window_ind + step >= inputs.size(1):\n",
        "                    break\n",
        "                predictions = inputs[:, window_ind + step] \n",
        "                current_edge_logits, prior_hidden = self.encoder.single_step_forward(predictions, prior_hidden)\n",
        "                predictions, decoder_hidden, _ = self.single_step_forward(predictions, decoder_hidden, current_edge_logits, True)\n",
        "                current_batch_preds.append(predictions)\n",
        "                tmp_prior = self.encoder.copy_states(prior_hidden)\n",
        "                tmp_decoder = self.copy_states(decoder_hidden)\n",
        "                prior_states.append(tmp_prior)\n",
        "                decoder_states.append(tmp_decoder)\n",
        "                if return_edges:\n",
        "                    current_batch_edges.append(current_edge_logits.cpu())\n",
        "            batch_prior_hidden = self.encoder.merge_hidden(prior_states)\n",
        "            batch_decoder_hidden = self.merge_hidden(decoder_states)\n",
        "            current_batch_preds = torch.cat(current_batch_preds, 0)\n",
        "            current_timestep_preds = [current_batch_preds]\n",
        "            if return_edges:\n",
        "                current_batch_edges = torch.cat(current_batch_edges, 0)\n",
        "                current_timestep_edges = [current_batch_edges]\n",
        "            for step in range(prediction_steps - 1):\n",
        "                current_batch_edge_logits, batch_prior_hidden = self.encoder.single_step_forward(current_batch_preds, batch_prior_hidden)\n",
        "                current_batch_preds, batch_decoder_hidden, _ = self.single_step_forward(current_batch_preds, batch_decoder_hidden, current_batch_edge_logits, True)\n",
        "                current_timestep_preds.append(current_batch_preds)\n",
        "                if return_edges:\n",
        "                    current_timestep_edges.append(current_batch_edge_logits.cpu())\n",
        "            all_timestep_preds.append(torch.stack(current_timestep_preds, dim=1))\n",
        "            if return_edges:\n",
        "                all_timestep_edges.append(torch.stack(current_timestep_edges, dim=1))\n",
        "        result =  torch.cat(all_timestep_preds, dim=0)\n",
        "        if return_edges:\n",
        "            edge_result = torch.cat(all_timestep_edges, dim=0)\n",
        "            return result.unsqueeze(0), edge_result.unsqueeze(0)\n",
        "        else:\n",
        "            return result.unsqueeze(0)\n",
        "\n",
        "    def nll(self, preds, target):\n",
        "        if self.nll_loss_type == 'crossent':\n",
        "            return self.nll_crossent(preds, target)\n",
        "        elif self.nll_loss_type == 'gaussian':\n",
        "            return self.nll_gaussian(preds, target)\n",
        "        elif self.nll_loss_type == 'poisson':\n",
        "            return self.nll_poisson(preds, target)\n",
        "\n",
        "    def nll_gaussian(self, preds, target, add_const=False):\n",
        "        neg_log_p = ((preds - target) ** 2 / (2 * self.prior_variance))\n",
        "        const = 0.5 * np.log(2 * np.pi * self.prior_variance)\n",
        "        #neg_log_p += const\n",
        "        if self.normalize_nll_per_var:\n",
        "            return neg_log_p.sum() / (target.size(0) * target.size(2))\n",
        "        elif self.normalize_nll:\n",
        "            return (neg_log_p.sum(-1) + const).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return neg_log_p.view(target.size(0), -1).sum() / (target.size(1))\n",
        "\n",
        "\n",
        "    def nll_crossent(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def nll_poisson(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def kl_categorical_learned(self, preds, prior_logits):\n",
        "        log_prior = nn.LogSoftmax(dim=-1)(prior_logits)\n",
        "        kl_div = preds*(torch.log(preds + 1e-16) - log_prior)\n",
        "        if self.normalize_kl:     \n",
        "            return kl_div.sum(-1).view(preds.size(0), -1).mean(dim=1)\n",
        "        elif self.normalize_kl_per_var:\n",
        "            return kl_div.sum() / (self.num_vars * preds.size(0))\n",
        "        else:\n",
        "            return kl_div.view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def kl_categorical_avg(self, preds, eps=1e-16):\n",
        "        avg_preds = preds.mean(dim=2)\n",
        "        kl_div = avg_preds*(torch.log(avg_preds+eps) - self.log_prior)\n",
        "        if self.normalize_kl:     \n",
        "            return kl_div.sum(-1).view(preds.size(0), -1).mean(dim=1)\n",
        "        elif self.normalize_kl_per_var:\n",
        "            return kl_div.sum() / (self.num_vars * preds.size(0))\n",
        "        else:\n",
        "            return kl_div.view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "\n",
        "    def save(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "7sDVnc-yiQss"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model"
      ],
      "metadata": {
        "id": "WPyOiuyfiVLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(params):        \n",
        "  model = DNRI(params)\n",
        "  print(\"dNRI MODEL: \",model)\n",
        "\n",
        "  model.cuda()\n",
        "  return model"
      ],
      "metadata": {
        "id": "YYDNnt9AiXmv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(params)"
      ],
      "metadata": {
        "id": "DYzkGBEGia0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8ef4c5-fc67-4007-dd3a-021a3297ce49"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using learned recurrent interaction net decoder.\n",
            "dNRI MODEL:  DNRI(\n",
            "  (encoder): DNRI_Encoder(\n",
            "    (mlp1): RefNRIMLP(\n",
            "      (model): Sequential(\n",
            "        (0): Linear(in_features=4, out_features=10, bias=True)\n",
            "        (1): ELU(alpha=1.0, inplace=True)\n",
            "        (2): Dropout(p=0.5, inplace=False)\n",
            "        (3): Linear(in_features=10, out_features=10, bias=True)\n",
            "        (4): ELU(alpha=1.0, inplace=True)\n",
            "      )\n",
            "      (bn): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mlp2): RefNRIMLP(\n",
            "      (model): Sequential(\n",
            "        (0): Linear(in_features=20, out_features=10, bias=True)\n",
            "        (1): ELU(alpha=1.0, inplace=True)\n",
            "        (2): Dropout(p=0.5, inplace=False)\n",
            "        (3): Linear(in_features=10, out_features=10, bias=True)\n",
            "        (4): ELU(alpha=1.0, inplace=True)\n",
            "      )\n",
            "      (bn): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mlp3): RefNRIMLP(\n",
            "      (model): Sequential(\n",
            "        (0): Linear(in_features=10, out_features=10, bias=True)\n",
            "        (1): ELU(alpha=1.0, inplace=True)\n",
            "        (2): Dropout(p=0.5, inplace=False)\n",
            "        (3): Linear(in_features=10, out_features=10, bias=True)\n",
            "        (4): ELU(alpha=1.0, inplace=True)\n",
            "      )\n",
            "      (bn): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mlp4): RefNRIMLP(\n",
            "      (model): Sequential(\n",
            "        (0): Linear(in_features=30, out_features=10, bias=True)\n",
            "        (1): ELU(alpha=1.0, inplace=True)\n",
            "        (2): Dropout(p=0.5, inplace=False)\n",
            "        (3): Linear(in_features=10, out_features=10, bias=True)\n",
            "        (4): ELU(alpha=1.0, inplace=True)\n",
            "      )\n",
            "      (bn): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (forward_rnn): LSTM(10, 10, batch_first=True)\n",
            "    (reverse_rnn): LSTM(10, 10, batch_first=True)\n",
            "    (encoder_fc_out): Sequential(\n",
            "      (0): Linear(in_features=20, out_features=10, bias=True)\n",
            "      (1): ELU(alpha=1.0, inplace=True)\n",
            "      (2): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (3): ELU(alpha=1.0, inplace=True)\n",
            "      (4): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (5): ELU(alpha=1.0, inplace=True)\n",
            "      (6): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (7): ELU(alpha=1.0, inplace=True)\n",
            "      (8): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (9): ELU(alpha=1.0, inplace=True)\n",
            "      (10): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (11): ELU(alpha=1.0, inplace=True)\n",
            "      (12): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (13): ELU(alpha=1.0, inplace=True)\n",
            "      (14): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (15): ELU(alpha=1.0, inplace=True)\n",
            "      (16): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (17): ELU(alpha=1.0, inplace=True)\n",
            "      (18): Linear(in_features=10, out_features=2, bias=True)\n",
            "    )\n",
            "    (prior_fc_out): Sequential(\n",
            "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (1): ELU(alpha=1.0, inplace=True)\n",
            "      (2): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (3): ELU(alpha=1.0, inplace=True)\n",
            "      (4): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (5): ELU(alpha=1.0, inplace=True)\n",
            "      (6): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (7): ELU(alpha=1.0, inplace=True)\n",
            "      (8): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (9): ELU(alpha=1.0, inplace=True)\n",
            "      (10): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (11): ELU(alpha=1.0, inplace=True)\n",
            "      (12): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (13): ELU(alpha=1.0, inplace=True)\n",
            "      (14): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (15): ELU(alpha=1.0, inplace=True)\n",
            "      (16): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (17): ELU(alpha=1.0, inplace=True)\n",
            "      (18): Linear(in_features=10, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (decoder): DNRI_Decoder(\n",
            "    (msg_fc1): ModuleList(\n",
            "      (0): Linear(in_features=20, out_features=10, bias=True)\n",
            "      (1): Linear(in_features=20, out_features=10, bias=True)\n",
            "    )\n",
            "    (msg_fc2): ModuleList(\n",
            "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
            "      (1): Linear(in_features=10, out_features=10, bias=True)\n",
            "    )\n",
            "    (hidden_r): Linear(in_features=10, out_features=10, bias=False)\n",
            "    (hidden_i): Linear(in_features=10, out_features=10, bias=False)\n",
            "    (hidden_h): Linear(in_features=10, out_features=10, bias=False)\n",
            "    (input_r): Linear(in_features=4, out_features=10, bias=True)\n",
            "    (input_i): Linear(in_features=4, out_features=10, bias=True)\n",
            "    (input_n): Linear(in_features=4, out_features=10, bias=True)\n",
            "    (out_fc1): Linear(in_features=10, out_features=10, bias=True)\n",
            "    (out_fc2): Linear(in_features=10, out_features=10, bias=True)\n",
            "    (out_fc3): Linear(in_features=10, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "FjnGUJxWiaQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, params, train_writer, val_writer):\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    val_batch_size = params.get('val_batch_size', batch_size)\n",
        "    if val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "    accumulate_steps = params.get('accumulate_steps')\n",
        "    training_scheduler = params.get('training_scheduler', None)\n",
        "    num_epochs = params.get('num_epochs', 100)\n",
        "    val_interval = params.get('val_interval', 1)\n",
        "    val_start = params.get('val_start', 0)\n",
        "    clip_grad = params.get('clip_grad', None)\n",
        "    clip_grad_norm = params.get('clip_grad_norm', None)\n",
        "    normalize_nll = params.get('normalize_nll', False)\n",
        "    normalize_kl = params.get('normalize_kl', False)\n",
        "    tune_on_nll = params.get('tune_on_nll', False)\n",
        "    verbose = params.get('verbose', False)\n",
        "    val_teacher_forcing = params.get('val_teacher_forcing', False)\n",
        "    continue_training = params.get('continue_training', False)\n",
        "    train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    val_data_loader = DataLoader(val_data, batch_size=val_batch_size)\n",
        "    lr = params['lr']\n",
        "    wd = params.get('wd', 0.)\n",
        "    mom = params.get('mom', 0.)\n",
        "    \n",
        "    model_params = [param for param in model.parameters() if param.requires_grad]\n",
        "    if params.get('use_adam', False):\n",
        "        opt = torch.optim.Adam(model_params, lr=lr, weight_decay=wd)\n",
        "    else:\n",
        "        opt = torch.optim.SGD(model_params, lr=lr, weight_decay=wd, momentum=mom)\n",
        "\n",
        "    working_dir = params['working_dir']\n",
        "    best_path = os.path.join(working_dir, 'best_model')\n",
        "    checkpoint_dir = os.path.join(working_dir, 'model_checkpoint')\n",
        "    training_path = os.path.join(working_dir, 'training_checkpoint')\n",
        "    if continue_training:\n",
        "        print(\"RESUMING TRAINING\")\n",
        "        model.load(checkpoint_dir)\n",
        "        train_params = torch.load(training_path)\n",
        "        start_epoch = train_params['epoch']\n",
        "        opt.load_state_dict(train_params['optimizer'])\n",
        "        best_val_result = train_params['best_val_result']\n",
        "        best_val_epoch = train_params['best_val_epoch']\n",
        "        print(\"STARTING EPOCH: \",start_epoch)\n",
        "    else:\n",
        "        start_epoch = 1\n",
        "        best_val_epoch = -1\n",
        "        best_val_result = 10000000\n",
        "    \n",
        "    training_scheduler = build_scheduler(opt, params)\n",
        "    end = start = 0 \n",
        "    seed(1)\n",
        "    for epoch in range(start_epoch, num_epochs+1):\n",
        "        print(\"EPOCH\", epoch, (end-start))\n",
        "        model.train()\n",
        "        model.train_percent = epoch / num_epochs\n",
        "        start = time.time() \n",
        "        for batch_ind, batch in enumerate(train_data_loader):\n",
        "            inputs = batch['inputs']\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "            loss, loss_nll, loss_kl, logits, _ = model.calculate_loss(inputs, is_train=True, return_logits=True)\n",
        "            loss.backward()\n",
        "            if verbose:\n",
        "                print(\"\\tBATCH %d OF %d: %f, %f, %f\"%(batch_ind+1, len(train_data_loader), loss.item(), loss_nll.mean().item(), loss_kl.mean().item()))\n",
        "            if accumulate_steps == -1 or (batch_ind+1)%accumulate_steps == 0:\n",
        "                if verbose and accumulate_steps > 0:\n",
        "                    print(\"\\tUPDATING WEIGHTS\")\n",
        "                if clip_grad is not None:\n",
        "                    nn.utils.clip_grad_value_(model.parameters(), clip_grad)\n",
        "                elif clip_grad_norm is not None:\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)        \n",
        "                opt.step()\n",
        "                opt.zero_grad()\n",
        "                if accumulate_steps > 0 and accumulate_steps > len(train_data_loader) - batch_ind - 1:\n",
        "                    break\n",
        "            \n",
        "        if training_scheduler is not None:\n",
        "            training_scheduler.step()\n",
        "        \n",
        "        if train_writer is not None:\n",
        "            train_writer.add_scalar('loss', loss.item(), global_step=epoch)\n",
        "            if normalize_nll:\n",
        "                train_writer.add_scalar('NLL', loss_nll.mean().item(), global_step=epoch)\n",
        "            else:\n",
        "                train_writer.add_scalar('NLL', loss_nll.mean().item()/(inputs.size(1)*inputs.size(2)), global_step=epoch)\n",
        "            \n",
        "            train_writer.add_scalar(\"KL Divergence\", loss_kl.mean().item(), global_step=epoch)\n",
        "        model.eval()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        total_nll = 0\n",
        "        total_kl = 0\n",
        "        if verbose:\n",
        "            print(\"COMPUTING VAL LOSSES\")\n",
        "        with torch.no_grad():\n",
        "            for batch_ind, batch in enumerate(val_data_loader):\n",
        "                inputs = batch['inputs']\n",
        "                if gpu:\n",
        "                    inputs = inputs.cuda(non_blocking=True)\n",
        "                loss, loss_nll, loss_kl, logits, _ = model.calculate_loss(inputs, is_train=False, teacher_forcing=val_teacher_forcing, return_logits=True)\n",
        "                total_kl += loss_kl.sum().item()\n",
        "                total_nll += loss_nll.sum().item()\n",
        "                if verbose:\n",
        "                    print(\"\\tVAL BATCH %d of %d: %f, %f\"%(batch_ind+1, len(val_data_loader), loss_nll.mean(), loss_kl.mean()))\n",
        "            \n",
        "        total_kl /= len(val_data)\n",
        "        total_nll /= len(val_data)\n",
        "        total_loss = model.kl_coef*total_kl + total_nll #TODO: this is a thing you fixed\n",
        "        if val_writer is not None:\n",
        "            val_writer.add_scalar('loss', total_loss, global_step=epoch)\n",
        "            val_writer.add_scalar(\"NLL\", total_nll, global_step=epoch)\n",
        "            val_writer.add_scalar(\"KL Divergence\", total_kl, global_step=epoch)\n",
        "        if tune_on_nll:\n",
        "            tuning_loss = total_nll\n",
        "        else:\n",
        "            tuning_loss = total_loss\n",
        "        if tuning_loss < best_val_result:\n",
        "            best_val_epoch = epoch\n",
        "            best_val_result = tuning_loss\n",
        "            print(\"BEST VAL RESULT. SAVING MODEL...\")\n",
        "            model.save(best_path)\n",
        "        model.save(checkpoint_dir)\n",
        "        torch.save({\n",
        "                    'epoch':epoch+1,\n",
        "                    'optimizer':opt.state_dict(),\n",
        "                    'best_val_result':best_val_result,\n",
        "                    'best_val_epoch':best_val_epoch,\n",
        "                   }, training_path)\n",
        "        print(\"EPOCH %d EVAL: \"%epoch)\n",
        "        print(\"\\tCURRENT VAL LOSS: %f\"%tuning_loss)\n",
        "        print(\"\\tBEST VAL LOSS:    %f\"%best_val_result)\n",
        "        print(\"\\tBEST VAL EPOCH:   %d\"%best_val_epoch)\n",
        "        end = time.time()"
      ],
      "metadata": {
        "id": "gFAiV2h8iiBK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = [numpy.array(i) for i in dataframe[:100].R]\n",
        "test_dataset = [numpy.array(i) for i in dataframe[100:150].R]"
      ],
      "metadata": {
        "id": "u7atlPZom9CC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model,train_dataset,test_dataset, params, None, None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "hmt2pLjOmop7",
        "outputId": "974f045a-7680-439f-aa83-18b90eb75814"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-623a0a1a27a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-7c34bebfeaa8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, params, train_writer, val_writer)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_Z1zOC5_rwKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g0P2d3-ksdpX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}