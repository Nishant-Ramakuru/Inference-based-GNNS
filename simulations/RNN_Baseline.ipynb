{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nishant-Ramakuru/Inference-based-GNNS/blob/main/simulations/RNN_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Functions\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.colors as mcolors\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "import argparse, os, time\n",
        "from torch.nn import init\n",
        "import math\n",
        "import networkx as nx\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8Tm6GblxoZWs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXmvpJedOnr",
        "outputId": "0110ce94-4fc8-4ae3-f031-f92573dde1bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters"
      ],
      "metadata": {
        "id": "1kxH7lSHpbAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {}\n",
        "tau = 1\n",
        "params['use_adam'] = True\n",
        "params['test_burn_in_steps'] =0\n",
        "params['num_time_steps'] = 50\n",
        "params['data_path']= '/content/MyDrive/GNNs'\n",
        "params['num_train'] = 3000\n",
        "params['num_val'] = 1000\n",
        "params['num_test']= 1000\n",
        "params['load_model'] = False\n",
        "params['load_best_model'] = False\n",
        "params['model_type'] = 'RNN'\n",
        "#params['graph_type'] = ['static', 'dynamic']\n",
        "params['graph_type'] = 'dynamic'\n",
        "params['encoder_no_factor'] = True\n",
        "params['num_epochs'] = 100\n",
        "params['num_vars'] = params['num_agents'] = 10\n",
        "params['input_noise_type'] = 'none'\n",
        "params['input_size'] = 4\n",
        "params['nll_loss_type'] = 'gaussian'\n",
        "params['prior_variance'] = 5e-5\n",
        "params['batch_size'] = 64\n",
        "params['val_batch_size'] = 64\n",
        "params['accumulate_steps'] = 40\n",
        "params['num_edge_types'] = 1\n",
        "params['encoder_dropout'] = 0.0\n",
        "params['encoder_hidden'] = 256\n",
        "params['encoder_rnn_hidden'] = 64\n",
        "params['encoder_rnn_type'] = 'lstm'\n",
        "params['decoder_rnn_type'] = 'lstm'\n",
        "params['encoder_mlp_num_layers'] = 1\n",
        "params['encoder_mlp_hidden'] = 256\n",
        "params['prior_num_layers'] = 1\n",
        "params['prior_hidden_size'] = 256\n",
        "params['gpu'] = False\n",
        "params['decoder_hidden'] = 256\n",
        "params['skip_first'] = False\n",
        "params['decoder_dropout'] = 0.0\n",
        "params['decoder_type'] = None\n",
        "params['lr'] = 5e-4\n",
        "params['mode'] = \"train\"\n",
        "\n",
        "params['working_dir'] =params['output_dir'] =  ('/content/MyDrive/GNNs')"
      ],
      "metadata": {
        "id": "hu42uHhigCwW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "id": "kfqJoGAgpd_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle(\"/content/drive/MyDrive/GNNs/boids_buffer_10_final1.csv\")"
      ],
      "metadata": {
        "id": "XXXXqOdbc1as",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049c3fa3-e82b-4e35-9177-b5884aa0af82"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo0__BlW4zLO",
        "outputId": "8284cf87-3bb9-4584-98e0-4c17b59b81ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Sx9crDBZdld5",
        "outputId": "04cbac67-dd63-4489-bd10-4e8eb782e5a5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   R  \\\n",
              "0  [[1077.9397, 666.84686], [856.4423, 1137.0732]...   \n",
              "1  [[1073.0123, 667.6944], [856.3285, 1142.072], ...   \n",
              "2  [[1068.0665, 668.4283], [856.2146, 1147.0707],...   \n",
              "3  [[1063.112, 669.102], [856.10077, 1152.0693], ...   \n",
              "4  [[1058.1525, 669.736], [855.9869, 1157.0681], ...   \n",
              "\n",
              "                                               theta  \\\n",
              "0  [2.9513416, 1.5935696, 4.8110423, 0.96409255, ...   \n",
              "1  [2.9859188, 1.5935696, 4.8110423, 0.96409255, ...   \n",
              "2  [3.0014527, 1.5935696, 4.8110423, 0.96409255, ...   \n",
              "3  [3.0109863, 1.5935696, 4.8110423, 0.96409255, ...   \n",
              "4  [3.0177057, 1.5935696, 4.8110423, 0.96409255, ...   \n",
              "\n",
              "                                            velocity  \\\n",
              "0  [[-4.927397, 0.8475409], [-0.11385684, 4.99870...   \n",
              "1  [[-4.9457974, 0.7338834], [-0.11385684, 4.9987...   \n",
              "2  [[-4.954386, 0.6736986], [-0.11385684, 4.99870...   \n",
              "3  [[-4.9596305, 0.6340109], [-0.11385684, 4.9987...   \n",
              "4  [[-4.963271, 0.6048854], [-0.11385684, 4.99870...   \n",
              "\n",
              "                                          trajectory  \n",
              "0  [[1077.9397, 666.84686, -4.927397, 0.8475409],...  \n",
              "1  [[1073.0123, 667.6944, -4.9457974, 0.7338834],...  \n",
              "2  [[1068.0665, 668.4283, -4.954386, 0.6736986], ...  \n",
              "3  [[1063.112, 669.102, -4.9596305, 0.6340109], [...  \n",
              "4  [[1058.1525, 669.736, -4.963271, 0.6048854], [...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a172a9a0-dedb-492f-88d8-e9af68a38c5a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R</th>\n",
              "      <th>theta</th>\n",
              "      <th>velocity</th>\n",
              "      <th>trajectory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[1077.9397, 666.84686], [856.4423, 1137.0732]...</td>\n",
              "      <td>[2.9513416, 1.5935696, 4.8110423, 0.96409255, ...</td>\n",
              "      <td>[[-4.927397, 0.8475409], [-0.11385684, 4.99870...</td>\n",
              "      <td>[[1077.9397, 666.84686, -4.927397, 0.8475409],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[1073.0123, 667.6944], [856.3285, 1142.072], ...</td>\n",
              "      <td>[2.9859188, 1.5935696, 4.8110423, 0.96409255, ...</td>\n",
              "      <td>[[-4.9457974, 0.7338834], [-0.11385684, 4.9987...</td>\n",
              "      <td>[[1073.0123, 667.6944, -4.9457974, 0.7338834],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[1068.0665, 668.4283], [856.2146, 1147.0707],...</td>\n",
              "      <td>[3.0014527, 1.5935696, 4.8110423, 0.96409255, ...</td>\n",
              "      <td>[[-4.954386, 0.6736986], [-0.11385684, 4.99870...</td>\n",
              "      <td>[[1068.0665, 668.4283, -4.954386, 0.6736986], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[1063.112, 669.102], [856.10077, 1152.0693], ...</td>\n",
              "      <td>[3.0109863, 1.5935696, 4.8110423, 0.96409255, ...</td>\n",
              "      <td>[[-4.9596305, 0.6340109], [-0.11385684, 4.9987...</td>\n",
              "      <td>[[1063.112, 669.102, -4.9596305, 0.6340109], [...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[1058.1525, 669.736], [855.9869, 1157.0681], ...</td>\n",
              "      <td>[3.0177057, 1.5935696, 4.8110423, 0.96409255, ...</td>\n",
              "      <td>[[-4.963271, 0.6048854], [-0.11385684, 4.99870...</td>\n",
              "      <td>[[1058.1525, 669.736, -4.963271, 0.6048854], [...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a172a9a0-dedb-492f-88d8-e9af68a38c5a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a172a9a0-dedb-492f-88d8-e9af68a38c5a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a172a9a0-dedb-492f-88d8-e9af68a38c5a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for w in range(len(df)):\n",
        "  \n",
        "  state = np.array(df.R[w])\n",
        "  D = list()\n",
        "  for a,i in enumerate(state):\n",
        "    d= []\n",
        "    for b,j in enumerate(state):\n",
        "      eDistance = math.hypot(i[0] - j[0], i[1] - j[1])\n",
        "      if a == b:\n",
        "        d.append(0)\n",
        "      elif int(eDistance) <= 200:\n",
        "        d.append(1)\n",
        "      else:\n",
        "        d.append(0)\n",
        "    D.append(d)\n",
        "\n",
        "  data.append(np.array(D))\n",
        "edge_data = np.array(data)\n",
        "all_data = np.array(list(df.trajectory))\n",
        "\n",
        "adj_array = []\n",
        "#print(edge_data.shape)\n",
        "for time_step in range(len(edge_data)):\n",
        "  edge = []\n",
        "  for i in range(len(edge_data[0])):\n",
        "    edge = edge + list(list(edge_data[time_step][i][:i])+list(edge_data[time_step][i][i+1:]))\n",
        "    \n",
        "  #print(len(edge[0].shape))\n",
        "  adj_array.append(edge)\n",
        "\n",
        "edge_data = np.array(adj_array)"
      ],
      "metadata": {
        "id": "DvNzNXDsmHrD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = np.stack(all_data)\n",
        "train_data = torch.FloatTensor(all_data[:params['num_train']])\n",
        "val_data = torch.FloatTensor(all_data[params['num_train']:params['num_train']+params['num_val']])\n",
        "test_data = torch.FloatTensor(all_data[params['num_train']+params['num_val']:params['num_train']+params['num_val']+params['num_test']])\n",
        "\n",
        "train_edges = torch.FloatTensor(edge_data[:params['num_train']])\n",
        "val_edges = torch.FloatTensor(edge_data[params['num_train']:params['num_train']+params['num_val']])\n",
        "test_edges = torch.FloatTensor(edge_data[params['num_train']+params['num_val']:params['num_train']+params['num_val']+params['num_test']])"
      ],
      "metadata": {
        "id": "sMqcjpLRea24"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del all_data, df,edge_data, data"
      ],
      "metadata": {
        "id": "d9nZE2UU9tCL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Shape:\", train_data.shape,\"\\n\", \n",
        "       \"Val Shape:\", val_data.shape,\"\\n\",\n",
        "      \"Test Shape:\", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UGCd5PmDRff",
        "outputId": "813a72dc-147c-4ba5-c21d-93906d0f8c79"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Shape: torch.Size([3000, 10, 4]) \n",
            " Val Shape: torch.Size([1000, 10, 4]) \n",
            " Test Shape: torch.Size([1000, 10, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.reshape([int(params[\"num_train\"]/50),50,10,4])\n",
        "val_data = val_data.reshape([int(params[\"num_val\"]/50),50,10,4])\n",
        "test_data = test_data.reshape([int(params[\"num_test\"]/50),50,10,4])\n",
        "\n",
        "train_edges = train_edges.reshape([int(params['num_train']/50),50,90])\n",
        "val_edges = val_edges.reshape([int(params['num_val']/50),50,90])\n",
        "test_edges = test_edges.reshape([int(params['num_test']/50),50,90])"
      ],
      "metadata": {
        "id": "a5aGYElZbFo_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torch.nn.functional.normalize(train_data)\n",
        "val_data = torch.nn.functional.normalize(val_data)\n",
        "test_data = torch.nn.functional.normalize(test_data)"
      ],
      "metadata": {
        "id": "lRvZM3sW8hCa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA = []\n",
        "\n",
        "for i in range(train_data.shape[0]):\n",
        "  DATA.append({'inputs':train_data[i].reshape([1,50,10,4]),'edges':train_edges[i].reshape([1,50,90])})\n",
        "\n",
        "VAL = []\n",
        "\n",
        "for i in range(val_data.shape[0]):\n",
        "  VAL.append({'inputs':val_data[i].reshape([1,50,10,4]),'edges':val_edges[i].reshape([1,50,90])})\n",
        "\n",
        "TEST = []\n",
        "\n",
        "for i in range(test_data.shape[0]):\n",
        "  TEST.append({'inputs':test_data[i].reshape([1,50,10,4]),'edges':test_edges[i].reshape([1,50,90])})"
      ],
      "metadata": {
        "id": "rw95XbyRx3XM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "def seed(seed_val):\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    random.seed(seed_val)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "def build_scheduler(opt, params):\n",
        "    lr_decay_factor = params.get('lr_decay_factor')\n",
        "    lr_decay_steps = params.get('lr_decay_steps')\n",
        "    if lr_decay_factor:\n",
        "        return torch.optim.lr_scheduler.StepLR(opt, lr_decay_steps, lr_decay_factor)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "class build_writers:\n",
        "    def __init__(self, working_dir, is_test=False):\n",
        "        self.writer_dir = os.path.join(working_dir, 'logs/')\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __enter__(self):\n",
        "        train_writer_dir = os.path.join(self.writer_dir, 'train')\n",
        "        val_writer_dir = os.path.join(self.writer_dir, 'val')\n",
        "        self.train_writer = SummaryWriter(train_writer_dir)\n",
        "        self.val_writer = SummaryWriter(val_writer_dir)\n",
        "        if self.is_test:\n",
        "            test_writer_dir = os.path.join(self.writer_dir, 'test')\n",
        "            self.test_writer = SummaryWriter(test_writer_dir)\n",
        "            return self.train_writer, self.val_writer, self.test_writer\n",
        "        else:\n",
        "            return self.train_writer, self.val_writer\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        self.train_writer.close()\n",
        "        self.val_writer.close()\n",
        "        if self.is_test:\n",
        "            self.test_writer.close()\n",
        "\n",
        "# Code from NRI.\n",
        "def normalize(data):\n",
        "\treturn (data-(torch.mean(data))/ (torch.std(data)))\n",
        "\n",
        "\n",
        "def unnormalize(data, data_max, data_min):\n",
        "\treturn (data + 1) * (data_max - data_min) / 2. + data_min\n",
        "\n",
        "\n",
        "def get_edge_inds(num_vars):\n",
        "\tedges = []\n",
        "\tfor i in range(num_vars):\n",
        "\t\tfor j in range(num_vars):\n",
        "\t\t\tif i == j:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tedges.append([i, j])\n",
        "\treturn edges\n",
        "\n",
        "class RefNRIMLP(nn.Module):\n",
        "    \"\"\"Two-layer fully-connected ELU net with batch norm.\"\"\"\n",
        "\n",
        "    def __init__(self, n_in, n_hid, n_out, do_prob=0., no_bn=False):\n",
        "        super(RefNRIMLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(n_in, n_hid),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, n_out),\n",
        "            nn.ELU(inplace=True)\n",
        "        )\n",
        "        if no_bn:\n",
        "            self.bn = None\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm1d(n_out)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def batch_norm(self, inputs):\n",
        "        orig_shape = inputs.shape\n",
        "        x = inputs.view(-1, inputs.size(-1))\n",
        "        x = self.bn(x)\n",
        "        return x.view(orig_shape)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Input shape: [num_sims, num_things, num_features]\n",
        "        x = self.model(inputs)\n",
        "        if self.bn is not None:\n",
        "            return self.batch_norm(x)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "\n",
        "def sample_gumbel(shape, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Sample from Gumbel(0, 1)\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    U = torch.rand(shape).float()\n",
        "    return - torch.log(eps - torch.log(U + eps))\n",
        "\n",
        "\n",
        "def gumbel_softmax_sample(logits, tau=1, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Draw a sample from the Gumbel-Softmax distribution\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    gumbel_noise = sample_gumbel(logits.size(), eps=eps)\n",
        "    if logits.is_cuda:\n",
        "        gumbel_noise = gumbel_noise.cuda()\n",
        "    y = logits + gumbel_noise\n",
        "    tau = int(1)\n",
        "    return F.softmax(y / tau, dim=-1)\n",
        "\n",
        "\n",
        "def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
        "    Args:\n",
        "      logits: [batch_size, n_class] unnormalized log-probs\n",
        "      tau: non-negative scalar temperature\n",
        "      hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
        "    Returns:\n",
        "      [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
        "      If hard=True, then the returned sample will be one-hot, otherwise it will\n",
        "      be a probability distribution that sums to 1 across classes\n",
        "    Constraints:\n",
        "    - this implementation only works on batch_size x num_features tensor for now\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    y_soft = gumbel_softmax_sample(logits, tau=tau, eps=eps)\n",
        "    if hard:\n",
        "        shape = logits.size()\n",
        "        _, k = y_soft.data.max(-1)\n",
        "        # this bit is based on\n",
        "        # https://discuss.pytorch.org/t/stop-gradients-for-st-gumbel-softmax/530/5\n",
        "        y_hard = torch.zeros(*shape)\n",
        "        if y_soft.is_cuda:\n",
        "            y_hard = y_hard.cuda()\n",
        "        y_hard = y_hard.zero_().scatter_(-1, k.view(shape[:-1] + (1,)), 1.0)\n",
        "        # this cool bit of code achieves two things:\n",
        "        # - makes the output value exactly one-hot (since we add then\n",
        "        #   subtract y_soft value)\n",
        "        # - makes the gradient equal to y_soft gradient (since we strip\n",
        "        #   all other gradients)\n",
        "        y = y_hard - y_soft.data + y_soft\n",
        "    else:\n",
        "        y = y_soft\n",
        "    return y\n",
        "\n",
        "\n",
        "def get_graph_info(masks, num_vars, use_edge2node=True):\n",
        "    if num_vars == 1:\n",
        "        return None, None, None\n",
        "    edges = torch.ones(num_vars, device=masks.device) - torch.eye(num_vars, device=masks.device)\n",
        "    tmp = torch.where(edges)\n",
        "    send_edges = tmp[0]\n",
        "    recv_edges = tmp[1]\n",
        "    tmp_inds = torch.tensor(list(range(num_vars)), device=masks.device, dtype=torch.long).unsqueeze_(1)\n",
        "    if use_edge2node:\n",
        "        edge2node_inds = (tmp_inds == recv_edges.unsqueeze(0)).nonzero()[:, 1].contiguous().view(-1, num_vars-1)\n",
        "        return send_edges, recv_edges, edge2node_inds\n",
        "    else:\n",
        "        return send_edges, recv_edges"
      ],
      "metadata": {
        "id": "nujWHRp4W0CD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNRI"
      ],
      "metadata": {
        "id": "yzULzLLYq5vS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RecurrentBaseline(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(RecurrentBaseline, self).__init__()\n",
        "        self.num_vars = params['num_vars']\n",
        "        self.teacher_forcing_steps = params.get('teacher_forcing_steps', -1)\n",
        "        self.nll_loss_type = params.get('nll_loss_type', 'crossent')\n",
        "        self.prior_variance = params.get('prior_variance')\n",
        "        self.normalize_nll = params.get('normalize_nll', False)\n",
        "        self.normalize_nll_per_var = params.get('normalize_nll_per_var', False)\n",
        "        self.anneal_teacher_forcing = params.get('anneal_teacher_forcing', False)\n",
        "        self.val_teacher_forcing_steps = params.get('val_teacher_forcing_steps', -1)\n",
        "        self.kl_coef = 0\n",
        "        self.steps = 0\n",
        "    \n",
        "    def single_step_forward(self, inputs, hidden):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def normalize_inputs(self, inputs):\n",
        "        return inputs\n",
        "    \n",
        "    def calculate_loss(self, inputs, is_train=False, teacher_forcing=True, return_logits=False, use_prior_logits=False, normalized_inputs=None):\n",
        "        hidden = self.get_initial_hidden(inputs)\n",
        "        num_time_steps = inputs.size(1)\n",
        "        all_predictions = []\n",
        "        if not is_train:\n",
        "            teacher_forcing_steps = self.val_teacher_forcing_steps\n",
        "        else:\n",
        "            teacher_forcing_steps = self.teacher_forcing_steps\n",
        "        for step in range(num_time_steps-1):\n",
        "            if (teacher_forcing and (teacher_forcing_steps == -1 or step < teacher_forcing_steps)) or step == 0:\n",
        "                current_inputs = inputs[:, step]\n",
        "            else:\n",
        "                current_inputs = predictions\n",
        "            predictions, hidden = self.single_step_forward(current_inputs, hidden)\n",
        "            all_predictions.append(predictions)\n",
        "        all_predictions = torch.stack(all_predictions, dim=1)\n",
        "        target = inputs[:, 1:, :, :]\n",
        "        loss_nll = self.nll(all_predictions, target)\n",
        "        loss_kl = torch.zeros_like(loss_nll)\n",
        "        loss = loss_nll.mean()\n",
        "        #print(loss, loss_nll, loss_kl,\"RNNbase\")\n",
        "        if return_logits:\n",
        "            return loss, loss_nll, loss_kl, None, all_predictions\n",
        "        else:\n",
        "            return loss, loss_nll, loss_kl\n",
        "\n",
        "    def predict_future(self, inputs, prediction_steps, return_everything=False):\n",
        "        burn_in_timesteps = inputs.size(1)\n",
        "        hidden = self.get_initial_hidden(inputs)\n",
        "        all_predictions = []\n",
        "        for step in range(burn_in_timesteps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            predictions, hidden = self.single_step_forward(current_inputs, hidden)\n",
        "            if return_everything:\n",
        "                all_predictions.append(predictions)\n",
        "        predictions = inputs[:, burn_in_timesteps-1]\n",
        "        for step in range(prediction_steps):\n",
        "            predictions, hidden = self.single_step_forward(predictions, hidden)\n",
        "            all_predictions.append(predictions)\n",
        "        \n",
        "        predictions = torch.stack(all_predictions, dim=1)\n",
        "        return predictions\n",
        "\n",
        "    def copy_states(self, state):\n",
        "        if isinstance(state, tuple) or isinstance(state, list):\n",
        "            current_state = (state[0].clone(), state[1].clone())\n",
        "        else:\n",
        "            current_state = state.clone()\n",
        "        return current_state\n",
        "\n",
        "    def merge_hidden(self, hidden):\n",
        "        if isinstance(hidden[0], tuple) or isinstance(hidden[0], list):\n",
        "            result0 = torch.cat([x[0] for x in hidden], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in hidden], dim=0)\n",
        "            return (result0, result1)\n",
        "        else:\n",
        "            return torch.cat(hidden, dim=0)\n",
        "\n",
        "    def predict_future_fixedwindow(self, inputs, burn_in_steps, prediction_steps, batch_size):\n",
        "        hidden = self.get_initial_hidden(inputs)\n",
        "        for step in range(burn_in_steps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            predictions, hidden = self.single_step_forward(current_inputs, hidden)\n",
        "        all_timestep_preds = []\n",
        "        for window_ind in range(burn_in_steps - 1, inputs.size(1)-1, batch_size):\n",
        "            current_batch_preds = []\n",
        "            states = []\n",
        "            for step in range(batch_size):\n",
        "                if window_ind + step >= inputs.size(1):\n",
        "                    break\n",
        "                predictions = inputs[:, window_ind + step]\n",
        "                predictions, hidden = self.single_step_forward(predictions, hidden)\n",
        "                current_batch_preds.append(predictions)\n",
        "                tmp_decoder = self.copy_states(hidden)\n",
        "                states.append(tmp_decoder)\n",
        "            batch_hidden = self.merge_hidden(states)\n",
        "            current_batch_preds = torch.cat(current_batch_preds, 0)\n",
        "            current_timestep_preds = [current_batch_preds]\n",
        "            for step in range(prediction_steps - 1):\n",
        "                current_batch_preds, batch_hidden = self.single_step_forward(current_batch_preds, batch_hidden)\n",
        "                current_timestep_preds.append(current_batch_preds)\n",
        "            all_timestep_preds.append(torch.stack(current_timestep_preds, dim=1))\n",
        "        results = torch.cat(all_timestep_preds, dim=0)\n",
        "        return results.unsqueeze(0)\n",
        "\n",
        "    def nll(self, preds, target):\n",
        "        if self.nll_loss_type == 'crossent':\n",
        "            return self.nll_crossent(preds, target)\n",
        "        elif self.nll_loss_type == 'gaussian':\n",
        "            return self.nll_gaussian(preds, target)\n",
        "        elif self.nll_loss_type == 'poisson':\n",
        "            return self.nll_poisson(preds, target)\n",
        "\n",
        "    def nll_gaussian(self, preds, target, add_const=False):\n",
        "        neg_log_p = ((preds - target) ** 2 / (2 * self.prior_variance))\n",
        "        const = 0.5 * np.log(2 * np.pi * self.prior_variance)\n",
        "        #neg_log_p += const\n",
        "        if self.normalize_nll_per_var:\n",
        "            return neg_log_p.sum() / (target.size(0) * target.size(2))\n",
        "        elif self.normalize_nll:\n",
        "            return (neg_log_p.sum(-1) + const).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return neg_log_p.view(target.size(0), -1).sum() / (target.size(1))\n",
        "\n",
        "\n",
        "    def nll_crossent(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def nll_poisson(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def save(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.load_state_dict(torch.load(path))\n",
        "\n",
        "\n",
        "class SingleRNNBaseline(RecurrentBaseline):\n",
        "    def __init__(self, params):\n",
        "        super(SingleRNNBaseline, self).__init__(params)\n",
        "        self.n_hid = n_hid = params['decoder_hidden']\n",
        "        out_size = params['input_size']\n",
        "        do_prob = params['decoder_dropout']\n",
        "        input_size = params['input_size']\n",
        "        self.num_vars = num_vars = params['num_vars']\n",
        "        self.rnn_type = params['decoder_rnn_type']\n",
        "        if self.rnn_type == 'lstm':\n",
        "            self.rnn = nn.LSTMCell(input_size, n_hid)\n",
        "        elif self.rnn_type == 'gru':\n",
        "            self.rnn = nn.GRUCell(input_size, n_hid)\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(n_hid, n_hid),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, n_hid),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, out_size),\n",
        "        )\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return None\n",
        "        '''\n",
        "        if self.rnn_type == 'lstm':\n",
        "            raise NotImplementedError\n",
        "            return torch.zeros(inputs.size(0)*inputs.size(2), self.n_hid, device=inputs.device)\n",
        "        else:\n",
        "            return torch.zeros(inputs.size(0)*inputs.size(2), self.n_hid, device=inputs.device)\n",
        "        '''\n",
        "\n",
        "    def single_step_forward(self, inputs, hidden):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        tmp_inp = inputs.reshape(-1, inputs.size(-1))\n",
        "        hidden = self.rnn(tmp_inp)\n",
        "        if self.rnn_type == 'lstm':\n",
        "            tmp = hidden[0].view(inputs.size(0), inputs.size(1), -1)\n",
        "        else:\n",
        "            tmp = hidden.view(inputs.size(0), inputs.size(1), -1)\n",
        "        outputs = inputs + self.out(tmp)\n",
        "        return outputs, hidden\n",
        "\n",
        "class JointRNNBaseline(RecurrentBaseline):\n",
        "    def __init__(self, params):\n",
        "        super(JointRNNBaseline, self).__init__(params)\n",
        "        self.n_hid = n_hid = params['decoder_hidden']\n",
        "        do_prob = params['decoder_dropout']\n",
        "        self.num_vars = num_vars = params['num_vars']\n",
        "        out_size = input_size = params['input_size']*num_vars\n",
        "        self.rnn_type = params['decoder_rnn_type']\n",
        "        if self.rnn_type == 'lstm':\n",
        "            self.rnn = nn.LSTMCell(input_size, n_hid)\n",
        "        elif self.rnn_type == 'gru':\n",
        "            self.rnn = nn.GRUCell(input_size, n_hid)\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(n_hid, n_hid),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, n_hid),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, out_size),\n",
        "        )\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return None\n",
        "        '''\n",
        "        if self.rnn_type == 'lstm':\n",
        "            raise NotImplementedError\n",
        "            return torch.zeros(inputs.size(0)*inputs.size(2), self.n_hid, device=inputs.device)\n",
        "        else:\n",
        "            return torch.zeros(inputs.size(0)*inputs.size(2), self.n_hid, device=inputs.device)\n",
        "        '''\n",
        "\n",
        "    def single_step_forward(self, inputs, hidden):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        tmp_inp = inputs.view(inputs.size(0), -1)\n",
        "        hidden = self.rnn(tmp_inp)\n",
        "        if self.rnn_type == 'lstm':\n",
        "            tmp = hidden[0]\n",
        "        else:\n",
        "            tmp = hidden\n",
        "        outputs = inputs + self.out(tmp).view(inputs.size(0), inputs.size(1), -1)\n",
        "        return outputs, hidden\n",
        " \n",
        "        \n",
        "\n",
        "\n",
        "class FullyConnectedBaseline(RecurrentBaseline):\n",
        "    def __init__(self, params):\n",
        "        super(FullyConnectedBaseline, self).__init__(params)\n",
        "        n_hid = params['decoder_hidden']\n",
        "        edge_types = params['num_edge_types']\n",
        "        skip_first = params['skip_first']\n",
        "        out_size = params['input_size']\n",
        "        do_prob = params['decoder_dropout']\n",
        "        input_size = params['input_size']\n",
        "        self.num_vars = num_vars =  params['num_vars']\n",
        "\n",
        "        self.msg_fc1 = nn.Linear(2*n_hid, n_hid)\n",
        "        self.msg_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.msg_out_shape = n_hid\n",
        "        self.skip_first_edge_type = skip_first\n",
        "\n",
        "        self.hidden_r = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_i = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_h = nn.Linear(n_hid, n_hid, bias=False)\n",
        "\n",
        "        self.input_r = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_i = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_n = nn.Linear(input_size, n_hid, bias=True)\n",
        "\n",
        "        self.out_fc1 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc3 = nn.Linear(n_hid, out_size)\n",
        "\n",
        "        print('Using learned recurrent interaction net decoder.')\n",
        "\n",
        "        self.dropout_prob = do_prob\n",
        "\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = nn.Parameter(torch.FloatTensor(encode_onehot(self.recv_edges)), requires_grad=False)\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return torch.zeros(inputs.size(0), inputs.size(2), self.msg_out_shape, device=inputs.device)\n",
        "\n",
        "\n",
        "    def single_step_forward(self, inputs, hidden):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        # Edges size: [batch, num_edges, num_edge_types]\n",
        "        if self.training:\n",
        "            dropout_prob = self.dropout_prob\n",
        "        else:\n",
        "            dropout_prob = 0.\n",
        "        \n",
        "        # node2edge\n",
        "        receivers = hidden[:, self.recv_edges, :]\n",
        "        senders = hidden[:, self.send_edges, :]\n",
        "\n",
        "        # pre_msg: [batch, num_edges, 2*msg_out]\n",
        "        pre_msg = torch.cat([receivers, senders], dim=-1)\n",
        "\n",
        "        msg = torch.tanh(self.msg_fc1(pre_msg))\n",
        "        msg = F.dropout(msg, p=dropout_prob)\n",
        "        msg = torch.tanh(self.msg_fc2(msg))\n",
        "        all_msgs = msg\n",
        "\n",
        "        # This step sums all of the messages per node\n",
        "        agg_msgs = all_msgs.transpose(-2, -1).matmul(self.edge2node_mat).transpose(-2, -1)\n",
        "        agg_msgs = agg_msgs.contiguous() / (self.num_vars - 1) # Average\n",
        "\n",
        "        # GRU-style gated aggregation\n",
        "        inp_r = self.input_r(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_i = self.input_i(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_n = self.input_n(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        r = torch.sigmoid(inp_r + self.hidden_r(agg_msgs))\n",
        "        i = torch.sigmoid(inp_i + self.hidden_i(agg_msgs))\n",
        "        n = torch.tanh(inp_n + r*self.hidden_h(agg_msgs))\n",
        "        hidden = (1 - i)*n + i*hidden\n",
        "\n",
        "        # Output MLP\n",
        "        pred = F.dropout(F.relu(self.out_fc1(hidden)), p=dropout_prob)\n",
        "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=dropout_prob)\n",
        "        pred = self.out_fc3(pred)\n",
        "\n",
        "        pred = inputs + pred\n",
        "\n",
        "        return pred, hidden"
      ],
      "metadata": {
        "id": "iuQqExnLXtOC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model"
      ],
      "metadata": {
        "id": "ShgCZ5FdsCDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(params):\n",
        "    if params['model_type'] == 'RNN':\n",
        "        model = SingleRNNBaseline(params)\n",
        "        print(\"dNRI MODEL: \",model)\n",
        "    if params['load_best_model']:\n",
        "        print(\"LOADING BEST MODEL\")\n",
        "        path = os.path.join(params['working_dir'], 'best_model')\n",
        "        model.load(path)\n",
        "    elif params['load_model']:\n",
        "        print(\"LOADING MODEL FROM SPECIFIED PATH\")\n",
        "        model.load(params['load_model'])\n",
        "    if params['gpu']:\n",
        "        model.cuda()\n",
        "    return model"
      ],
      "metadata": {
        "id": "rzUdzq4oWlju"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = SingleRNNBaseline(params)"
      ],
      "metadata": {
        "id": "reEU032Ou7Dk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "8Aw_sYeXsxYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, params, train_writer, val_writer):\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    val_batch_size = params.get('val_batch_size', batch_size)\n",
        "    if val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "    accumulate_steps = params.get('accumulate_steps')\n",
        "    training_scheduler = params.get('training_scheduler', None)\n",
        "    num_epochs = params.get('num_epochs', 100)\n",
        "    val_interval = params.get('val_interval', 1)\n",
        "    val_start = params.get('val_start', 0)\n",
        "    clip_grad = params.get('clip_grad', None)\n",
        "    clip_grad_norm = params.get('clip_grad_norm', None)\n",
        "    normalize_nll = params.get('normalize_nll', False)\n",
        "    normalize_kl = params.get('normalize_kl', False)\n",
        "    tune_on_nll = params.get('tune_on_nll', False)\n",
        "    verbose = params.get('verbose', False)\n",
        "    val_teacher_forcing = params.get('val_teacher_forcing', False)\n",
        "    continue_training = params.get('continue_training', False)\n",
        "    #train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    train_data_loader = DATA\n",
        "    #val_data_loader = DataLoader(val_data, batch_size=val_batch_size)\n",
        "    val_data_loader = VAL\n",
        "    lr = params['lr']\n",
        "    wd = params.get('wd', 0.1)\n",
        "    mom = params.get('mom', 0.9)\n",
        "    \n",
        "    #model_params = [param for param in model.parameters() if param.requires_grad]\n",
        "    model_params = model.parameters()\n",
        "    if params.get('use_adam', False):\n",
        "        opt = torch.optim.Adam(model_params, lr=lr, weight_decay=wd)\n",
        "    else:\n",
        "        opt = torch.optim.SGD(model_params, lr=lr, weight_decay=wd, momentum=mom)\n",
        "\n",
        "    working_dir = params['working_dir']\n",
        "    best_path = os.path.join(working_dir, 'best_model')\n",
        "    checkpoint_dir = os.path.join(working_dir, 'model_checkpoint')\n",
        "    training_path = os.path.join(working_dir, 'training_checkpoint')\n",
        "    if continue_training:\n",
        "        print(\"RESUMING TRAINING\")\n",
        "        model.load(checkpoint_dir)\n",
        "        train_params = torch.load(training_path)\n",
        "        start_epoch = train_params['epoch']\n",
        "        opt.load_state_dict(train_params['optimizer'])\n",
        "        best_val_result = train_params['best_val_result']\n",
        "        best_val_epoch = train_params['best_val_epoch']\n",
        "        print(\"STARTING EPOCH: \",start_epoch)\n",
        "    else:\n",
        "        start_epoch = 1\n",
        "        best_val_epoch = -1\n",
        "        best_val_result = 10000000\n",
        "    \n",
        "    training_scheduler = build_scheduler(opt, params)\n",
        "    end = start = 0 \n",
        "    #misc.seed(1)\n",
        "    result = []\n",
        "    for epoch in range(start_epoch, num_epochs+1):\n",
        "        print(\"EPOCH\", epoch, (end-start))\n",
        "        model.train()\n",
        "        model.train_percent = epoch / num_epochs\n",
        "        start = time.time() \n",
        "        for batch_ind, batch in enumerate(train_data_loader):\n",
        "            \n",
        "            inputs = batch['inputs']\n",
        "            #inputs = batch\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "            loss, loss_nll, loss_kl, logits, _ = model.calculate_loss(inputs, is_train=True, return_logits=True)\n",
        "            loss.backward()\n",
        "            if verbose:\n",
        "                print(\"\\tBATCH %d OF %d: %f, %f, %f\"%(batch_ind+1, len(train_data_loader), loss.item(), loss_nll.mean().item(), loss_kl.mean().item()))\n",
        "            if accumulate_steps == -1 or (batch_ind+1)%accumulate_steps == 0:\n",
        "                if verbose and accumulate_steps > 0:\n",
        "                    print(\"\\tUPDATING WEIGHTS\")\n",
        "                if clip_grad is not None:\n",
        "                    nn.utils.clip_grad_value_(model.parameters(), clip_grad)\n",
        "                elif clip_grad_norm is not None:\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)        \n",
        "                opt.step()\n",
        "                opt.zero_grad()\n",
        "                if accumulate_steps > 0 and accumulate_steps > len(train_data_loader) - batch_ind - 1:\n",
        "                    break\n",
        "            \n",
        "        if training_scheduler is not None:\n",
        "            training_scheduler.step()\n",
        "        \n",
        "        if train_writer is not None:\n",
        "            train_writer.add_scalar('loss', loss.item(), global_step=epoch)\n",
        "            if normalize_nll:\n",
        "                train_writer.add_scalar('NLL', loss_nll.mean().item(), global_step=epoch)\n",
        "            else:\n",
        "                train_writer.add_scalar('NLL', loss_nll.mean().item()/(inputs.size(1)*inputs.size(2)), global_step=epoch)\n",
        "            \n",
        "            train_writer.add_scalar(\"KL Divergence\", loss_kl.mean().item(), global_step=epoch)\n",
        "        model.eval()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        total_nll = 0\n",
        "        total_kl = 0\n",
        "        if verbose:\n",
        "            print(\"COMPUTING VAL LOSSES\")\n",
        "        with torch.no_grad():\n",
        "            for batch_ind, batch in enumerate(val_data_loader):\n",
        "                inputs = batch['inputs']\n",
        "                if gpu:\n",
        "                    inputs = inputs.cuda(non_blocking=True)\n",
        "                loss, loss_nll, loss_kl, logits, _ = model.calculate_loss(inputs, is_train=False, teacher_forcing=val_teacher_forcing, return_logits=True)\n",
        "                \n",
        "                total_kl += loss_kl.sum().item()\n",
        "                total_nll += loss_nll.sum().item()\n",
        "                if verbose:\n",
        "                  print(\"\\tVAL BATCH %d of %d: %f, %f\"%(batch_ind+1, len(val_data_loader), loss_nll.mean(), loss_kl.mean()))\n",
        "            \n",
        "        #total_kl /= len(val_data_loader)\n",
        "        #total_nll /= len(val_data_loader)\n",
        "        total_loss = model.kl_coef*total_kl + total_nll #TODO: this is a thing you fixed\n",
        "  \n",
        "        if val_writer is not None:\n",
        "            val_writer.add_scalar('loss', total_loss, global_step=epoch)\n",
        "            val_writer.add_scalar(\"NLL\", total_nll, global_step=epoch)\n",
        "            val_writer.add_scalar(\"KL Divergence\", total_kl, global_step=epoch)\n",
        "        if tune_on_nll:\n",
        "            tuning_loss = total_nll\n",
        "        else:\n",
        "            tuning_loss = total_loss\n",
        "        if tuning_loss < best_val_result:\n",
        "            best_val_epoch = epoch\n",
        "            best_val_result = tuning_loss\n",
        "            print(\"BEST VAL RESULT. SAVING MODEL...\")\n",
        "            #model.save(best_path)\n",
        "        model.save(checkpoint_dir)\n",
        "        torch.save({\n",
        "                    'epoch':epoch+1,\n",
        "                    'optimizer':opt.state_dict(),\n",
        "                    'best_val_result':best_val_result,\n",
        "                    'best_val_epoch':best_val_epoch,\n",
        "                   }, training_path)\n",
        "        print(\"EPOCH %d EVAL: \"%epoch)\n",
        "        print(\"\\tCURRENT VAL LOSS: %f\"%tuning_loss)\n",
        "        print(\"\\tBEST VAL LOSS:    %f\"%best_val_result)\n",
        "        print(\"\\tBEST VAL EPOCH:   %d\"%best_val_epoch)\n",
        "        result.append(tuning_loss)\n",
        "        end = time.time()\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "4vdJXF9FaLto"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Forward Prediction"
      ],
      "metadata": {
        "id": "24nOLAx_s3H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_forward_prediction(model, dataset, burn_in_steps, forward_pred_steps, params, return_total_errors=False):\n",
        "    dataset.return_edges = False\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, pin_memory=gpu)\n",
        "    model.eval()\n",
        "    total_se = 0\n",
        "    batch_count = 0\n",
        "    all_errors = []\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        with torch.no_grad():\n",
        "            model_inputs = inputs[:, :burn_in_steps]\n",
        "            gt_predictions = inputs[:, burn_in_steps:burn_in_steps+forward_pred_steps]\n",
        "            if gpu:\n",
        "                model_inputs = model_inputs.cuda(non_blocking=True)\n",
        "            model_preds = model.predict_future(model_inputs, forward_pred_steps).cpu()\n",
        "            batch_count += 1\n",
        "            if return_total_errors:\n",
        "                all_errors.append(F.mse_loss(model_preds, gt_predictions, reduction='none').view(model_preds.size(0), model_preds.size(1), -1).mean(dim=-1))\n",
        "            else:\n",
        "                total_se += F.mse_loss(model_preds, gt_predictions, reduction='none').view(model_preds.size(0), model_preds.size(1), -1).mean(dim=-1).sum(dim=0)\n",
        "    if return_total_errors:\n",
        "        return torch.cat(all_errors, dim=0)\n",
        "    else:\n",
        "        return total_se / len(dataset)\n",
        "\n",
        "def eval_forward_prediction_fixedwindow(model, dataset, burn_in_steps, forward_pred_steps, params, return_total_errors=False):\n",
        "    dataset.return_edges = False\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    data_loader = DataLoader(dataset, batch_size=1)\n",
        "    model.eval()\n",
        "    total_se = 0\n",
        "    batch_count = 0\n",
        "    all_errors = []\n",
        "    total_count = torch.zeros(forward_pred_steps)\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        print(\"BATCH IND %d OF %d\"%(batch_ind+1, len(data_loader)))\n",
        "        with torch.no_grad():\n",
        "\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "            model_preds = model.predict_future_fixedwindow(inputs, burn_in_steps, forward_pred_steps, batch_size).cpu()\n",
        "            for window_ind in range(model_preds.size(1)):\n",
        "                current_preds = model_preds[:, window_ind]\n",
        "                start_ind = burn_in_steps + window_ind\n",
        "                gt_preds = inputs[:, start_ind:start_ind + forward_pred_steps].cpu()\n",
        "                if gt_preds.size(1) < forward_pred_steps:\n",
        "                    mask = torch.cat([torch.ones(gt_preds.size(1)), torch.zeros(forward_pred_steps - gt_preds.size(1))])\n",
        "                    gt_preds = torch.cat([gt_preds, torch.zeros(gt_preds.size(0), forward_pred_steps-gt_preds.size(1), gt_preds.size(2), gt_preds.size(3))], dim=1)\n",
        "                else:\n",
        "                    mask = torch.ones(forward_pred_steps)\n",
        "                total_se += F.mse_loss(current_preds, gt_preds, reduction='none').view(current_preds.size(0), current_preds.size(1), -1).mean(dim=-1).sum(dim=0).cpu()*mask\n",
        "                total_count += mask\n",
        "\n",
        "    return total_se / total_count\n",
        "\n",
        "\n",
        "def eval_forward_prediction_dynamicvars(model, dataset, params):\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    collate_fn = params.get('collate_fn', None)\n",
        "    data_loader = DataLoader(dataset, batch_size=1, pin_memory=gpu, collate_fn=collate_fn)\n",
        "    model.eval()\n",
        "    total_se = 0\n",
        "    batch_count = 0\n",
        "    final_errors = torch.zeros(0)\n",
        "    final_counts = torch.zeros(0)\n",
        "    bad_count = 0\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        print(\"DATA POINT \",batch_ind)\n",
        "        inputs = batch['inputs']\n",
        "        gt_preds = inputs[0, 1:]\n",
        "        masks = batch['masks']\n",
        "        node_inds = batch.get('node_inds', None)\n",
        "        graph_info = batch.get('graph_info', None)\n",
        "        burn_in_masks = batch['burn_in_masks']\n",
        "        pred_masks = (masks.float() - burn_in_masks)[0, 1:]\n",
        "        with torch.no_grad():\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "                masks = masks.cuda(non_blocking=True)\n",
        "                burn_in_masks = burn_in_masks.cuda(non_blocking=True)\n",
        "            model_preds = model.predict_future(inputs, masks, node_inds, graph_info, burn_in_masks)[0].cpu()\n",
        "            max_len = pred_masks.sum(dim=0).max().int().item()\n",
        "            if max_len > len(final_errors):\n",
        "                final_errors = torch.cat([final_errors, torch.zeros(max_len - len(final_errors))])\n",
        "                final_counts = torch.cat([final_counts, torch.zeros(max_len - len(final_counts))])\n",
        "            for var in range(masks.size(-1)):\n",
        "                var_gt = gt_preds[:, var]\n",
        "                var_preds = model_preds[:, var]\n",
        "                var_pred_masks = pred_masks[:, var]\n",
        "                var_losses = F.mse_loss(var_preds, var_gt, reduction='none').mean(dim=-1)*var_pred_masks\n",
        "                tmp_inds = torch.nonzero(var_pred_masks)\n",
        "                if len(tmp_inds) == 0:\n",
        "                    continue\n",
        "                for i in range(len(tmp_inds)-1):\n",
        "                    if tmp_inds[i+1] - tmp_inds[i] != 1:\n",
        "                        bad_count += 1\n",
        "                        break\n",
        "                num_entries = var_pred_masks.sum().int().item()\n",
        "                final_errors[:num_entries] += var_losses[tmp_inds[0].item():tmp_inds[0].item()+num_entries]\n",
        "                final_counts[:num_entries] += var_pred_masks[tmp_inds[0]:tmp_inds[0]+num_entries]\n",
        "    print(\"FINAL BAD COUNT: \",bad_count)\n",
        "    return final_errors/final_counts, final_counts"
      ],
      "metadata": {
        "id": "RNpuii-haje_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "tmGdYg-HTaIs"
      },
      "outputs": [],
      "source": [
        "def eval_edges(model, dataset, params):\n",
        "\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    eval_metric = params.get('eval_metric')\n",
        "    num_edge_types = params['num_edge_types']\n",
        "    skip_first = params['skip_first']\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, pin_memory=gpu)\n",
        "    full_edge_count = 0.\n",
        "    model.eval()\n",
        "    correct_edges = 0.\n",
        "    edge_count = 0.\n",
        "    correct_0_edges = 0.\n",
        "    edge_0_count = 0.\n",
        "    correct_1_edges = 0.\n",
        "    edge_1_count = 0.\n",
        "\n",
        "    correct = num_predicted = num_gt = 0\n",
        "    all_edges = []\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        gt_edges = batch['edges'].long()\n",
        "        with torch.no_grad():\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "                gt_edges = gt_edges.cuda(non_blocking=True)\n",
        "\n",
        "            _, _, _, edges, _ = model.calculate_loss(inputs, is_train=False, return_logits=True)\n",
        "            edges = edges.argmax(dim=-1)\n",
        "            all_edges.append(edges.cpu())\n",
        "            if len(edges.shape) == 3 and len(gt_edges.shape) == 2:\n",
        "                gt_edges = gt_edges.unsqueeze(1).expand(gt_edges.size(0), edges.size(1), gt_edges.size(1))\n",
        "            elif len(gt_edges.shape) == 3 and len(edges.shape) == 2:\n",
        "                edges = edges.unsqueeze(1).expand(edges.size(0), gt_edges.size(1), edges.size(1))\n",
        "            if edges.size(1) == gt_edges.size(1) - 1:\n",
        "                gt_edges = gt_edges[:, :-1]\n",
        "            edge_count += edges.numel()\n",
        "            full_edge_count += gt_edges.numel()\n",
        "            correct_edges += ((edges == gt_edges)).sum().item()\n",
        "            edge_0_count += (gt_edges == 0).sum().item()\n",
        "            edge_1_count += (gt_edges == 1).sum().item()\n",
        "            correct_0_edges += ((edges == gt_edges)*(gt_edges == 0)).sum().item()\n",
        "            correct_1_edges += ((edges == gt_edges)*(gt_edges == 1)).sum().item()\n",
        "            correct += (edges*gt_edges).sum().item()\n",
        "            num_predicted += edges.sum().item()\n",
        "            num_gt += gt_edges.sum().item()\n",
        "    prec = correct / (num_predicted + 1e-8)\n",
        "    rec = correct / (num_gt + 1e-8)\n",
        "    f1 = 2*prec*rec / (prec+rec+1e-6)\n",
        "    all_edges = torch.cat(all_edges)\n",
        "    return f1, correct_edges / (full_edge_count + 1e-8), correct_0_edges / (edge_0_count + 1e-8), correct_1_edges / (edge_1_count + 1e-8), all_edges\n",
        "\n",
        "def plot_sample(model, dataset, num_samples, params):\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1)\n",
        "    use_gt_edges = params.get('use_gt_edges')\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size)\n",
        "    model.eval()\n",
        "    batch_count = 0\n",
        "    all_errors = []\n",
        "\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        gt_edges = batch.get('edges', None)\n",
        "        with torch.no_grad():\n",
        "            model_inputs = inputs[:, :burn_in_steps]\n",
        "            gt_predictions = inputs[:, burn_in_steps:burn_in_steps+forward_pred_steps]\n",
        "            if gpu:\n",
        "                model_inputs = model_inputs.cuda(non_blocking=True)\n",
        "                if gt_edges is not None and use_gt_edges:\n",
        "                    gt_edges = gt_edges.cuda(non_blocking=True)\n",
        "            if not use_gt_edges:\n",
        "                gt_edges=None\n",
        "            model_preds = model.predict_future(model_inputs, forward_pred_steps).cpu()\n",
        "            #total_se += F.mse_loss(model_preds, gt_predictions).item()\n",
        "            print(\"MSE: \", torch.nn.functional.mse_loss(model_preds, gt_predictions).item())\n",
        "            batch_count += 1\n",
        "        fig, ax = plt.subplots()\n",
        "        unnormalized_preds = dataset.unnormalize(model_preds)\n",
        "        unnormalized_gt = dataset.unnormalize(inputs)\n",
        "        def update(frame):\n",
        "            ax.clear()\n",
        "            ax.plot(unnormalized_gt[0, frame, 0, 0], unnormalized_gt[0, frame, 0, 1], 'bo')\n",
        "            ax.plot(unnormalized_gt[0, frame, 1, 0], unnormalized_gt[0, frame, 1, 1], 'ro')\n",
        "            ax.plot(unnormalized_gt[0, frame, 2, 0], unnormalized_gt[0, frame, 2, 1], 'go')\n",
        "            if frame >= params['burn_in_steps']:\n",
        "                tmp_fr = frame - params['burn_in_steps']\n",
        "                ax.plot(unnormalized_preds[0, tmp_fr, 0, 0], unnormalized_preds[0, tmp_fr, 0, 1], 'bo', alpha=0.5)\n",
        "                ax.plot(unnormalized_preds[0, tmp_fr, 1, 0], unnormalized_preds[0, tmp_fr, 1, 1], 'ro', alpha=0.5)\n",
        "                ax.plot(unnormalized_preds[0, tmp_fr, 2, 0], unnormalized_preds[0, tmp_fr, 2, 1], 'go', alpha=0.5)\n",
        "            ax.set_xlim(-6, 6)\n",
        "            ax.set_ylim(-6, 6)\n",
        "        ani = animation.FuncAnimation(fig, update, interval=100, frames=params['burn_in_steps']+forward_pred_steps)\n",
        "        path = os.path.join(params['working_dir'], 'pred_trajectory_%d.mp4'%batch_ind)\n",
        "        ani.save(path, codec='mpeg4')\n",
        "        if batch_count >= num_samples:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(params)\n",
        "if params['mode'] == 'train':\n",
        "    with build_writers(params['working_dir']) as (train_writer, val_writer):\n",
        "        result = train(model, train_data, val_data, params, train_writer, val_writer)\n",
        "\n",
        "elif params['mode'] == 'eval':\n",
        "    test_data = TEST\n",
        "    forward_pred = 50 - params['test_burn_in_steps']\n",
        "    test_mse  = eval_forward_prediction(model, test_data, params['test_burn_in_steps'], forward_pred, params)\n",
        "    path = os.path.join(params['working_dir'], params['error_out_name']%params['test_burn_in_steps'])\n",
        "    np.save(path, test_mse.cpu().numpy())\n",
        "    test_mse_1 = test_mse[0].item()\n",
        "    test_mse_15 = test_mse[14].item()\n",
        "    test_mse_25 = test_mse[24].item()\n",
        "    print(\"FORWARD PRED RESULTS:\")\n",
        "    print(\"\\t1 STEP: \",test_mse_1)\n",
        "    print(\"\\t15 STEP: \",test_mse_15)\n",
        "    print(\"\\t25 STEP: \",test_mse_25)\n",
        "\n",
        "\n",
        "    f1, all_acc, acc_0, acc_1, edges = eval_edges(model, val_data, params)\n",
        "    print(\"Val Edge results:\")\n",
        "    print(\"\\tF1: \",f1)\n",
        "    print(\"\\tAll predicted edge accuracy: \",all_acc)\n",
        "    print(\"\\tFirst Edge Acc: \",acc_0)\n",
        "    print(\"\\tSecond Edge Acc: \",acc_1)\n",
        "    out_dir = os.path.join(params['working_dir'], 'preds')\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    out_path = os.path.join(out_dir, 'encoder_edges.npy')\n",
        "    np.save(out_path, edges.numpy())\n",
        "\n",
        "    plot_sample(model, test_data, params['test_burn_in_steps'], params)\n",
        "\n",
        "elif params['mode'] == 'record_predictions':\n",
        "    model.eval()\n",
        "    burn_in = params['test_burn_in_steps']\n",
        "    forward_pred = 50 - params['test_burn_in_steps']\n",
        "    test_data = TEST\n",
        "    if params['subject_ind'] == -1:\n",
        "        val_data_loader = DataLoader(test_data, batch_size=params['batch_size'])\n",
        "        all_predictions = []\n",
        "        all_edges = []\n",
        "        for batch_ind,batch in enumerate(val_data_loader):\n",
        "            print(\"BATCH %d of %d\"%(batch_ind+1, len(val_data_loader)))\n",
        "            inputs = batch['inputs']\n",
        "            if params['gpu']:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "            with torch.no_grad():\n",
        "                predictions, edges = model.predict_future(inputs[:, :burn_in], forward_pred, return_edges=True, return_everything=True)\n",
        "                all_predictions.append(predictions)\n",
        "                all_edges.append(edges)\n",
        "        if params['error_suffix'] is not None:\n",
        "            out_path = os.path.join(params['working_dir'], 'preds/', 'all_test_subjects_%s.npy'%params['error_suffix'])\n",
        "        else:\n",
        "            out_path = os.path.join(params['working_dir'], 'preds/', 'all_test_subjects.npy')\n",
        "\n",
        "        predictions = torch.cat(all_predictions, dim=0)\n",
        "        edges = torch.cat(all_edges, dim=0)\n",
        "\n",
        "    else:\n",
        "        data = test_data[params['subject_ind']]\n",
        "        inputs = data['inputs'].unsqueeze(0)\n",
        "        if params['gpu']:\n",
        "            inputs = inputs.cuda(non_blocking=True)\n",
        "        with torch.no_grad():\n",
        "            predictions, edges = model.predict_future(inputs[:, :burn_in], forward_pred, return_edges=True, return_everything=True)\n",
        "            predictions = predictions.squeeze(0)\n",
        "            edges = edges.squeeze(0)\n",
        "        out_path = os.path.join(params['working_dir'], 'preds/', 'subject_%d.npy'%args.subject_ind)\n",
        "    tmp_dir = os.path.join(params['working_dir'], 'preds/')\n",
        "    if not os.path.exists(tmp_dir):\n",
        "        os.makedirs(tmp_dir)\n",
        "    torch.save([predictions.cpu(), edges.cpu()], out_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvqz0fqwYhEp",
        "outputId": "53f98520-4ba8-41e3-e96d-5f04309cfb12"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dNRI MODEL:  SingleRNNBaseline(\n",
            "  (rnn): LSTMCell(4, 256)\n",
            "  (out): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.0, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.0, inplace=False)\n",
            "    (6): Linear(in_features=256, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "EPOCH 1 0\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 1 EVAL: \n",
            "\tCURRENT VAL LOSS: 6364813.468750\n",
            "\tBEST VAL LOSS:    6364813.468750\n",
            "\tBEST VAL EPOCH:   1\n",
            "EPOCH 2 4.731487512588501\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 2 EVAL: \n",
            "\tCURRENT VAL LOSS: 3587084.546875\n",
            "\tBEST VAL LOSS:    3587084.546875\n",
            "\tBEST VAL EPOCH:   2\n",
            "EPOCH 3 4.572407245635986\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 3 EVAL: \n",
            "\tCURRENT VAL LOSS: 1666348.671875\n",
            "\tBEST VAL LOSS:    1666348.671875\n",
            "\tBEST VAL EPOCH:   3\n",
            "EPOCH 4 6.461230754852295\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 4 EVAL: \n",
            "\tCURRENT VAL LOSS: 577879.273438\n",
            "\tBEST VAL LOSS:    577879.273438\n",
            "\tBEST VAL EPOCH:   4\n",
            "EPOCH 5 5.518139600753784\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 5 EVAL: \n",
            "\tCURRENT VAL LOSS: 199774.099609\n",
            "\tBEST VAL LOSS:    199774.099609\n",
            "\tBEST VAL EPOCH:   5\n",
            "EPOCH 6 4.50679087638855\n",
            "EPOCH 6 EVAL: \n",
            "\tCURRENT VAL LOSS: 341476.025391\n",
            "\tBEST VAL LOSS:    199774.099609\n",
            "\tBEST VAL EPOCH:   5\n",
            "EPOCH 7 4.428390026092529\n",
            "EPOCH 7 EVAL: \n",
            "\tCURRENT VAL LOSS: 728356.101562\n",
            "\tBEST VAL LOSS:    199774.099609\n",
            "\tBEST VAL EPOCH:   5\n",
            "EPOCH 8 5.81419563293457\n",
            "EPOCH 8 EVAL: \n",
            "\tCURRENT VAL LOSS: 1110513.371094\n",
            "\tBEST VAL LOSS:    199774.099609\n",
            "\tBEST VAL EPOCH:   5\n",
            "EPOCH 9 4.4089436531066895\n",
            "EPOCH 9 EVAL: \n",
            "\tCURRENT VAL LOSS: 1334631.449219\n",
            "\tBEST VAL LOSS:    199774.099609\n",
            "\tBEST VAL EPOCH:   5\n",
            "EPOCH 10 4.981045722961426\n",
            "EPOCH 10 EVAL: \n",
            "\tCURRENT VAL LOSS: 1355501.542969\n",
            "\tBEST VAL LOSS:    199774.099609\n",
            "\tBEST VAL EPOCH:   5\n",
            "EPOCH 11 4.552398204803467\n",
            "EPOCH 11 EVAL: \n",
            "\tCURRENT VAL LOSS: 1210277.089844\n",
            "\tBEST VAL LOSS:    199774.099609\n",
            "\tBEST VAL EPOCH:   5\n",
            "EPOCH 12 4.434756755828857\n",
            "EPOCH 12 EVAL: \n",
            "\tCURRENT VAL LOSS: 972597.542969\n",
            "\tBEST VAL LOSS:    199774.099609\n",
            "\tBEST VAL EPOCH:   5\n",
            "EPOCH 13 4.506284236907959\n",
            "EPOCH 13 EVAL: \n",
            "\tCURRENT VAL LOSS: 711526.273438\n",
            "\tBEST VAL LOSS:    199774.099609\n",
            "\tBEST VAL EPOCH:   5\n",
            "EPOCH 14 4.409502744674683\n",
            "EPOCH 14 EVAL: \n",
            "\tCURRENT VAL LOSS: 477169.533203\n",
            "\tBEST VAL LOSS:    199774.099609\n",
            "\tBEST VAL EPOCH:   5\n",
            "EPOCH 15 4.48069953918457\n",
            "EPOCH 15 EVAL: \n",
            "\tCURRENT VAL LOSS: 296199.440430\n",
            "\tBEST VAL LOSS:    199774.099609\n",
            "\tBEST VAL EPOCH:   5\n",
            "EPOCH 16 4.516801834106445\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 16 EVAL: \n",
            "\tCURRENT VAL LOSS: 178500.611816\n",
            "\tBEST VAL LOSS:    178500.611816\n",
            "\tBEST VAL EPOCH:   16\n",
            "EPOCH 17 4.469253301620483\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 17 EVAL: \n",
            "\tCURRENT VAL LOSS: 122088.715332\n",
            "\tBEST VAL LOSS:    122088.715332\n",
            "\tBEST VAL EPOCH:   17\n",
            "EPOCH 18 4.4590163230896\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 18 EVAL: \n",
            "\tCURRENT VAL LOSS: 116830.382812\n",
            "\tBEST VAL LOSS:    116830.382812\n",
            "\tBEST VAL EPOCH:   18\n",
            "EPOCH 19 4.420910596847534\n",
            "EPOCH 19 EVAL: \n",
            "\tCURRENT VAL LOSS: 146689.507324\n",
            "\tBEST VAL LOSS:    116830.382812\n",
            "\tBEST VAL EPOCH:   18\n",
            "EPOCH 20 4.475960731506348\n",
            "EPOCH 20 EVAL: \n",
            "\tCURRENT VAL LOSS: 197681.011719\n",
            "\tBEST VAL LOSS:    116830.382812\n",
            "\tBEST VAL EPOCH:   18\n",
            "EPOCH 21 4.461681604385376\n",
            "EPOCH 21 EVAL: \n",
            "\tCURRENT VAL LOSS: 253545.741211\n",
            "\tBEST VAL LOSS:    116830.382812\n",
            "\tBEST VAL EPOCH:   18\n",
            "EPOCH 22 4.4691033363342285\n",
            "EPOCH 22 EVAL: \n",
            "\tCURRENT VAL LOSS: 301877.915039\n",
            "\tBEST VAL LOSS:    116830.382812\n",
            "\tBEST VAL EPOCH:   18\n",
            "EPOCH 23 4.394164323806763\n",
            "EPOCH 23 EVAL: \n",
            "\tCURRENT VAL LOSS: 333292.012695\n",
            "\tBEST VAL LOSS:    116830.382812\n",
            "\tBEST VAL EPOCH:   18\n",
            "EPOCH 24 4.416472434997559\n",
            "EPOCH 24 EVAL: \n",
            "\tCURRENT VAL LOSS: 343301.402344\n",
            "\tBEST VAL LOSS:    116830.382812\n",
            "\tBEST VAL EPOCH:   18\n",
            "EPOCH 25 4.449500560760498\n",
            "EPOCH 25 EVAL: \n",
            "\tCURRENT VAL LOSS: 331695.098633\n",
            "\tBEST VAL LOSS:    116830.382812\n",
            "\tBEST VAL EPOCH:   18\n",
            "EPOCH 26 4.414880752563477\n",
            "EPOCH 26 EVAL: \n",
            "\tCURRENT VAL LOSS: 301245.852539\n",
            "\tBEST VAL LOSS:    116830.382812\n",
            "\tBEST VAL EPOCH:   18\n",
            "EPOCH 27 5.72713303565979\n",
            "EPOCH 27 EVAL: \n",
            "\tCURRENT VAL LOSS: 257618.005859\n",
            "\tBEST VAL LOSS:    116830.382812\n",
            "\tBEST VAL EPOCH:   18\n",
            "EPOCH 28 4.409827709197998\n",
            "EPOCH 28 EVAL: \n",
            "\tCURRENT VAL LOSS: 208670.197266\n",
            "\tBEST VAL LOSS:    116830.382812\n",
            "\tBEST VAL EPOCH:   18\n",
            "EPOCH 29 4.441481590270996\n",
            "EPOCH 29 EVAL: \n",
            "\tCURRENT VAL LOSS: 162009.430176\n",
            "\tBEST VAL LOSS:    116830.382812\n",
            "\tBEST VAL EPOCH:   18\n",
            "EPOCH 30 4.457118511199951\n",
            "EPOCH 30 EVAL: \n",
            "\tCURRENT VAL LOSS: 123890.400391\n",
            "\tBEST VAL LOSS:    116830.382812\n",
            "\tBEST VAL EPOCH:   18\n",
            "EPOCH 31 4.522339105606079\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 31 EVAL: \n",
            "\tCURRENT VAL LOSS: 98233.860840\n",
            "\tBEST VAL LOSS:    98233.860840\n",
            "\tBEST VAL EPOCH:   31\n",
            "EPOCH 32 4.455518007278442\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 32 EVAL: \n",
            "\tCURRENT VAL LOSS: 86242.366699\n",
            "\tBEST VAL LOSS:    86242.366699\n",
            "\tBEST VAL EPOCH:   32\n",
            "EPOCH 33 4.441216230392456\n",
            "EPOCH 33 EVAL: \n",
            "\tCURRENT VAL LOSS: 86472.933594\n",
            "\tBEST VAL LOSS:    86242.366699\n",
            "\tBEST VAL EPOCH:   32\n",
            "EPOCH 34 4.421361446380615\n",
            "EPOCH 34 EVAL: \n",
            "\tCURRENT VAL LOSS: 95278.622070\n",
            "\tBEST VAL LOSS:    86242.366699\n",
            "\tBEST VAL EPOCH:   32\n",
            "EPOCH 35 4.395214319229126\n",
            "EPOCH 35 EVAL: \n",
            "\tCURRENT VAL LOSS: 107784.563477\n",
            "\tBEST VAL LOSS:    86242.366699\n",
            "\tBEST VAL EPOCH:   32\n",
            "EPOCH 36 4.380030870437622\n",
            "EPOCH 36 EVAL: \n",
            "\tCURRENT VAL LOSS: 119350.893066\n",
            "\tBEST VAL LOSS:    86242.366699\n",
            "\tBEST VAL EPOCH:   32\n",
            "EPOCH 37 4.359705686569214\n",
            "EPOCH 37 EVAL: \n",
            "\tCURRENT VAL LOSS: 126688.854004\n",
            "\tBEST VAL LOSS:    86242.366699\n",
            "\tBEST VAL EPOCH:   32\n",
            "EPOCH 38 4.455095052719116\n",
            "EPOCH 38 EVAL: \n",
            "\tCURRENT VAL LOSS: 128285.147461\n",
            "\tBEST VAL LOSS:    86242.366699\n",
            "\tBEST VAL EPOCH:   32\n",
            "EPOCH 39 4.423961877822876\n",
            "EPOCH 39 EVAL: \n",
            "\tCURRENT VAL LOSS: 124369.130859\n",
            "\tBEST VAL LOSS:    86242.366699\n",
            "\tBEST VAL EPOCH:   32\n",
            "EPOCH 40 4.383698463439941\n",
            "EPOCH 40 EVAL: \n",
            "\tCURRENT VAL LOSS: 116404.612305\n",
            "\tBEST VAL LOSS:    86242.366699\n",
            "\tBEST VAL EPOCH:   32\n",
            "EPOCH 41 4.415334939956665\n",
            "EPOCH 41 EVAL: \n",
            "\tCURRENT VAL LOSS: 106484.859375\n",
            "\tBEST VAL LOSS:    86242.366699\n",
            "\tBEST VAL EPOCH:   32\n",
            "EPOCH 42 4.427555322647095\n",
            "EPOCH 42 EVAL: \n",
            "\tCURRENT VAL LOSS: 96641.746582\n",
            "\tBEST VAL LOSS:    86242.366699\n",
            "\tBEST VAL EPOCH:   32\n",
            "EPOCH 43 4.484783411026001\n",
            "EPOCH 43 EVAL: \n",
            "\tCURRENT VAL LOSS: 88730.638916\n",
            "\tBEST VAL LOSS:    86242.366699\n",
            "\tBEST VAL EPOCH:   32\n",
            "EPOCH 44 4.500280380249023\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 44 EVAL: \n",
            "\tCURRENT VAL LOSS: 83911.285156\n",
            "\tBEST VAL LOSS:    83911.285156\n",
            "\tBEST VAL EPOCH:   44\n",
            "EPOCH 45 4.521822214126587\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 45 EVAL: \n",
            "\tCURRENT VAL LOSS: 82626.849121\n",
            "\tBEST VAL LOSS:    82626.849121\n",
            "\tBEST VAL EPOCH:   45\n",
            "EPOCH 46 4.400078535079956\n",
            "EPOCH 46 EVAL: \n",
            "\tCURRENT VAL LOSS: 84588.532959\n",
            "\tBEST VAL LOSS:    82626.849121\n",
            "\tBEST VAL EPOCH:   45\n",
            "EPOCH 47 4.422574043273926\n",
            "EPOCH 47 EVAL: \n",
            "\tCURRENT VAL LOSS: 88776.326172\n",
            "\tBEST VAL LOSS:    82626.849121\n",
            "\tBEST VAL EPOCH:   45\n",
            "EPOCH 48 4.435030937194824\n",
            "EPOCH 48 EVAL: \n",
            "\tCURRENT VAL LOSS: 93617.371582\n",
            "\tBEST VAL LOSS:    82626.849121\n",
            "\tBEST VAL EPOCH:   45\n",
            "EPOCH 49 4.453161954879761\n",
            "EPOCH 49 EVAL: \n",
            "\tCURRENT VAL LOSS: 97690.224609\n",
            "\tBEST VAL LOSS:    82626.849121\n",
            "\tBEST VAL EPOCH:   45\n",
            "EPOCH 50 4.512023210525513\n",
            "EPOCH 50 EVAL: \n",
            "\tCURRENT VAL LOSS: 99935.900391\n",
            "\tBEST VAL LOSS:    82626.849121\n",
            "\tBEST VAL EPOCH:   45\n",
            "EPOCH 51 4.462054014205933\n",
            "EPOCH 51 EVAL: \n",
            "\tCURRENT VAL LOSS: 100156.623535\n",
            "\tBEST VAL LOSS:    82626.849121\n",
            "\tBEST VAL EPOCH:   45\n",
            "EPOCH 52 4.5121190547943115\n",
            "EPOCH 52 EVAL: \n",
            "\tCURRENT VAL LOSS: 98487.267578\n",
            "\tBEST VAL LOSS:    82626.849121\n",
            "\tBEST VAL EPOCH:   45\n",
            "EPOCH 53 4.4574220180511475\n",
            "EPOCH 53 EVAL: \n",
            "\tCURRENT VAL LOSS: 95472.889648\n",
            "\tBEST VAL LOSS:    82626.849121\n",
            "\tBEST VAL EPOCH:   45\n",
            "EPOCH 54 4.479825973510742\n",
            "EPOCH 54 EVAL: \n",
            "\tCURRENT VAL LOSS: 91820.251953\n",
            "\tBEST VAL LOSS:    82626.849121\n",
            "\tBEST VAL EPOCH:   45\n",
            "EPOCH 55 6.02869439125061\n",
            "EPOCH 55 EVAL: \n",
            "\tCURRENT VAL LOSS: 87942.775391\n",
            "\tBEST VAL LOSS:    82626.849121\n",
            "\tBEST VAL EPOCH:   45\n",
            "EPOCH 56 5.659936189651489\n",
            "EPOCH 56 EVAL: \n",
            "\tCURRENT VAL LOSS: 84705.605225\n",
            "\tBEST VAL LOSS:    82626.849121\n",
            "\tBEST VAL EPOCH:   45\n",
            "EPOCH 57 4.409197807312012\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 57 EVAL: \n",
            "\tCURRENT VAL LOSS: 82445.243896\n",
            "\tBEST VAL LOSS:    82445.243896\n",
            "\tBEST VAL EPOCH:   57\n",
            "EPOCH 58 4.384092092514038\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 58 EVAL: \n",
            "\tCURRENT VAL LOSS: 81676.732910\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 59 4.400979280471802\n",
            "EPOCH 59 EVAL: \n",
            "\tCURRENT VAL LOSS: 82108.059082\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 60 4.360718727111816\n",
            "EPOCH 60 EVAL: \n",
            "\tCURRENT VAL LOSS: 82773.593750\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 61 4.466734170913696\n",
            "EPOCH 61 EVAL: \n",
            "\tCURRENT VAL LOSS: 83243.463135\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 62 4.372623920440674\n",
            "EPOCH 62 EVAL: \n",
            "\tCURRENT VAL LOSS: 83549.370850\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 63 4.438675403594971\n",
            "EPOCH 63 EVAL: \n",
            "\tCURRENT VAL LOSS: 83481.443604\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 64 4.454715728759766\n",
            "EPOCH 64 EVAL: \n",
            "\tCURRENT VAL LOSS: 83156.058350\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 65 4.618360757827759\n",
            "EPOCH 65 EVAL: \n",
            "\tCURRENT VAL LOSS: 82739.491211\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 66 4.569270133972168\n",
            "EPOCH 66 EVAL: \n",
            "\tCURRENT VAL LOSS: 82355.522461\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 67 4.6821277141571045\n",
            "EPOCH 67 EVAL: \n",
            "\tCURRENT VAL LOSS: 82114.330322\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 68 4.69161057472229\n",
            "EPOCH 68 EVAL: \n",
            "\tCURRENT VAL LOSS: 82245.987061\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 69 4.562241315841675\n",
            "EPOCH 69 EVAL: \n",
            "\tCURRENT VAL LOSS: 82660.240234\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 70 4.537543773651123\n",
            "EPOCH 70 EVAL: \n",
            "\tCURRENT VAL LOSS: 83101.755859\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 71 4.722912073135376\n",
            "EPOCH 71 EVAL: \n",
            "\tCURRENT VAL LOSS: 83372.491699\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 72 4.6598961353302\n",
            "EPOCH 72 EVAL: \n",
            "\tCURRENT VAL LOSS: 83405.090820\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 73 4.491820812225342\n",
            "EPOCH 73 EVAL: \n",
            "\tCURRENT VAL LOSS: 83221.772705\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 74 4.57841157913208\n",
            "EPOCH 74 EVAL: \n",
            "\tCURRENT VAL LOSS: 82920.560791\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 75 4.617823600769043\n",
            "EPOCH 75 EVAL: \n",
            "\tCURRENT VAL LOSS: 82682.282715\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 76 4.516643524169922\n",
            "EPOCH 76 EVAL: \n",
            "\tCURRENT VAL LOSS: 82418.109619\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 77 4.514334440231323\n",
            "EPOCH 77 EVAL: \n",
            "\tCURRENT VAL LOSS: 82129.360107\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 78 4.543713331222534\n",
            "EPOCH 78 EVAL: \n",
            "\tCURRENT VAL LOSS: 81864.117920\n",
            "\tBEST VAL LOSS:    81676.732910\n",
            "\tBEST VAL EPOCH:   58\n",
            "EPOCH 79 4.662192106246948\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 79 EVAL: \n",
            "\tCURRENT VAL LOSS: 81597.530762\n",
            "\tBEST VAL LOSS:    81597.530762\n",
            "\tBEST VAL EPOCH:   79\n",
            "EPOCH 80 4.525348424911499\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 80 EVAL: \n",
            "\tCURRENT VAL LOSS: 81592.904297\n",
            "\tBEST VAL LOSS:    81592.904297\n",
            "\tBEST VAL EPOCH:   80\n",
            "EPOCH 81 4.5342535972595215\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 81 EVAL: \n",
            "\tCURRENT VAL LOSS: 81561.299072\n",
            "\tBEST VAL LOSS:    81561.299072\n",
            "\tBEST VAL EPOCH:   81\n",
            "EPOCH 82 4.509490013122559\n",
            "EPOCH 82 EVAL: \n",
            "\tCURRENT VAL LOSS: 81596.920166\n",
            "\tBEST VAL LOSS:    81561.299072\n",
            "\tBEST VAL EPOCH:   81\n",
            "EPOCH 83 4.55546760559082\n",
            "EPOCH 83 EVAL: \n",
            "\tCURRENT VAL LOSS: 81667.899170\n",
            "\tBEST VAL LOSS:    81561.299072\n",
            "\tBEST VAL EPOCH:   81\n",
            "EPOCH 84 4.435917615890503\n",
            "EPOCH 84 EVAL: \n",
            "\tCURRENT VAL LOSS: 81741.514160\n",
            "\tBEST VAL LOSS:    81561.299072\n",
            "\tBEST VAL EPOCH:   81\n",
            "EPOCH 85 4.560471057891846\n",
            "EPOCH 85 EVAL: \n",
            "\tCURRENT VAL LOSS: 81780.457520\n",
            "\tBEST VAL LOSS:    81561.299072\n",
            "\tBEST VAL EPOCH:   81\n",
            "EPOCH 86 4.733372926712036\n",
            "EPOCH 86 EVAL: \n",
            "\tCURRENT VAL LOSS: 81775.691406\n",
            "\tBEST VAL LOSS:    81561.299072\n",
            "\tBEST VAL EPOCH:   81\n",
            "EPOCH 87 4.725484848022461\n",
            "EPOCH 87 EVAL: \n",
            "\tCURRENT VAL LOSS: 81750.947998\n",
            "\tBEST VAL LOSS:    81561.299072\n",
            "\tBEST VAL EPOCH:   81\n",
            "EPOCH 88 4.640740633010864\n",
            "EPOCH 88 EVAL: \n",
            "\tCURRENT VAL LOSS: 81754.127930\n",
            "\tBEST VAL LOSS:    81561.299072\n",
            "\tBEST VAL EPOCH:   81\n",
            "EPOCH 89 4.451344013214111\n",
            "EPOCH 89 EVAL: \n",
            "\tCURRENT VAL LOSS: 81820.660400\n",
            "\tBEST VAL LOSS:    81561.299072\n",
            "\tBEST VAL EPOCH:   81\n",
            "EPOCH 90 4.573952674865723\n",
            "EPOCH 90 EVAL: \n",
            "\tCURRENT VAL LOSS: 81900.715088\n",
            "\tBEST VAL LOSS:    81561.299072\n",
            "\tBEST VAL EPOCH:   81\n",
            "EPOCH 91 4.458402633666992\n",
            "EPOCH 91 EVAL: \n",
            "\tCURRENT VAL LOSS: 81926.201172\n",
            "\tBEST VAL LOSS:    81561.299072\n",
            "\tBEST VAL EPOCH:   81\n",
            "EPOCH 92 4.478066444396973\n",
            "EPOCH 92 EVAL: \n",
            "\tCURRENT VAL LOSS: 81836.383789\n",
            "\tBEST VAL LOSS:    81561.299072\n",
            "\tBEST VAL EPOCH:   81\n",
            "EPOCH 93 4.566796064376831\n",
            "EPOCH 93 EVAL: \n",
            "\tCURRENT VAL LOSS: 81636.608398\n",
            "\tBEST VAL LOSS:    81561.299072\n",
            "\tBEST VAL EPOCH:   81\n",
            "EPOCH 94 4.649946451187134\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 94 EVAL: \n",
            "\tCURRENT VAL LOSS: 81403.755371\n",
            "\tBEST VAL LOSS:    81403.755371\n",
            "\tBEST VAL EPOCH:   94\n",
            "EPOCH 95 5.048618793487549\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 95 EVAL: \n",
            "\tCURRENT VAL LOSS: 81238.371582\n",
            "\tBEST VAL LOSS:    81238.371582\n",
            "\tBEST VAL EPOCH:   95\n",
            "EPOCH 96 5.329691648483276\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 96 EVAL: \n",
            "\tCURRENT VAL LOSS: 81205.349854\n",
            "\tBEST VAL LOSS:    81205.349854\n",
            "\tBEST VAL EPOCH:   96\n",
            "EPOCH 97 4.503856897354126\n",
            "EPOCH 97 EVAL: \n",
            "\tCURRENT VAL LOSS: 81277.937988\n",
            "\tBEST VAL LOSS:    81205.349854\n",
            "\tBEST VAL EPOCH:   96\n",
            "EPOCH 98 4.620985746383667\n",
            "EPOCH 98 EVAL: \n",
            "\tCURRENT VAL LOSS: 81290.542969\n",
            "\tBEST VAL LOSS:    81205.349854\n",
            "\tBEST VAL EPOCH:   96\n",
            "EPOCH 99 4.491544008255005\n",
            "EPOCH 99 EVAL: \n",
            "\tCURRENT VAL LOSS: 81292.354736\n",
            "\tBEST VAL LOSS:    81205.349854\n",
            "\tBEST VAL EPOCH:   96\n",
            "EPOCH 100 4.401360988616943\n",
            "EPOCH 100 EVAL: \n",
            "\tCURRENT VAL LOSS: 81301.946533\n",
            "\tBEST VAL LOSS:    81205.349854\n",
            "\tBEST VAL EPOCH:   96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "plt.plot(result)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "MEaTSzgFx1rH",
        "outputId": "59d23c18-5029-482b-9d9e-a9524fccabea"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGAE Jax"
      ],
      "metadata": {
        "id": "i5-lp7bUtNH8"
      }
    }
  ]
}