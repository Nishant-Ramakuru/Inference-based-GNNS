{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nishant-Ramakuru/Inference-based-GNNS/blob/main/simulations/RNN_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Functions\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.colors as mcolors\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "import argparse, os, time\n",
        "from torch.nn import init\n",
        "import math\n",
        "import networkx as nx\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8Tm6GblxoZWs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXmvpJedOnr",
        "outputId": "0110ce94-4fc8-4ae3-f031-f92573dde1bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters"
      ],
      "metadata": {
        "id": "1kxH7lSHpbAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {}\n",
        "tau = 1\n",
        "params['use_adam'] = True\n",
        "params['test_burn_in_steps'] =0\n",
        "params['num_time_steps'] = 50\n",
        "params['data_path']= '/content/MyDrive/GNNs'\n",
        "params['num_train'] = 3000\n",
        "params['num_val'] = 1000\n",
        "params['num_test']= 1000\n",
        "params['load_model'] = False\n",
        "params['load_best_model'] = False\n",
        "params['model_type'] = 'RNN'\n",
        "#params['graph_type'] = ['static', 'dynamic']\n",
        "params['graph_type'] = 'dynamic'\n",
        "params['encoder_no_factor'] = True\n",
        "params['num_epochs'] = 10\n",
        "params['num_vars'] = params['num_agents'] = 10\n",
        "params['input_noise_type'] = 'none'\n",
        "params['input_size'] = 4\n",
        "params['nll_loss_type'] = 'gaussian'\n",
        "params['prior_variance'] = 5e-5\n",
        "params['batch_size'] = 64\n",
        "params['val_batch_size'] = 64\n",
        "params['accumulate_steps'] = 40\n",
        "params['num_edge_types'] = 1\n",
        "params['encoder_dropout'] = 0.0\n",
        "params['encoder_hidden'] = 256\n",
        "params['encoder_rnn_hidden'] = 64\n",
        "params['encoder_rnn_type'] = 'lstm'\n",
        "params['decoder_rnn_type'] = 'lstm'\n",
        "params['encoder_mlp_num_layers'] = 1\n",
        "params['encoder_mlp_hidden'] = 256\n",
        "params['prior_num_layers'] = 1\n",
        "params['prior_hidden_size'] = 256\n",
        "params['gpu'] = False\n",
        "params['decoder_hidden'] = 256\n",
        "params['skip_first'] = False\n",
        "params['decoder_dropout'] = 0.0\n",
        "params['decoder_type'] = None\n",
        "params['lr'] = 5e-4\n",
        "params['mode'] = \"train\"\n",
        "\n",
        "params['working_dir'] =params['output_dir'] =  ('/content/MyDrive/GNNs')"
      ],
      "metadata": {
        "id": "hu42uHhigCwW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "id": "kfqJoGAgpd_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle(\"/content/drive/MyDrive/GNNs/boids_buffer_10_final1.csv\")"
      ],
      "metadata": {
        "id": "XXXXqOdbc1as",
        "outputId": "049c3fa3-e82b-4e35-9177-b5884aa0af82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo0__BlW4zLO",
        "outputId": "8284cf87-3bb9-4584-98e0-4c17b59b81ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Sx9crDBZdld5",
        "outputId": "04cbac67-dd63-4489-bd10-4e8eb782e5a5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   R  \\\n",
              "0  [[1077.9397, 666.84686], [856.4423, 1137.0732]...   \n",
              "1  [[1073.0123, 667.6944], [856.3285, 1142.072], ...   \n",
              "2  [[1068.0665, 668.4283], [856.2146, 1147.0707],...   \n",
              "3  [[1063.112, 669.102], [856.10077, 1152.0693], ...   \n",
              "4  [[1058.1525, 669.736], [855.9869, 1157.0681], ...   \n",
              "\n",
              "                                               theta  \\\n",
              "0  [2.9513416, 1.5935696, 4.8110423, 0.96409255, ...   \n",
              "1  [2.9859188, 1.5935696, 4.8110423, 0.96409255, ...   \n",
              "2  [3.0014527, 1.5935696, 4.8110423, 0.96409255, ...   \n",
              "3  [3.0109863, 1.5935696, 4.8110423, 0.96409255, ...   \n",
              "4  [3.0177057, 1.5935696, 4.8110423, 0.96409255, ...   \n",
              "\n",
              "                                            velocity  \\\n",
              "0  [[-4.927397, 0.8475409], [-0.11385684, 4.99870...   \n",
              "1  [[-4.9457974, 0.7338834], [-0.11385684, 4.9987...   \n",
              "2  [[-4.954386, 0.6736986], [-0.11385684, 4.99870...   \n",
              "3  [[-4.9596305, 0.6340109], [-0.11385684, 4.9987...   \n",
              "4  [[-4.963271, 0.6048854], [-0.11385684, 4.99870...   \n",
              "\n",
              "                                          trajectory  \n",
              "0  [[1077.9397, 666.84686, -4.927397, 0.8475409],...  \n",
              "1  [[1073.0123, 667.6944, -4.9457974, 0.7338834],...  \n",
              "2  [[1068.0665, 668.4283, -4.954386, 0.6736986], ...  \n",
              "3  [[1063.112, 669.102, -4.9596305, 0.6340109], [...  \n",
              "4  [[1058.1525, 669.736, -4.963271, 0.6048854], [...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a172a9a0-dedb-492f-88d8-e9af68a38c5a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R</th>\n",
              "      <th>theta</th>\n",
              "      <th>velocity</th>\n",
              "      <th>trajectory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[1077.9397, 666.84686], [856.4423, 1137.0732]...</td>\n",
              "      <td>[2.9513416, 1.5935696, 4.8110423, 0.96409255, ...</td>\n",
              "      <td>[[-4.927397, 0.8475409], [-0.11385684, 4.99870...</td>\n",
              "      <td>[[1077.9397, 666.84686, -4.927397, 0.8475409],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[1073.0123, 667.6944], [856.3285, 1142.072], ...</td>\n",
              "      <td>[2.9859188, 1.5935696, 4.8110423, 0.96409255, ...</td>\n",
              "      <td>[[-4.9457974, 0.7338834], [-0.11385684, 4.9987...</td>\n",
              "      <td>[[1073.0123, 667.6944, -4.9457974, 0.7338834],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[1068.0665, 668.4283], [856.2146, 1147.0707],...</td>\n",
              "      <td>[3.0014527, 1.5935696, 4.8110423, 0.96409255, ...</td>\n",
              "      <td>[[-4.954386, 0.6736986], [-0.11385684, 4.99870...</td>\n",
              "      <td>[[1068.0665, 668.4283, -4.954386, 0.6736986], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[1063.112, 669.102], [856.10077, 1152.0693], ...</td>\n",
              "      <td>[3.0109863, 1.5935696, 4.8110423, 0.96409255, ...</td>\n",
              "      <td>[[-4.9596305, 0.6340109], [-0.11385684, 4.9987...</td>\n",
              "      <td>[[1063.112, 669.102, -4.9596305, 0.6340109], [...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[1058.1525, 669.736], [855.9869, 1157.0681], ...</td>\n",
              "      <td>[3.0177057, 1.5935696, 4.8110423, 0.96409255, ...</td>\n",
              "      <td>[[-4.963271, 0.6048854], [-0.11385684, 4.99870...</td>\n",
              "      <td>[[1058.1525, 669.736, -4.963271, 0.6048854], [...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a172a9a0-dedb-492f-88d8-e9af68a38c5a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a172a9a0-dedb-492f-88d8-e9af68a38c5a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a172a9a0-dedb-492f-88d8-e9af68a38c5a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for w in range(len(df)):\n",
        "  \n",
        "  state = np.array(df.R[w])\n",
        "  D = list()\n",
        "  for a,i in enumerate(state):\n",
        "    d= []\n",
        "    for b,j in enumerate(state):\n",
        "      eDistance = math.hypot(i[0] - j[0], i[1] - j[1])\n",
        "      if a == b:\n",
        "        d.append(0)\n",
        "      elif int(eDistance) <= 200:\n",
        "        d.append(1)\n",
        "      else:\n",
        "        d.append(0)\n",
        "    D.append(d)\n",
        "\n",
        "  data.append(np.array(D))\n",
        "edge_data = np.array(data)\n",
        "all_data = np.array(list(df.trajectory))\n",
        "\n",
        "adj_array = []\n",
        "#print(edge_data.shape)\n",
        "for time_step in range(len(edge_data)):\n",
        "  edge = []\n",
        "  for i in range(len(edge_data[0])):\n",
        "    edge = edge + list(list(edge_data[time_step][i][:i])+list(edge_data[time_step][i][i+1:]))\n",
        "    \n",
        "  #print(len(edge[0].shape))\n",
        "  adj_array.append(edge)\n",
        "\n",
        "edge_data = np.array(adj_array)"
      ],
      "metadata": {
        "id": "DvNzNXDsmHrD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = np.stack(all_data)\n",
        "train_data = torch.FloatTensor(all_data[:params['num_train']])\n",
        "val_data = torch.FloatTensor(all_data[params['num_train']:params['num_train']+params['num_val']])\n",
        "test_data = torch.FloatTensor(all_data[params['num_train']+params['num_val']:params['num_train']+params['num_val']+params['num_test']])\n",
        "\n",
        "train_edges = torch.FloatTensor(edge_data[:params['num_train']])\n",
        "val_edges = torch.FloatTensor(edge_data[params['num_train']:params['num_train']+params['num_val']])\n",
        "test_edges = torch.FloatTensor(edge_data[params['num_train']+params['num_val']:params['num_train']+params['num_val']+params['num_test']])"
      ],
      "metadata": {
        "id": "sMqcjpLRea24"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del all_data, df,edge_data, data"
      ],
      "metadata": {
        "id": "d9nZE2UU9tCL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Shape:\", train_data.shape,\"\\n\", \n",
        "       \"Val Shape:\", val_data.shape,\"\\n\",\n",
        "      \"Test Shape:\", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UGCd5PmDRff",
        "outputId": "813a72dc-147c-4ba5-c21d-93906d0f8c79"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Shape: torch.Size([3000, 10, 4]) \n",
            " Val Shape: torch.Size([1000, 10, 4]) \n",
            " Test Shape: torch.Size([1000, 10, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.reshape([int(params[\"num_train\"]/50),50,10,4])\n",
        "val_data = val_data.reshape([int(params[\"num_val\"]/50),50,10,4])\n",
        "test_data = test_data.reshape([int(params[\"num_test\"]/50),50,10,4])\n",
        "\n",
        "train_edges = train_edges.reshape([int(params['num_train']/50),50,90])\n",
        "val_edges = val_edges.reshape([int(params['num_val']/50),50,90])\n",
        "test_edges = test_edges.reshape([int(params['num_test']/50),50,90])"
      ],
      "metadata": {
        "id": "a5aGYElZbFo_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torch.nn.functional.normalize(train_data)\n",
        "val_data = torch.nn.functional.normalize(val_data)\n",
        "test_data = torch.nn.functional.normalize(test_data)"
      ],
      "metadata": {
        "id": "lRvZM3sW8hCa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA = []\n",
        "\n",
        "for i in range(train_data.shape[0]):\n",
        "  DATA.append({'inputs':train_data[i].reshape([1,50,10,4]),'edges':train_edges[i].reshape([1,50,90])})\n",
        "\n",
        "VAL = []\n",
        "\n",
        "for i in range(val_data.shape[0]):\n",
        "  VAL.append({'inputs':val_data[i].reshape([1,50,10,4]),'edges':val_edges[i].reshape([1,50,90])})\n",
        "\n",
        "TEST = []\n",
        "\n",
        "for i in range(test_data.shape[0]):\n",
        "  TEST.append({'inputs':test_data[i].reshape([1,50,10,4]),'edges':test_edges[i].reshape([1,50,90])})"
      ],
      "metadata": {
        "id": "rw95XbyRx3XM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "def seed(seed_val):\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    random.seed(seed_val)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "def build_scheduler(opt, params):\n",
        "    lr_decay_factor = params.get('lr_decay_factor')\n",
        "    lr_decay_steps = params.get('lr_decay_steps')\n",
        "    if lr_decay_factor:\n",
        "        return torch.optim.lr_scheduler.StepLR(opt, lr_decay_steps, lr_decay_factor)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "class build_writers:\n",
        "    def __init__(self, working_dir, is_test=False):\n",
        "        self.writer_dir = os.path.join(working_dir, 'logs/')\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __enter__(self):\n",
        "        train_writer_dir = os.path.join(self.writer_dir, 'train')\n",
        "        val_writer_dir = os.path.join(self.writer_dir, 'val')\n",
        "        self.train_writer = SummaryWriter(train_writer_dir)\n",
        "        self.val_writer = SummaryWriter(val_writer_dir)\n",
        "        if self.is_test:\n",
        "            test_writer_dir = os.path.join(self.writer_dir, 'test')\n",
        "            self.test_writer = SummaryWriter(test_writer_dir)\n",
        "            return self.train_writer, self.val_writer, self.test_writer\n",
        "        else:\n",
        "            return self.train_writer, self.val_writer\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        self.train_writer.close()\n",
        "        self.val_writer.close()\n",
        "        if self.is_test:\n",
        "            self.test_writer.close()\n",
        "\n",
        "# Code from NRI.\n",
        "def normalize(data):\n",
        "\treturn (data-(torch.mean(data))/ (torch.std(data)))\n",
        "\n",
        "\n",
        "def unnormalize(data, data_max, data_min):\n",
        "\treturn (data + 1) * (data_max - data_min) / 2. + data_min\n",
        "\n",
        "\n",
        "def get_edge_inds(num_vars):\n",
        "\tedges = []\n",
        "\tfor i in range(num_vars):\n",
        "\t\tfor j in range(num_vars):\n",
        "\t\t\tif i == j:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tedges.append([i, j])\n",
        "\treturn edges\n",
        "\n",
        "class RefNRIMLP(nn.Module):\n",
        "    \"\"\"Two-layer fully-connected ELU net with batch norm.\"\"\"\n",
        "\n",
        "    def __init__(self, n_in, n_hid, n_out, do_prob=0., no_bn=False):\n",
        "        super(RefNRIMLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(n_in, n_hid),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, n_out),\n",
        "            nn.ELU(inplace=True)\n",
        "        )\n",
        "        if no_bn:\n",
        "            self.bn = None\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm1d(n_out)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def batch_norm(self, inputs):\n",
        "        orig_shape = inputs.shape\n",
        "        x = inputs.view(-1, inputs.size(-1))\n",
        "        x = self.bn(x)\n",
        "        return x.view(orig_shape)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Input shape: [num_sims, num_things, num_features]\n",
        "        x = self.model(inputs)\n",
        "        if self.bn is not None:\n",
        "            return self.batch_norm(x)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "\n",
        "def sample_gumbel(shape, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Sample from Gumbel(0, 1)\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    U = torch.rand(shape).float()\n",
        "    return - torch.log(eps - torch.log(U + eps))\n",
        "\n",
        "\n",
        "def gumbel_softmax_sample(logits, tau=1, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Draw a sample from the Gumbel-Softmax distribution\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    gumbel_noise = sample_gumbel(logits.size(), eps=eps)\n",
        "    if logits.is_cuda:\n",
        "        gumbel_noise = gumbel_noise.cuda()\n",
        "    y = logits + gumbel_noise\n",
        "    tau = int(1)\n",
        "    return F.softmax(y / tau, dim=-1)\n",
        "\n",
        "\n",
        "def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
        "    Args:\n",
        "      logits: [batch_size, n_class] unnormalized log-probs\n",
        "      tau: non-negative scalar temperature\n",
        "      hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
        "    Returns:\n",
        "      [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
        "      If hard=True, then the returned sample will be one-hot, otherwise it will\n",
        "      be a probability distribution that sums to 1 across classes\n",
        "    Constraints:\n",
        "    - this implementation only works on batch_size x num_features tensor for now\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    y_soft = gumbel_softmax_sample(logits, tau=tau, eps=eps)\n",
        "    if hard:\n",
        "        shape = logits.size()\n",
        "        _, k = y_soft.data.max(-1)\n",
        "        # this bit is based on\n",
        "        # https://discuss.pytorch.org/t/stop-gradients-for-st-gumbel-softmax/530/5\n",
        "        y_hard = torch.zeros(*shape)\n",
        "        if y_soft.is_cuda:\n",
        "            y_hard = y_hard.cuda()\n",
        "        y_hard = y_hard.zero_().scatter_(-1, k.view(shape[:-1] + (1,)), 1.0)\n",
        "        # this cool bit of code achieves two things:\n",
        "        # - makes the output value exactly one-hot (since we add then\n",
        "        #   subtract y_soft value)\n",
        "        # - makes the gradient equal to y_soft gradient (since we strip\n",
        "        #   all other gradients)\n",
        "        y = y_hard - y_soft.data + y_soft\n",
        "    else:\n",
        "        y = y_soft\n",
        "    return y\n",
        "\n",
        "\n",
        "def get_graph_info(masks, num_vars, use_edge2node=True):\n",
        "    if num_vars == 1:\n",
        "        return None, None, None\n",
        "    edges = torch.ones(num_vars, device=masks.device) - torch.eye(num_vars, device=masks.device)\n",
        "    tmp = torch.where(edges)\n",
        "    send_edges = tmp[0]\n",
        "    recv_edges = tmp[1]\n",
        "    tmp_inds = torch.tensor(list(range(num_vars)), device=masks.device, dtype=torch.long).unsqueeze_(1)\n",
        "    if use_edge2node:\n",
        "        edge2node_inds = (tmp_inds == recv_edges.unsqueeze(0)).nonzero()[:, 1].contiguous().view(-1, num_vars-1)\n",
        "        return send_edges, recv_edges, edge2node_inds\n",
        "    else:\n",
        "        return send_edges, recv_edges"
      ],
      "metadata": {
        "id": "nujWHRp4W0CD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNRI"
      ],
      "metadata": {
        "id": "yzULzLLYq5vS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RecurrentBaseline(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(RecurrentBaseline, self).__init__()\n",
        "        self.num_vars = params['num_vars']\n",
        "        self.teacher_forcing_steps = params.get('teacher_forcing_steps', -1)\n",
        "        self.nll_loss_type = params.get('nll_loss_type', 'crossent')\n",
        "        self.prior_variance = params.get('prior_variance')\n",
        "        self.normalize_nll = params.get('normalize_nll', False)\n",
        "        self.normalize_nll_per_var = params.get('normalize_nll_per_var', False)\n",
        "        self.anneal_teacher_forcing = params.get('anneal_teacher_forcing', False)\n",
        "        self.val_teacher_forcing_steps = params.get('val_teacher_forcing_steps', -1)\n",
        "        self.kl_coef = 0\n",
        "        self.steps = 0\n",
        "    \n",
        "    def single_step_forward(self, inputs, hidden):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def normalize_inputs(self, inputs):\n",
        "        return inputs\n",
        "    \n",
        "    def calculate_loss(self, inputs, is_train=False, teacher_forcing=True, return_logits=False, use_prior_logits=False, normalized_inputs=None):\n",
        "        hidden = self.get_initial_hidden(inputs)\n",
        "        num_time_steps = inputs.size(1)\n",
        "        all_predictions = []\n",
        "        if not is_train:\n",
        "            teacher_forcing_steps = self.val_teacher_forcing_steps\n",
        "        else:\n",
        "            teacher_forcing_steps = self.teacher_forcing_steps\n",
        "        for step in range(num_time_steps-1):\n",
        "            if (teacher_forcing and (teacher_forcing_steps == -1 or step < teacher_forcing_steps)) or step == 0:\n",
        "                current_inputs = inputs[:, step]\n",
        "            else:\n",
        "                current_inputs = predictions\n",
        "            predictions, hidden = self.single_step_forward(current_inputs, hidden)\n",
        "            all_predictions.append(predictions)\n",
        "        all_predictions = torch.stack(all_predictions, dim=1)\n",
        "        target = inputs[:, 1:, :, :]\n",
        "        loss_nll = self.nll(all_predictions, target)\n",
        "        loss_kl = torch.zeros_like(loss_nll)\n",
        "        loss = loss_nll.mean()\n",
        "        #print(loss, loss_nll, loss_kl,\"RNNbase\")\n",
        "        if return_logits:\n",
        "            return loss, loss_nll, loss_kl, None, all_predictions\n",
        "        else:\n",
        "            return loss, loss_nll, loss_kl\n",
        "\n",
        "    def predict_future(self, inputs, prediction_steps, return_everything=False):\n",
        "        burn_in_timesteps = inputs.size(1)\n",
        "        hidden = self.get_initial_hidden(inputs)\n",
        "        all_predictions = []\n",
        "        for step in range(burn_in_timesteps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            predictions, hidden = self.single_step_forward(current_inputs, hidden)\n",
        "            if return_everything:\n",
        "                all_predictions.append(predictions)\n",
        "        predictions = inputs[:, burn_in_timesteps-1]\n",
        "        for step in range(prediction_steps):\n",
        "            predictions, hidden = self.single_step_forward(predictions, hidden)\n",
        "            all_predictions.append(predictions)\n",
        "        \n",
        "        predictions = torch.stack(all_predictions, dim=1)\n",
        "        return predictions\n",
        "\n",
        "    def copy_states(self, state):\n",
        "        if isinstance(state, tuple) or isinstance(state, list):\n",
        "            current_state = (state[0].clone(), state[1].clone())\n",
        "        else:\n",
        "            current_state = state.clone()\n",
        "        return current_state\n",
        "\n",
        "    def merge_hidden(self, hidden):\n",
        "        if isinstance(hidden[0], tuple) or isinstance(hidden[0], list):\n",
        "            result0 = torch.cat([x[0] for x in hidden], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in hidden], dim=0)\n",
        "            return (result0, result1)\n",
        "        else:\n",
        "            return torch.cat(hidden, dim=0)\n",
        "\n",
        "    def predict_future_fixedwindow(self, inputs, burn_in_steps, prediction_steps, batch_size):\n",
        "        hidden = self.get_initial_hidden(inputs)\n",
        "        for step in range(burn_in_steps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            predictions, hidden = self.single_step_forward(current_inputs, hidden)\n",
        "        all_timestep_preds = []\n",
        "        for window_ind in range(burn_in_steps - 1, inputs.size(1)-1, batch_size):\n",
        "            current_batch_preds = []\n",
        "            states = []\n",
        "            for step in range(batch_size):\n",
        "                if window_ind + step >= inputs.size(1):\n",
        "                    break\n",
        "                predictions = inputs[:, window_ind + step]\n",
        "                predictions, hidden = self.single_step_forward(predictions, hidden)\n",
        "                current_batch_preds.append(predictions)\n",
        "                tmp_decoder = self.copy_states(hidden)\n",
        "                states.append(tmp_decoder)\n",
        "            batch_hidden = self.merge_hidden(states)\n",
        "            current_batch_preds = torch.cat(current_batch_preds, 0)\n",
        "            current_timestep_preds = [current_batch_preds]\n",
        "            for step in range(prediction_steps - 1):\n",
        "                current_batch_preds, batch_hidden = self.single_step_forward(current_batch_preds, batch_hidden)\n",
        "                current_timestep_preds.append(current_batch_preds)\n",
        "            all_timestep_preds.append(torch.stack(current_timestep_preds, dim=1))\n",
        "        results = torch.cat(all_timestep_preds, dim=0)\n",
        "        return results.unsqueeze(0)\n",
        "\n",
        "    def nll(self, preds, target):\n",
        "        if self.nll_loss_type == 'crossent':\n",
        "            return self.nll_crossent(preds, target)\n",
        "        elif self.nll_loss_type == 'gaussian':\n",
        "            return self.nll_gaussian(preds, target)\n",
        "        elif self.nll_loss_type == 'poisson':\n",
        "            return self.nll_poisson(preds, target)\n",
        "\n",
        "    def nll_gaussian(self, preds, target, add_const=False):\n",
        "        neg_log_p = ((preds - target) ** 2 / (2 * self.prior_variance))\n",
        "        const = 0.5 * np.log(2 * np.pi * self.prior_variance)\n",
        "        #neg_log_p += const\n",
        "        if self.normalize_nll_per_var:\n",
        "            return neg_log_p.sum() / (target.size(0) * target.size(2))\n",
        "        elif self.normalize_nll:\n",
        "            return (neg_log_p.sum(-1) + const).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return neg_log_p.view(target.size(0), -1).sum() / (target.size(1))\n",
        "\n",
        "\n",
        "    def nll_crossent(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def nll_poisson(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def save(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.load_state_dict(torch.load(path))\n",
        "\n",
        "\n",
        "class SingleRNNBaseline(RecurrentBaseline):\n",
        "    def __init__(self, params):\n",
        "        super(SingleRNNBaseline, self).__init__(params)\n",
        "        self.n_hid = n_hid = params['decoder_hidden']\n",
        "        out_size = params['input_size']\n",
        "        do_prob = params['decoder_dropout']\n",
        "        input_size = params['input_size']\n",
        "        self.num_vars = num_vars = params['num_vars']\n",
        "        self.rnn_type = params['decoder_rnn_type']\n",
        "        if self.rnn_type == 'lstm':\n",
        "            self.rnn = nn.LSTMCell(input_size, n_hid)\n",
        "        elif self.rnn_type == 'gru':\n",
        "            self.rnn = nn.GRUCell(input_size, n_hid)\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(n_hid, n_hid),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, n_hid),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, out_size),\n",
        "        )\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return None\n",
        "        '''\n",
        "        if self.rnn_type == 'lstm':\n",
        "            raise NotImplementedError\n",
        "            return torch.zeros(inputs.size(0)*inputs.size(2), self.n_hid, device=inputs.device)\n",
        "        else:\n",
        "            return torch.zeros(inputs.size(0)*inputs.size(2), self.n_hid, device=inputs.device)\n",
        "        '''\n",
        "\n",
        "    def single_step_forward(self, inputs, hidden):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        tmp_inp = inputs.reshape(-1, inputs.size(-1))\n",
        "        hidden = self.rnn(tmp_inp)\n",
        "        if self.rnn_type == 'lstm':\n",
        "            tmp = hidden[0].view(inputs.size(0), inputs.size(1), -1)\n",
        "        else:\n",
        "            tmp = hidden.view(inputs.size(0), inputs.size(1), -1)\n",
        "        outputs = inputs + self.out(tmp)\n",
        "        return outputs, hidden\n",
        "\n",
        "class JointRNNBaseline(RecurrentBaseline):\n",
        "    def __init__(self, params):\n",
        "        super(JointRNNBaseline, self).__init__(params)\n",
        "        self.n_hid = n_hid = params['decoder_hidden']\n",
        "        do_prob = params['decoder_dropout']\n",
        "        self.num_vars = num_vars = params['num_vars']\n",
        "        out_size = input_size = params['input_size']*num_vars\n",
        "        self.rnn_type = params['decoder_rnn_type']\n",
        "        if self.rnn_type == 'lstm':\n",
        "            self.rnn = nn.LSTMCell(input_size, n_hid)\n",
        "        elif self.rnn_type == 'gru':\n",
        "            self.rnn = nn.GRUCell(input_size, n_hid)\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(n_hid, n_hid),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, n_hid),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, out_size),\n",
        "        )\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return None\n",
        "        '''\n",
        "        if self.rnn_type == 'lstm':\n",
        "            raise NotImplementedError\n",
        "            return torch.zeros(inputs.size(0)*inputs.size(2), self.n_hid, device=inputs.device)\n",
        "        else:\n",
        "            return torch.zeros(inputs.size(0)*inputs.size(2), self.n_hid, device=inputs.device)\n",
        "        '''\n",
        "\n",
        "    def single_step_forward(self, inputs, hidden):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        tmp_inp = inputs.view(inputs.size(0), -1)\n",
        "        hidden = self.rnn(tmp_inp)\n",
        "        if self.rnn_type == 'lstm':\n",
        "            tmp = hidden[0]\n",
        "        else:\n",
        "            tmp = hidden\n",
        "        outputs = inputs + self.out(tmp).view(inputs.size(0), inputs.size(1), -1)\n",
        "        return outputs, hidden\n",
        " \n",
        "        \n",
        "\n",
        "\n",
        "class FullyConnectedBaseline(RecurrentBaseline):\n",
        "    def __init__(self, params):\n",
        "        super(FullyConnectedBaseline, self).__init__(params)\n",
        "        n_hid = params['decoder_hidden']\n",
        "        edge_types = params['num_edge_types']\n",
        "        skip_first = params['skip_first']\n",
        "        out_size = params['input_size']\n",
        "        do_prob = params['decoder_dropout']\n",
        "        input_size = params['input_size']\n",
        "        self.num_vars = num_vars =  params['num_vars']\n",
        "\n",
        "        self.msg_fc1 = nn.Linear(2*n_hid, n_hid)\n",
        "        self.msg_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.msg_out_shape = n_hid\n",
        "        self.skip_first_edge_type = skip_first\n",
        "\n",
        "        self.hidden_r = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_i = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_h = nn.Linear(n_hid, n_hid, bias=False)\n",
        "\n",
        "        self.input_r = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_i = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_n = nn.Linear(input_size, n_hid, bias=True)\n",
        "\n",
        "        self.out_fc1 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc3 = nn.Linear(n_hid, out_size)\n",
        "\n",
        "        print('Using learned recurrent interaction net decoder.')\n",
        "\n",
        "        self.dropout_prob = do_prob\n",
        "\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = nn.Parameter(torch.FloatTensor(encode_onehot(self.recv_edges)), requires_grad=False)\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return torch.zeros(inputs.size(0), inputs.size(2), self.msg_out_shape, device=inputs.device)\n",
        "\n",
        "\n",
        "    def single_step_forward(self, inputs, hidden):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        # Edges size: [batch, num_edges, num_edge_types]\n",
        "        if self.training:\n",
        "            dropout_prob = self.dropout_prob\n",
        "        else:\n",
        "            dropout_prob = 0.\n",
        "        \n",
        "        # node2edge\n",
        "        receivers = hidden[:, self.recv_edges, :]\n",
        "        senders = hidden[:, self.send_edges, :]\n",
        "\n",
        "        # pre_msg: [batch, num_edges, 2*msg_out]\n",
        "        pre_msg = torch.cat([receivers, senders], dim=-1)\n",
        "\n",
        "        msg = torch.tanh(self.msg_fc1(pre_msg))\n",
        "        msg = F.dropout(msg, p=dropout_prob)\n",
        "        msg = torch.tanh(self.msg_fc2(msg))\n",
        "        all_msgs = msg\n",
        "\n",
        "        # This step sums all of the messages per node\n",
        "        agg_msgs = all_msgs.transpose(-2, -1).matmul(self.edge2node_mat).transpose(-2, -1)\n",
        "        agg_msgs = agg_msgs.contiguous() / (self.num_vars - 1) # Average\n",
        "\n",
        "        # GRU-style gated aggregation\n",
        "        inp_r = self.input_r(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_i = self.input_i(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_n = self.input_n(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        r = torch.sigmoid(inp_r + self.hidden_r(agg_msgs))\n",
        "        i = torch.sigmoid(inp_i + self.hidden_i(agg_msgs))\n",
        "        n = torch.tanh(inp_n + r*self.hidden_h(agg_msgs))\n",
        "        hidden = (1 - i)*n + i*hidden\n",
        "\n",
        "        # Output MLP\n",
        "        pred = F.dropout(F.relu(self.out_fc1(hidden)), p=dropout_prob)\n",
        "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=dropout_prob)\n",
        "        pred = self.out_fc3(pred)\n",
        "\n",
        "        pred = inputs + pred\n",
        "\n",
        "        return pred, hidden"
      ],
      "metadata": {
        "id": "iuQqExnLXtOC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model"
      ],
      "metadata": {
        "id": "ShgCZ5FdsCDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(params):\n",
        "    if params['model_type'] == 'RNN':\n",
        "        model = SingleRNNBaseline(params)\n",
        "        print(\"dNRI MODEL: \",model)\n",
        "    if params['load_best_model']:\n",
        "        print(\"LOADING BEST MODEL\")\n",
        "        path = os.path.join(params['working_dir'], 'best_model')\n",
        "        model.load(path)\n",
        "    elif params['load_model']:\n",
        "        print(\"LOADING MODEL FROM SPECIFIED PATH\")\n",
        "        model.load(params['load_model'])\n",
        "    if params['gpu']:\n",
        "        model.cuda()\n",
        "    return model"
      ],
      "metadata": {
        "id": "rzUdzq4oWlju"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = SingleRNNBaseline(params)"
      ],
      "metadata": {
        "id": "reEU032Ou7Dk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "8Aw_sYeXsxYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, params, train_writer, val_writer):\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    val_batch_size = params.get('val_batch_size', batch_size)\n",
        "    if val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "    accumulate_steps = params.get('accumulate_steps')\n",
        "    training_scheduler = params.get('training_scheduler', None)\n",
        "    num_epochs = params.get('num_epochs', 100)\n",
        "    val_interval = params.get('val_interval', 1)\n",
        "    val_start = params.get('val_start', 0)\n",
        "    clip_grad = params.get('clip_grad', None)\n",
        "    clip_grad_norm = params.get('clip_grad_norm', None)\n",
        "    normalize_nll = params.get('normalize_nll', False)\n",
        "    normalize_kl = params.get('normalize_kl', False)\n",
        "    tune_on_nll = params.get('tune_on_nll', False)\n",
        "    verbose = params.get('verbose', False)\n",
        "    val_teacher_forcing = params.get('val_teacher_forcing', False)\n",
        "    continue_training = params.get('continue_training', False)\n",
        "    #train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    train_data_loader = DATA\n",
        "    #val_data_loader = DataLoader(val_data, batch_size=val_batch_size)\n",
        "    val_data_loader = VAL\n",
        "    lr = params['lr']\n",
        "    wd = params.get('wd', 0.1)\n",
        "    mom = params.get('mom', 0.9)\n",
        "    \n",
        "    #model_params = [param for param in model.parameters() if param.requires_grad]\n",
        "    model_params = model.parameters()\n",
        "    if params.get('use_adam', False):\n",
        "        opt = torch.optim.Adam(model_params, lr=lr, weight_decay=wd)\n",
        "    else:\n",
        "        opt = torch.optim.SGD(model_params, lr=lr, weight_decay=wd, momentum=mom)\n",
        "\n",
        "    working_dir = params['working_dir']\n",
        "    best_path = os.path.join(working_dir, 'best_model')\n",
        "    checkpoint_dir = os.path.join(working_dir, 'model_checkpoint')\n",
        "    training_path = os.path.join(working_dir, 'training_checkpoint')\n",
        "    if continue_training:\n",
        "        print(\"RESUMING TRAINING\")\n",
        "        model.load(checkpoint_dir)\n",
        "        train_params = torch.load(training_path)\n",
        "        start_epoch = train_params['epoch']\n",
        "        opt.load_state_dict(train_params['optimizer'])\n",
        "        best_val_result = train_params['best_val_result']\n",
        "        best_val_epoch = train_params['best_val_epoch']\n",
        "        print(\"STARTING EPOCH: \",start_epoch)\n",
        "    else:\n",
        "        start_epoch = 1\n",
        "        best_val_epoch = -1\n",
        "        best_val_result = 10000000\n",
        "    \n",
        "    training_scheduler = build_scheduler(opt, params)\n",
        "    end = start = 0 \n",
        "    #misc.seed(1)\n",
        "    result = []\n",
        "    for epoch in range(start_epoch, num_epochs+1):\n",
        "        print(\"EPOCH\", epoch, (end-start))\n",
        "        model.train()\n",
        "        model.train_percent = epoch / num_epochs\n",
        "        start = time.time() \n",
        "        for batch_ind, batch in enumerate(train_data_loader):\n",
        "            \n",
        "            inputs = batch['inputs']\n",
        "            #inputs = batch\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "            loss, loss_nll, loss_kl, logits, _ = model.calculate_loss(inputs, is_train=True, return_logits=True)\n",
        "            loss.backward()\n",
        "            if verbose:\n",
        "                print(\"\\tBATCH %d OF %d: %f, %f, %f\"%(batch_ind+1, len(train_data_loader), loss.item(), loss_nll.mean().item(), loss_kl.mean().item()))\n",
        "            if accumulate_steps == -1 or (batch_ind+1)%accumulate_steps == 0:\n",
        "                if verbose and accumulate_steps > 0:\n",
        "                    print(\"\\tUPDATING WEIGHTS\")\n",
        "                if clip_grad is not None:\n",
        "                    nn.utils.clip_grad_value_(model.parameters(), clip_grad)\n",
        "                elif clip_grad_norm is not None:\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)        \n",
        "                opt.step()\n",
        "                opt.zero_grad()\n",
        "                if accumulate_steps > 0 and accumulate_steps > len(train_data_loader) - batch_ind - 1:\n",
        "                    break\n",
        "            \n",
        "        if training_scheduler is not None:\n",
        "            training_scheduler.step()\n",
        "        \n",
        "        if train_writer is not None:\n",
        "            train_writer.add_scalar('loss', loss.item(), global_step=epoch)\n",
        "            if normalize_nll:\n",
        "                train_writer.add_scalar('NLL', loss_nll.mean().item(), global_step=epoch)\n",
        "            else:\n",
        "                train_writer.add_scalar('NLL', loss_nll.mean().item()/(inputs.size(1)*inputs.size(2)), global_step=epoch)\n",
        "            \n",
        "            train_writer.add_scalar(\"KL Divergence\", loss_kl.mean().item(), global_step=epoch)\n",
        "        model.eval()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        total_nll = 0\n",
        "        total_kl = 0\n",
        "        if verbose:\n",
        "            print(\"COMPUTING VAL LOSSES\")\n",
        "        with torch.no_grad():\n",
        "            for batch_ind, batch in enumerate(val_data_loader):\n",
        "                inputs = batch['inputs']\n",
        "                if gpu:\n",
        "                    inputs = inputs.cuda(non_blocking=True)\n",
        "                loss, loss_nll, loss_kl, logits, _ = model.calculate_loss(inputs, is_train=False, teacher_forcing=val_teacher_forcing, return_logits=True)\n",
        "                \n",
        "                total_kl += loss_kl.sum().item()\n",
        "                total_nll += loss_nll.sum().item()\n",
        "                if verbose:\n",
        "                  print(\"\\tVAL BATCH %d of %d: %f, %f\"%(batch_ind+1, len(val_data_loader), loss_nll.mean(), loss_kl.mean()))\n",
        "            \n",
        "        #total_kl /= len(val_data_loader)\n",
        "        #total_nll /= len(val_data_loader)\n",
        "        total_loss = model.kl_coef*total_kl + total_nll #TODO: this is a thing you fixed\n",
        "  \n",
        "        if val_writer is not None:\n",
        "            val_writer.add_scalar('loss', total_loss, global_step=epoch)\n",
        "            val_writer.add_scalar(\"NLL\", total_nll, global_step=epoch)\n",
        "            val_writer.add_scalar(\"KL Divergence\", total_kl, global_step=epoch)\n",
        "        if tune_on_nll:\n",
        "            tuning_loss = total_nll\n",
        "        else:\n",
        "            tuning_loss = total_loss\n",
        "        if tuning_loss < best_val_result:\n",
        "            best_val_epoch = epoch\n",
        "            best_val_result = tuning_loss\n",
        "            print(\"BEST VAL RESULT. SAVING MODEL...\")\n",
        "            #model.save(best_path)\n",
        "        model.save(checkpoint_dir)\n",
        "        torch.save({\n",
        "                    'epoch':epoch+1,\n",
        "                    'optimizer':opt.state_dict(),\n",
        "                    'best_val_result':best_val_result,\n",
        "                    'best_val_epoch':best_val_epoch,\n",
        "                   }, training_path)\n",
        "        print(\"EPOCH %d EVAL: \"%epoch)\n",
        "        print(\"\\tCURRENT VAL LOSS: %f\"%tuning_loss)\n",
        "        print(\"\\tBEST VAL LOSS:    %f\"%best_val_result)\n",
        "        print(\"\\tBEST VAL EPOCH:   %d\"%best_val_epoch)\n",
        "        result.append(tuning_loss)\n",
        "        end = time.time()\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "4vdJXF9FaLto"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Forward Prediction"
      ],
      "metadata": {
        "id": "24nOLAx_s3H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_forward_prediction(model, dataset, burn_in_steps, forward_pred_steps, params, return_total_errors=False):\n",
        "    dataset.return_edges = False\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, pin_memory=gpu)\n",
        "    model.eval()\n",
        "    total_se = 0\n",
        "    batch_count = 0\n",
        "    all_errors = []\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        with torch.no_grad():\n",
        "            model_inputs = inputs[:, :burn_in_steps]\n",
        "            gt_predictions = inputs[:, burn_in_steps:burn_in_steps+forward_pred_steps]\n",
        "            if gpu:\n",
        "                model_inputs = model_inputs.cuda(non_blocking=True)\n",
        "            model_preds = model.predict_future(model_inputs, forward_pred_steps).cpu()\n",
        "            batch_count += 1\n",
        "            if return_total_errors:\n",
        "                all_errors.append(F.mse_loss(model_preds, gt_predictions, reduction='none').view(model_preds.size(0), model_preds.size(1), -1).mean(dim=-1))\n",
        "            else:\n",
        "                total_se += F.mse_loss(model_preds, gt_predictions, reduction='none').view(model_preds.size(0), model_preds.size(1), -1).mean(dim=-1).sum(dim=0)\n",
        "    if return_total_errors:\n",
        "        return torch.cat(all_errors, dim=0)\n",
        "    else:\n",
        "        return total_se / len(dataset)\n",
        "\n",
        "def eval_forward_prediction_fixedwindow(model, dataset, burn_in_steps, forward_pred_steps, params, return_total_errors=False):\n",
        "    dataset.return_edges = False\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    data_loader = DataLoader(dataset, batch_size=1)\n",
        "    model.eval()\n",
        "    total_se = 0\n",
        "    batch_count = 0\n",
        "    all_errors = []\n",
        "    total_count = torch.zeros(forward_pred_steps)\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        print(\"BATCH IND %d OF %d\"%(batch_ind+1, len(data_loader)))\n",
        "        with torch.no_grad():\n",
        "\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "            model_preds = model.predict_future_fixedwindow(inputs, burn_in_steps, forward_pred_steps, batch_size).cpu()\n",
        "            for window_ind in range(model_preds.size(1)):\n",
        "                current_preds = model_preds[:, window_ind]\n",
        "                start_ind = burn_in_steps + window_ind\n",
        "                gt_preds = inputs[:, start_ind:start_ind + forward_pred_steps].cpu()\n",
        "                if gt_preds.size(1) < forward_pred_steps:\n",
        "                    mask = torch.cat([torch.ones(gt_preds.size(1)), torch.zeros(forward_pred_steps - gt_preds.size(1))])\n",
        "                    gt_preds = torch.cat([gt_preds, torch.zeros(gt_preds.size(0), forward_pred_steps-gt_preds.size(1), gt_preds.size(2), gt_preds.size(3))], dim=1)\n",
        "                else:\n",
        "                    mask = torch.ones(forward_pred_steps)\n",
        "                total_se += F.mse_loss(current_preds, gt_preds, reduction='none').view(current_preds.size(0), current_preds.size(1), -1).mean(dim=-1).sum(dim=0).cpu()*mask\n",
        "                total_count += mask\n",
        "\n",
        "    return total_se / total_count\n",
        "\n",
        "\n",
        "def eval_forward_prediction_dynamicvars(model, dataset, params):\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    collate_fn = params.get('collate_fn', None)\n",
        "    data_loader = DataLoader(dataset, batch_size=1, pin_memory=gpu, collate_fn=collate_fn)\n",
        "    model.eval()\n",
        "    total_se = 0\n",
        "    batch_count = 0\n",
        "    final_errors = torch.zeros(0)\n",
        "    final_counts = torch.zeros(0)\n",
        "    bad_count = 0\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        print(\"DATA POINT \",batch_ind)\n",
        "        inputs = batch['inputs']\n",
        "        gt_preds = inputs[0, 1:]\n",
        "        masks = batch['masks']\n",
        "        node_inds = batch.get('node_inds', None)\n",
        "        graph_info = batch.get('graph_info', None)\n",
        "        burn_in_masks = batch['burn_in_masks']\n",
        "        pred_masks = (masks.float() - burn_in_masks)[0, 1:]\n",
        "        with torch.no_grad():\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "                masks = masks.cuda(non_blocking=True)\n",
        "                burn_in_masks = burn_in_masks.cuda(non_blocking=True)\n",
        "            model_preds = model.predict_future(inputs, masks, node_inds, graph_info, burn_in_masks)[0].cpu()\n",
        "            max_len = pred_masks.sum(dim=0).max().int().item()\n",
        "            if max_len > len(final_errors):\n",
        "                final_errors = torch.cat([final_errors, torch.zeros(max_len - len(final_errors))])\n",
        "                final_counts = torch.cat([final_counts, torch.zeros(max_len - len(final_counts))])\n",
        "            for var in range(masks.size(-1)):\n",
        "                var_gt = gt_preds[:, var]\n",
        "                var_preds = model_preds[:, var]\n",
        "                var_pred_masks = pred_masks[:, var]\n",
        "                var_losses = F.mse_loss(var_preds, var_gt, reduction='none').mean(dim=-1)*var_pred_masks\n",
        "                tmp_inds = torch.nonzero(var_pred_masks)\n",
        "                if len(tmp_inds) == 0:\n",
        "                    continue\n",
        "                for i in range(len(tmp_inds)-1):\n",
        "                    if tmp_inds[i+1] - tmp_inds[i] != 1:\n",
        "                        bad_count += 1\n",
        "                        break\n",
        "                num_entries = var_pred_masks.sum().int().item()\n",
        "                final_errors[:num_entries] += var_losses[tmp_inds[0].item():tmp_inds[0].item()+num_entries]\n",
        "                final_counts[:num_entries] += var_pred_masks[tmp_inds[0]:tmp_inds[0]+num_entries]\n",
        "    print(\"FINAL BAD COUNT: \",bad_count)\n",
        "    return final_errors/final_counts, final_counts"
      ],
      "metadata": {
        "id": "RNpuii-haje_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "tmGdYg-HTaIs"
      },
      "outputs": [],
      "source": [
        "def eval_edges(model, dataset, params):\n",
        "\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    eval_metric = params.get('eval_metric')\n",
        "    num_edge_types = params['num_edge_types']\n",
        "    skip_first = params['skip_first']\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, pin_memory=gpu)\n",
        "    full_edge_count = 0.\n",
        "    model.eval()\n",
        "    correct_edges = 0.\n",
        "    edge_count = 0.\n",
        "    correct_0_edges = 0.\n",
        "    edge_0_count = 0.\n",
        "    correct_1_edges = 0.\n",
        "    edge_1_count = 0.\n",
        "\n",
        "    correct = num_predicted = num_gt = 0\n",
        "    all_edges = []\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        gt_edges = batch['edges'].long()\n",
        "        with torch.no_grad():\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "                gt_edges = gt_edges.cuda(non_blocking=True)\n",
        "\n",
        "            _, _, _, edges, _ = model.calculate_loss(inputs, is_train=False, return_logits=True)\n",
        "            edges = edges.argmax(dim=-1)\n",
        "            all_edges.append(edges.cpu())\n",
        "            if len(edges.shape) == 3 and len(gt_edges.shape) == 2:\n",
        "                gt_edges = gt_edges.unsqueeze(1).expand(gt_edges.size(0), edges.size(1), gt_edges.size(1))\n",
        "            elif len(gt_edges.shape) == 3 and len(edges.shape) == 2:\n",
        "                edges = edges.unsqueeze(1).expand(edges.size(0), gt_edges.size(1), edges.size(1))\n",
        "            if edges.size(1) == gt_edges.size(1) - 1:\n",
        "                gt_edges = gt_edges[:, :-1]\n",
        "            edge_count += edges.numel()\n",
        "            full_edge_count += gt_edges.numel()\n",
        "            correct_edges += ((edges == gt_edges)).sum().item()\n",
        "            edge_0_count += (gt_edges == 0).sum().item()\n",
        "            edge_1_count += (gt_edges == 1).sum().item()\n",
        "            correct_0_edges += ((edges == gt_edges)*(gt_edges == 0)).sum().item()\n",
        "            correct_1_edges += ((edges == gt_edges)*(gt_edges == 1)).sum().item()\n",
        "            correct += (edges*gt_edges).sum().item()\n",
        "            num_predicted += edges.sum().item()\n",
        "            num_gt += gt_edges.sum().item()\n",
        "    prec = correct / (num_predicted + 1e-8)\n",
        "    rec = correct / (num_gt + 1e-8)\n",
        "    f1 = 2*prec*rec / (prec+rec+1e-6)\n",
        "    all_edges = torch.cat(all_edges)\n",
        "    return f1, correct_edges / (full_edge_count + 1e-8), correct_0_edges / (edge_0_count + 1e-8), correct_1_edges / (edge_1_count + 1e-8), all_edges\n",
        "\n",
        "def plot_sample(model, dataset, num_samples, params):\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1)\n",
        "    use_gt_edges = params.get('use_gt_edges')\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size)\n",
        "    model.eval()\n",
        "    batch_count = 0\n",
        "    all_errors = []\n",
        "\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        gt_edges = batch.get('edges', None)\n",
        "        with torch.no_grad():\n",
        "            model_inputs = inputs[:, :burn_in_steps]\n",
        "            gt_predictions = inputs[:, burn_in_steps:burn_in_steps+forward_pred_steps]\n",
        "            if gpu:\n",
        "                model_inputs = model_inputs.cuda(non_blocking=True)\n",
        "                if gt_edges is not None and use_gt_edges:\n",
        "                    gt_edges = gt_edges.cuda(non_blocking=True)\n",
        "            if not use_gt_edges:\n",
        "                gt_edges=None\n",
        "            model_preds = model.predict_future(model_inputs, forward_pred_steps).cpu()\n",
        "            #total_se += F.mse_loss(model_preds, gt_predictions).item()\n",
        "            print(\"MSE: \", torch.nn.functional.mse_loss(model_preds, gt_predictions).item())\n",
        "            batch_count += 1\n",
        "        fig, ax = plt.subplots()\n",
        "        unnormalized_preds = dataset.unnormalize(model_preds)\n",
        "        unnormalized_gt = dataset.unnormalize(inputs)\n",
        "        def update(frame):\n",
        "            ax.clear()\n",
        "            ax.plot(unnormalized_gt[0, frame, 0, 0], unnormalized_gt[0, frame, 0, 1], 'bo')\n",
        "            ax.plot(unnormalized_gt[0, frame, 1, 0], unnormalized_gt[0, frame, 1, 1], 'ro')\n",
        "            ax.plot(unnormalized_gt[0, frame, 2, 0], unnormalized_gt[0, frame, 2, 1], 'go')\n",
        "            if frame >= params['burn_in_steps']:\n",
        "                tmp_fr = frame - params['burn_in_steps']\n",
        "                ax.plot(unnormalized_preds[0, tmp_fr, 0, 0], unnormalized_preds[0, tmp_fr, 0, 1], 'bo', alpha=0.5)\n",
        "                ax.plot(unnormalized_preds[0, tmp_fr, 1, 0], unnormalized_preds[0, tmp_fr, 1, 1], 'ro', alpha=0.5)\n",
        "                ax.plot(unnormalized_preds[0, tmp_fr, 2, 0], unnormalized_preds[0, tmp_fr, 2, 1], 'go', alpha=0.5)\n",
        "            ax.set_xlim(-6, 6)\n",
        "            ax.set_ylim(-6, 6)\n",
        "        ani = animation.FuncAnimation(fig, update, interval=100, frames=params['burn_in_steps']+forward_pred_steps)\n",
        "        path = os.path.join(params['working_dir'], 'pred_trajectory_%d.mp4'%batch_ind)\n",
        "        ani.save(path, codec='mpeg4')\n",
        "        if batch_count >= num_samples:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(params)\n",
        "if params['mode'] == 'train':\n",
        "    with build_writers(params['working_dir']) as (train_writer, val_writer):\n",
        "        result = train(model, train_data, val_data, params, train_writer, val_writer)\n",
        "\n",
        "elif params['mode'] == 'eval':\n",
        "    test_data = TEST\n",
        "    forward_pred = 50 - params['test_burn_in_steps']\n",
        "    test_mse  = eval_forward_prediction(model, test_data, params['test_burn_in_steps'], forward_pred, params)\n",
        "    path = os.path.join(params['working_dir'], params['error_out_name']%params['test_burn_in_steps'])\n",
        "    np.save(path, test_mse.cpu().numpy())\n",
        "    test_mse_1 = test_mse[0].item()\n",
        "    test_mse_15 = test_mse[14].item()\n",
        "    test_mse_25 = test_mse[24].item()\n",
        "    print(\"FORWARD PRED RESULTS:\")\n",
        "    print(\"\\t1 STEP: \",test_mse_1)\n",
        "    print(\"\\t15 STEP: \",test_mse_15)\n",
        "    print(\"\\t25 STEP: \",test_mse_25)\n",
        "\n",
        "\n",
        "    f1, all_acc, acc_0, acc_1, edges = eval_edges(model, val_data, params)\n",
        "    print(\"Val Edge results:\")\n",
        "    print(\"\\tF1: \",f1)\n",
        "    print(\"\\tAll predicted edge accuracy: \",all_acc)\n",
        "    print(\"\\tFirst Edge Acc: \",acc_0)\n",
        "    print(\"\\tSecond Edge Acc: \",acc_1)\n",
        "    out_dir = os.path.join(params['working_dir'], 'preds')\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    out_path = os.path.join(out_dir, 'encoder_edges.npy')\n",
        "    np.save(out_path, edges.numpy())\n",
        "\n",
        "    plot_sample(model, test_data, params['test_burn_in_steps'], params)\n",
        "\n",
        "elif params['mode'] == 'record_predictions':\n",
        "    model.eval()\n",
        "    burn_in = params['test_burn_in_steps']\n",
        "    forward_pred = 50 - params['test_burn_in_steps']\n",
        "    test_data = TEST\n",
        "    if params['subject_ind'] == -1:\n",
        "        val_data_loader = DataLoader(test_data, batch_size=params['batch_size'])\n",
        "        all_predictions = []\n",
        "        all_edges = []\n",
        "        for batch_ind,batch in enumerate(val_data_loader):\n",
        "            print(\"BATCH %d of %d\"%(batch_ind+1, len(val_data_loader)))\n",
        "            inputs = batch['inputs']\n",
        "            if params['gpu']:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "            with torch.no_grad():\n",
        "                predictions, edges = model.predict_future(inputs[:, :burn_in], forward_pred, return_edges=True, return_everything=True)\n",
        "                all_predictions.append(predictions)\n",
        "                all_edges.append(edges)\n",
        "        if params['error_suffix'] is not None:\n",
        "            out_path = os.path.join(params['working_dir'], 'preds/', 'all_test_subjects_%s.npy'%params['error_suffix'])\n",
        "        else:\n",
        "            out_path = os.path.join(params['working_dir'], 'preds/', 'all_test_subjects.npy')\n",
        "\n",
        "        predictions = torch.cat(all_predictions, dim=0)\n",
        "        edges = torch.cat(all_edges, dim=0)\n",
        "\n",
        "    else:\n",
        "        data = test_data[params['subject_ind']]\n",
        "        inputs = data['inputs'].unsqueeze(0)\n",
        "        if params['gpu']:\n",
        "            inputs = inputs.cuda(non_blocking=True)\n",
        "        with torch.no_grad():\n",
        "            predictions, edges = model.predict_future(inputs[:, :burn_in], forward_pred, return_edges=True, return_everything=True)\n",
        "            predictions = predictions.squeeze(0)\n",
        "            edges = edges.squeeze(0)\n",
        "        out_path = os.path.join(params['working_dir'], 'preds/', 'subject_%d.npy'%args.subject_ind)\n",
        "    tmp_dir = os.path.join(params['working_dir'], 'preds/')\n",
        "    if not os.path.exists(tmp_dir):\n",
        "        os.makedirs(tmp_dir)\n",
        "    torch.save([predictions.cpu(), edges.cpu()], out_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvqz0fqwYhEp",
        "outputId": "ec8ca9c2-0dc3-4b7e-dfc8-0e86b5cbf855"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dNRI MODEL:  SingleRNNBaseline(\n",
            "  (rnn): LSTMCell(4, 256)\n",
            "  (out): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.0, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.0, inplace=False)\n",
            "    (6): Linear(in_features=256, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "EPOCH 1 0\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 1 EVAL: \n",
            "\tCURRENT VAL LOSS: 3598131.343750\n",
            "\tBEST VAL LOSS:    3598131.343750\n",
            "\tBEST VAL EPOCH:   1\n",
            "EPOCH 2 4.566659927368164\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 2 EVAL: \n",
            "\tCURRENT VAL LOSS: 1551182.281250\n",
            "\tBEST VAL LOSS:    1551182.281250\n",
            "\tBEST VAL EPOCH:   2\n",
            "EPOCH 3 4.498998403549194\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 3 EVAL: \n",
            "\tCURRENT VAL LOSS: 502584.259766\n",
            "\tBEST VAL LOSS:    502584.259766\n",
            "\tBEST VAL EPOCH:   3\n",
            "EPOCH 4 4.576671600341797\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 4 EVAL: \n",
            "\tCURRENT VAL LOSS: 239802.382812\n",
            "\tBEST VAL LOSS:    239802.382812\n",
            "\tBEST VAL EPOCH:   4\n",
            "EPOCH 5 4.440937280654907\n",
            "EPOCH 5 EVAL: \n",
            "\tCURRENT VAL LOSS: 473910.513672\n",
            "\tBEST VAL LOSS:    239802.382812\n",
            "\tBEST VAL EPOCH:   4\n",
            "EPOCH 6 4.876152992248535\n",
            "EPOCH 6 EVAL: \n",
            "\tCURRENT VAL LOSS: 851783.378906\n",
            "\tBEST VAL LOSS:    239802.382812\n",
            "\tBEST VAL EPOCH:   4\n",
            "EPOCH 7 6.18180775642395\n",
            "EPOCH 7 EVAL: \n",
            "\tCURRENT VAL LOSS: 1098780.027344\n",
            "\tBEST VAL LOSS:    239802.382812\n",
            "\tBEST VAL EPOCH:   4\n",
            "EPOCH 8 4.534189462661743\n",
            "EPOCH 8 EVAL: \n",
            "\tCURRENT VAL LOSS: 1138199.812500\n",
            "\tBEST VAL LOSS:    239802.382812\n",
            "\tBEST VAL EPOCH:   4\n",
            "EPOCH 9 4.738386154174805\n",
            "EPOCH 9 EVAL: \n",
            "\tCURRENT VAL LOSS: 1014541.777344\n",
            "\tBEST VAL LOSS:    239802.382812\n",
            "\tBEST VAL EPOCH:   4\n",
            "EPOCH 10 4.766038417816162\n",
            "EPOCH 10 EVAL: \n",
            "\tCURRENT VAL LOSS: 805207.078125\n",
            "\tBEST VAL LOSS:    239802.382812\n",
            "\tBEST VAL EPOCH:   4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "plt.plot(result)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MEaTSzgFx1rH",
        "outputId": "ad147679-f5d5-4b66-ee4e-7738c1b1d083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGAE Jax"
      ],
      "metadata": {
        "id": "i5-lp7bUtNH8"
      }
    }
  ]
}