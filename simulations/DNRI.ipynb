{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nishant-Ramakuru/Inference-based-GNNS/blob/main/simulations/DNRI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Functions\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.colors as mcolors\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "import argparse, os, time\n",
        "from torch.nn import init\n",
        "import math\n",
        "import networkx as nx\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8Tm6GblxoZWs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXmvpJedOnr",
        "outputId": "2653429b-0bb9-4299-92a3-a92b405e443e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters"
      ],
      "metadata": {
        "id": "1kxH7lSHpbAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {}\n",
        "tau = 1\n",
        "params['test_burn_in_steps'] =0\n",
        "params['num_time_steps'] = 50\n",
        "params['data_path']= '/content/MyDrive/GNNs'\n",
        "params['num_train'] = 6000\n",
        "params['num_val'] = 2000\n",
        "params['num_test']= 2000\n",
        "params['load_model'] = False\n",
        "params['load_best_model'] = False\n",
        "params['model_type'] = 'dnri'\n",
        "#params['graph_type'] = ['static', 'dynamic']\n",
        "params['graph_type'] = 'dynamic'\n",
        "params['encoder_no_factor'] = True\n",
        "params['num_epochs'] = 100\n",
        "params['num_vars'] = params['num_agents'] = 10\n",
        "params['input_noise_type'] = 'none'\n",
        "params['input_size'] = 4\n",
        "params['nll_loss_type'] = 'gaussian'\n",
        "params['prior_variance'] = 5e-5\n",
        "params['batch_size'] = 64\n",
        "params['val_batch_size'] = 64\n",
        "params['accumulate_steps'] = 40\n",
        "params['num_edge_types'] = 2\n",
        "params['encoder_dropout'] = 0.5\n",
        "params['encoder_hidden'] = 256\n",
        "params['encoder_rnn_hidden'] = 64\n",
        "params['encoder_rnn_type'] = 'lstm'\n",
        "params['encoder_mlp_num_layers'] = 1\n",
        "params['encoder_mlp_hidden'] = 256\n",
        "params['prior_num_layers'] = 1\n",
        "params['prior_hidden_size'] = 256\n",
        "params['gpu'] = False\n",
        "params['decoder_hidden'] = 256\n",
        "params['skip_first'] = False\n",
        "params['decoder_dropout'] = 0.5\n",
        "params['decoder_type'] = None\n",
        "params['lr'] = 5e-4\n",
        "params['mode'] = \"train\"\n",
        "\n",
        "params['working_dir'] =params['output_dir'] =  ('/content/MyDrive/GNNs')"
      ],
      "metadata": {
        "id": "hu42uHhigCwW"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "id": "kfqJoGAgpd_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle(\"/content/drive/MyDrive/GNNs/boids_buffer_10_v3.csv\")"
      ],
      "metadata": {
        "id": "XXXXqOdbc1as"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo0__BlW4zLO",
        "outputId": "13434723-f557-480d-9740-9ca8eb818dae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "Sx9crDBZdld5",
        "outputId": "500480a3-557f-4580-8bd4-b057943d608c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   R  \\\n",
              "0  [[104.03759, 290.2829], [451.4676, 480.8318], ...   \n",
              "1  [[100.15297, 287.13492], [449.9903, 476.05502]...   \n",
              "2  [[96.26835, 283.98694], [448.51303, 471.27823]...   \n",
              "3  [[92.38372, 280.839], [447.03574, 466.50146], ...   \n",
              "4  [[88.4991, 277.691], [445.55844, 461.72467], [...   \n",
              "\n",
              "                                               theta  \\\n",
              "0  [3.8226228, 4.4124546, 1.4677178, 4.980793, 5....   \n",
              "1  [3.8226228, 4.4124546, 1.4677178, 4.980793, 5....   \n",
              "2  [3.8226228, 4.4124546, 1.4677178, 4.980793, 5....   \n",
              "3  [3.8226228, 4.4124546, 1.4677178, 4.980793, 5....   \n",
              "4  [3.8226228, 4.4124546, 1.4677178, 4.980793, 5....   \n",
              "\n",
              "                                            velocity  \\\n",
              "0  [[-3.8846226, -3.1479688], [-1.4772882, -4.776...   \n",
              "1  [[-3.8846226, -3.1479688], [-1.4772882, -4.776...   \n",
              "2  [[-3.8846226, -3.1479688], [-1.4772882, -4.776...   \n",
              "3  [[-3.8846226, -3.1479688], [-1.4772882, -4.776...   \n",
              "4  [[-3.8846226, -3.1479688], [-1.4772882, -4.776...   \n",
              "\n",
              "                                          trajectory  \n",
              "0  [[104.03759, 290.2829, -3.8846226, -3.1479688]...  \n",
              "1  [[100.15297, 287.13492, -3.8846226, -3.1479688...  \n",
              "2  [[96.26835, 283.98694, -3.8846226, -3.1479688]...  \n",
              "3  [[92.38372, 280.839, -3.8846226, -3.1479688], ...  \n",
              "4  [[88.4991, 277.691, -3.8846226, -3.1479688], [...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-775b020e-f3c1-4e91-9f34-ddcb372f69ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R</th>\n",
              "      <th>theta</th>\n",
              "      <th>velocity</th>\n",
              "      <th>trajectory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[104.03759, 290.2829], [451.4676, 480.8318], ...</td>\n",
              "      <td>[3.8226228, 4.4124546, 1.4677178, 4.980793, 5....</td>\n",
              "      <td>[[-3.8846226, -3.1479688], [-1.4772882, -4.776...</td>\n",
              "      <td>[[104.03759, 290.2829, -3.8846226, -3.1479688]...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[100.15297, 287.13492], [449.9903, 476.05502]...</td>\n",
              "      <td>[3.8226228, 4.4124546, 1.4677178, 4.980793, 5....</td>\n",
              "      <td>[[-3.8846226, -3.1479688], [-1.4772882, -4.776...</td>\n",
              "      <td>[[100.15297, 287.13492, -3.8846226, -3.1479688...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[96.26835, 283.98694], [448.51303, 471.27823]...</td>\n",
              "      <td>[3.8226228, 4.4124546, 1.4677178, 4.980793, 5....</td>\n",
              "      <td>[[-3.8846226, -3.1479688], [-1.4772882, -4.776...</td>\n",
              "      <td>[[96.26835, 283.98694, -3.8846226, -3.1479688]...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[92.38372, 280.839], [447.03574, 466.50146], ...</td>\n",
              "      <td>[3.8226228, 4.4124546, 1.4677178, 4.980793, 5....</td>\n",
              "      <td>[[-3.8846226, -3.1479688], [-1.4772882, -4.776...</td>\n",
              "      <td>[[92.38372, 280.839, -3.8846226, -3.1479688], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[88.4991, 277.691], [445.55844, 461.72467], [...</td>\n",
              "      <td>[3.8226228, 4.4124546, 1.4677178, 4.980793, 5....</td>\n",
              "      <td>[[-3.8846226, -3.1479688], [-1.4772882, -4.776...</td>\n",
              "      <td>[[88.4991, 277.691, -3.8846226, -3.1479688], [...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-775b020e-f3c1-4e91-9f34-ddcb372f69ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-775b020e-f3c1-4e91-9f34-ddcb372f69ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-775b020e-f3c1-4e91-9f34-ddcb372f69ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for w in range(len(df)):\n",
        "  \n",
        "  state = np.array(df.R[w])\n",
        "  D = list()\n",
        "  for a,i in enumerate(state):\n",
        "    d= []\n",
        "    for b,j in enumerate(state):\n",
        "      eDistance = math.hypot(i[0] - j[0], i[1] - j[1])\n",
        "      if a == b:\n",
        "        d.append(0)\n",
        "      elif int(eDistance) <= 45:\n",
        "        d.append(1)\n",
        "      else:\n",
        "        d.append(0)\n",
        "    D.append(d)\n",
        "\n",
        "  data.append(np.array(D))\n",
        "edge_data = np.array(data)\n",
        "all_data = np.array(list(df.trajectory))\n",
        "\n",
        "adj_array = []\n",
        "#print(edge_data.shape)\n",
        "for time_step in range(len(edge_data)):\n",
        "  edge = []\n",
        "  for i in range(len(edge_data[0])):\n",
        "    edge = edge + list(list(edge_data[time_step][i][:i])+list(edge_data[time_step][i][i+1:]))\n",
        "    \n",
        "  #print(len(edge[0].shape))\n",
        "  adj_array.append(edge)\n",
        "\n",
        "edge_data = np.array(adj_array)"
      ],
      "metadata": {
        "id": "DvNzNXDsmHrD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = np.stack(all_data)\n",
        "train_data = torch.FloatTensor(all_data[:params['num_train']])\n",
        "val_data = torch.FloatTensor(all_data[params['num_train']:params['num_train']+params['num_val']])\n",
        "test_data = torch.FloatTensor(all_data[params['num_train']+params['num_val']:params['num_train']+params['num_val']+params['num_test']])\n",
        "\n",
        "train_edges = torch.FloatTensor(edge_data[:params['num_train']])\n",
        "val_edges = torch.FloatTensor(edge_data[params['num_train']:params['num_train']+params['num_val']])\n",
        "test_edges = torch.FloatTensor(edge_data[params['num_train']+params['num_val']:params['num_train']+params['num_val']+params['num_test']])"
      ],
      "metadata": {
        "id": "sMqcjpLRea24"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del all_data, df,edge_data, data"
      ],
      "metadata": {
        "id": "d9nZE2UU9tCL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Shape:\", train_data.shape,\"\\n\", \n",
        "       \"Val Shape:\", val_data.shape,\"\\n\",\n",
        "      \"Test Shape:\", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UGCd5PmDRff",
        "outputId": "e6a34370-e1cc-4e5b-9b03-1c1ee3911560"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Shape: torch.Size([600, 10, 4]) \n",
            " Val Shape: torch.Size([200, 10, 4]) \n",
            " Test Shape: torch.Size([200, 10, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.reshape([int(params[\"num_train\"]/50),50,10,4])\n",
        "val_data = val_data.reshape([int(params[\"num_val\"]/50),50,10,4])\n",
        "test_data = test_data.reshape([int(params[\"num_test\"]/50),50,10,4])\n",
        "\n",
        "train_edges = train_edges.reshape([int(params['num_train']/50),50,90])\n",
        "val_edges = val_edges.reshape([int(params['num_val']/50),50,90])\n",
        "test_edges = test_edges.reshape([int(params['num_test']/50),50,90])"
      ],
      "metadata": {
        "id": "a5aGYElZbFo_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torch.nn.functional.normalize(train_data)\n",
        "val_data = torch.nn.functional.normalize(val_data)\n",
        "test_data = torch.nn.functional.normalize(test_data)"
      ],
      "metadata": {
        "id": "lRvZM3sW8hCa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA = []\n",
        "\n",
        "for i in range(train_data.shape[0]):\n",
        "  DATA.append({'inputs':train_data[i].reshape([1,50,10,4]),'edges':train_edges[i].reshape([1,50,90])})\n",
        "\n",
        "VAL = []\n",
        "\n",
        "for i in range(val_data.shape[0]):\n",
        "  VAL.append({'inputs':val_data[i].reshape([1,50,10,4]),'edges':val_edges[i].reshape([1,50,90])})\n",
        "\n",
        "TEST = []\n",
        "\n",
        "for i in range(test_data.shape[0]):\n",
        "  TEST.append({'inputs':test_data[i].reshape([1,50,10,4]),'edges':test_edges[i].reshape([1,50,90])})"
      ],
      "metadata": {
        "id": "rw95XbyRx3XM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "def seed(seed_val):\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    random.seed(seed_val)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "def build_scheduler(opt, params):\n",
        "    lr_decay_factor = params.get('lr_decay_factor')\n",
        "    lr_decay_steps = params.get('lr_decay_steps')\n",
        "    if lr_decay_factor:\n",
        "        return torch.optim.lr_scheduler.StepLR(opt, lr_decay_steps, lr_decay_factor)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "class build_writers:\n",
        "    def __init__(self, working_dir, is_test=False):\n",
        "        self.writer_dir = os.path.join(working_dir, 'logs/')\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __enter__(self):\n",
        "        train_writer_dir = os.path.join(self.writer_dir, 'train')\n",
        "        val_writer_dir = os.path.join(self.writer_dir, 'val')\n",
        "        self.train_writer = SummaryWriter(train_writer_dir)\n",
        "        self.val_writer = SummaryWriter(val_writer_dir)\n",
        "        if self.is_test:\n",
        "            test_writer_dir = os.path.join(self.writer_dir, 'test')\n",
        "            self.test_writer = SummaryWriter(test_writer_dir)\n",
        "            return self.train_writer, self.val_writer, self.test_writer\n",
        "        else:\n",
        "            return self.train_writer, self.val_writer\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        self.train_writer.close()\n",
        "        self.val_writer.close()\n",
        "        if self.is_test:\n",
        "            self.test_writer.close()\n",
        "\n",
        "# Code from NRI.\n",
        "def normalize(data):\n",
        "\treturn (data-(torch.mean(data))/ (torch.std(data)))\n",
        "\n",
        "\n",
        "def unnormalize(data, data_max, data_min):\n",
        "\treturn (data + 1) * (data_max - data_min) / 2. + data_min\n",
        "\n",
        "\n",
        "def get_edge_inds(num_vars):\n",
        "\tedges = []\n",
        "\tfor i in range(num_vars):\n",
        "\t\tfor j in range(num_vars):\n",
        "\t\t\tif i == j:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tedges.append([i, j])\n",
        "\treturn edges\n",
        "\n",
        "class RefNRIMLP(nn.Module):\n",
        "    \"\"\"Two-layer fully-connected ELU net with batch norm.\"\"\"\n",
        "\n",
        "    def __init__(self, n_in, n_hid, n_out, do_prob=0., no_bn=False):\n",
        "        super(RefNRIMLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(n_in, n_hid),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, n_out),\n",
        "            nn.ELU(inplace=True)\n",
        "        )\n",
        "        if no_bn:\n",
        "            self.bn = None\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm1d(n_out)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def batch_norm(self, inputs):\n",
        "        orig_shape = inputs.shape\n",
        "        x = inputs.view(-1, inputs.size(-1))\n",
        "        x = self.bn(x)\n",
        "        return x.view(orig_shape)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Input shape: [num_sims, num_things, num_features]\n",
        "        x = self.model(inputs)\n",
        "        if self.bn is not None:\n",
        "            return self.batch_norm(x)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "\n",
        "def sample_gumbel(shape, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Sample from Gumbel(0, 1)\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    U = torch.rand(shape).float()\n",
        "    return - torch.log(eps - torch.log(U + eps))\n",
        "\n",
        "\n",
        "def gumbel_softmax_sample(logits, tau=1, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Draw a sample from the Gumbel-Softmax distribution\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    gumbel_noise = sample_gumbel(logits.size(), eps=eps)\n",
        "    if logits.is_cuda:\n",
        "        gumbel_noise = gumbel_noise.cuda()\n",
        "    y = logits + gumbel_noise\n",
        "    #print(y.shape)\n",
        "    tau = int(1)\n",
        "    #print(F.softmax(y / tau, dim=-1))\n",
        "    return F.softmax(y / tau, dim=-1)\n",
        "\n",
        "\n",
        "def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
        "    Args:\n",
        "      logits: [batch_size, n_class] unnormalized log-probs\n",
        "      tau: non-negative scalar temperature\n",
        "      hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
        "    Returns:\n",
        "      [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
        "      If hard=True, then the returned sample will be one-hot, otherwise it will\n",
        "      be a probability distribution that sums to 1 across classes\n",
        "    Constraints:\n",
        "    - this implementation only works on batch_size x num_features tensor for now\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    y_soft = gumbel_softmax_sample(logits, tau=tau, eps=eps)\n",
        "    if hard:\n",
        "        shape = logits.size()\n",
        "        _, k = y_soft.data.max(-1)\n",
        "        # this bit is based on\n",
        "        # https://discuss.pytorch.org/t/stop-gradients-for-st-gumbel-softmax/530/5\n",
        "        y_hard = torch.zeros(*shape)\n",
        "        if y_soft.is_cuda:\n",
        "            y_hard = y_hard.cuda()\n",
        "        y_hard = y_hard.zero_().scatter_(-1, k.view(shape[:-1] + (1,)), 1.0)\n",
        "        # this cool bit of code achieves two things:\n",
        "        # - makes the output value exactly one-hot (since we add then\n",
        "        #   subtract y_soft value)\n",
        "        # - makes the gradient equal to y_soft gradient (since we strip\n",
        "        #   all other gradients)\n",
        "        y = y_hard - y_soft.data + y_soft\n",
        "    else:\n",
        "        y = y_soft\n",
        "    return y\n",
        "\n",
        "\n",
        "def get_graph_info(masks, num_vars, use_edge2node=True):\n",
        "    if num_vars == 1:\n",
        "        return None, None, None\n",
        "    edges = torch.ones(num_vars, device=masks.device) - torch.eye(num_vars, device=masks.device)\n",
        "    tmp = torch.where(edges)\n",
        "    send_edges = tmp[0]\n",
        "    recv_edges = tmp[1]\n",
        "    tmp_inds = torch.tensor(list(range(num_vars)), device=masks.device, dtype=torch.long).unsqueeze_(1)\n",
        "    if use_edge2node:\n",
        "        edge2node_inds = (tmp_inds == recv_edges.unsqueeze(0)).nonzero()[:, 1].contiguous().view(-1, num_vars-1)\n",
        "        return send_edges, recv_edges, edge2node_inds\n",
        "    else:\n",
        "        return send_edges, recv_edges"
      ],
      "metadata": {
        "id": "nujWHRp4W0CD"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNRI"
      ],
      "metadata": {
        "id": "yzULzLLYq5vS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNRI(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(DNRI, self).__init__()\n",
        "        # Model Params\n",
        "        self.num_vars = params['num_vars']\n",
        "        self.encoder = DNRI_Encoder(params)\n",
        "        decoder_type = params.get('decoder_type', None)\n",
        "        if decoder_type == 'ref_mlp':\n",
        "            self.decoder = DNRI_MLP_Decoder(params)\n",
        "        else:\n",
        "            self.decoder = DNRI_Decoder(params)\n",
        "        self.num_edge_types = params.get('num_edge_types')\n",
        "\n",
        "        # Training params\n",
        "        self.gumbel_temp = params.get('gumbel_temp')\n",
        "        self.train_hard_sample = params.get('train_hard_sample')\n",
        "        self.teacher_forcing_steps = params.get('teacher_forcing_steps', -1)\n",
        "        \n",
        "        self.normalize_kl = params.get('normalize_kl', False)\n",
        "        self.normalize_kl_per_var = params.get('normalize_kl_per_var', False)\n",
        "        self.normalize_nll = params.get('normalize_nll', False)\n",
        "        self.normalize_nll_per_var = params.get('normalize_nll_per_var', False)\n",
        "        self.kl_coef = params.get('kl_coef', 1.)\n",
        "        self.nll_loss_type = params.get('nll_loss_type', 'crossent')\n",
        "        self.prior_variance = params.get('prior_variance')\n",
        "        self.timesteps = params.get('timesteps', 0)\n",
        "        self.burn_in_steps = params.get('train_burn_in_steps')\n",
        "        self.teacher_forcing_prior = params.get('teacher_forcing_prior', False)\n",
        "        self.val_teacher_forcing_steps = params.get('val_teacher_forcing_steps', -1)\n",
        "        self.add_uniform_prior = params.get('add_uniform_prior')\n",
        "        if self.add_uniform_prior:\n",
        "            if params.get('no_edge_prior') is not None:\n",
        "                prior = np.zeros(self.num_edge_types)\n",
        "                prior.fill((1 - params['no_edge_prior'])/(self.num_edge_types - 1))\n",
        "                prior[0] = params['no_edge_prior']\n",
        "                log_prior = torch.FloatTensor(np.log(prior))\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                if params['gpu']:\n",
        "                    log_prior = log_prior.cuda(non_blocking=True)\n",
        "                self.log_prior = log_prior\n",
        "                print(\"USING NO EDGE PRIOR: \",self.log_prior)\n",
        "            else:\n",
        "                print(\"USING UNIFORM PRIOR\")\n",
        "                prior = np.zeros(self.num_edge_types)\n",
        "                prior.fill(1.0/self.num_edge_types)\n",
        "                log_prior = torch.FloatTensor(np.log(prior))\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                if params['gpu']:\n",
        "                    log_prior = log_prior.cuda(non_blocking=True)\n",
        "                self.log_prior = log_prior\n",
        "\n",
        "    def single_step_forward(self, inputs, decoder_hidden, edge_logits, hard_sample):\n",
        "        old_shape = edge_logits.shape\n",
        "        edges = gumbel_softmax(\n",
        "            edge_logits.reshape(-1, self.num_edge_types), \n",
        "            tau=self.gumbel_temp, \n",
        "            hard=hard_sample).view(old_shape)\n",
        "        predictions, decoder_hidden = self.decoder(inputs, decoder_hidden, edges)\n",
        "        return predictions, decoder_hidden, edges\n",
        "\n",
        "    def calculate_loss(self, inputs, is_train=False, teacher_forcing=True, return_edges=False, return_logits=False, use_prior_logits=False):\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        num_time_steps = inputs.size(1)\n",
        "        all_edges = []\n",
        "        all_predictions = []\n",
        "        all_priors = []\n",
        "        hard_sample = (not is_train) or self.train_hard_sample\n",
        "        prior_logits, posterior_logits, _ = self.encoder(inputs[:, :-1])\n",
        "        if not is_train:\n",
        "            teacher_forcing_steps = self.val_teacher_forcing_steps\n",
        "        else:\n",
        "            teacher_forcing_steps = self.teacher_forcing_steps\n",
        "        for step in range(num_time_steps-1):\n",
        "            if (teacher_forcing and (teacher_forcing_steps == -1 or step < teacher_forcing_steps)) or step == 0:\n",
        "                current_inputs = inputs[:, step]\n",
        "            else:\n",
        "                current_inputs = predictions\n",
        "            if not use_prior_logits:\n",
        "                current_p_logits = posterior_logits[:, step]\n",
        "            else:\n",
        "                current_p_logits = prior_logits[:, step]\n",
        "            predictions, decoder_hidden, edges = self.single_step_forward(current_inputs, decoder_hidden, current_p_logits, hard_sample)\n",
        "            all_predictions.append(predictions)\n",
        "            all_edges.append(edges)\n",
        "        all_predictions = torch.stack(all_predictions, dim=1)\n",
        "        target = inputs[:, 1:, :, :]\n",
        "        loss_nll = self.nll(all_predictions, target)\n",
        "        prob = F.softmax(posterior_logits, dim=-1)\n",
        "        loss_kl = self.kl_categorical_learned(prob, prior_logits)\n",
        "        #print(\"Loss_kl:\", loss_kl)\n",
        "        if self.add_uniform_prior:\n",
        "          loss_kl = 0.5*loss_kl + 0.5*self.kl_categorical_avg(prob)\n",
        "        loss = loss_nll + self.kl_coef*loss_kl\n",
        "        loss = loss.mean()\n",
        "        #print(loss, loss_nll, loss_kl, \"DNRI\")\n",
        "        if return_edges:\n",
        "            return loss, loss_nll, loss_kl, edges\n",
        "        elif return_logits:\n",
        "            return loss, loss_nll, loss_kl, posterior_logits, all_predictions\n",
        "        else:\n",
        "            return loss, loss_nll, loss_kl\n",
        "\n",
        "    def predict_future(self, inputs, prediction_steps, return_edges=False, return_everything=False):\n",
        "        burn_in_timesteps = inputs.size(1)\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        all_predictions = []\n",
        "        all_edges = []\n",
        "        prior_logits, _, prior_hidden = self.encoder(inputs[:, :-1])\n",
        "        for step in range(burn_in_timesteps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            current_edge_logits = prior_logits[:, step]\n",
        "            predictions, decoder_hidden, edges = self.single_step_forward(current_inputs, decoder_hidden, current_edge_logits, True)\n",
        "            if return_everything:\n",
        "                all_edges.append(edges)\n",
        "                all_predictions.append(predictions)\n",
        "        predictions = inputs[:, burn_in_timesteps-1]\n",
        "        for step in range(prediction_steps):\n",
        "            current_edge_logits, prior_hidden = self.encoder.single_step_forward(predictions, prior_hidden)\n",
        "            predictions, decoder_hidden, edges = self.single_step_forward(predictions, decoder_hidden, current_edge_logits, True)\n",
        "            all_predictions.append(predictions)\n",
        "            all_edges.append(edges)\n",
        "        \n",
        "        predictions = torch.stack(all_predictions, dim=1)\n",
        "        if return_edges:\n",
        "            edges = torch.stack(all_edges, dim=1)\n",
        "            return predictions, edges\n",
        "        else:\n",
        "            return predictions\n",
        "\n",
        "    def copy_states(self, state):\n",
        "        if isinstance(state, tuple) or isinstance(state, list):\n",
        "            current_state = (state[0].clone(), state[1].clone())\n",
        "        else:\n",
        "            current_state = state.clone()\n",
        "        return current_state\n",
        "\n",
        "    def merge_hidden(self, hidden):\n",
        "        if isinstance(hidden[0], tuple) or isinstance(hidden[0], list):\n",
        "            result0 = torch.cat([x[0] for x in hidden], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in hidden], dim=0)\n",
        "            return (result0, result1)\n",
        "        else:\n",
        "            return torch.cat(hidden, dim=0)\n",
        "\n",
        "    def predict_future_fixedwindow(self, inputs, burn_in_steps, prediction_steps, batch_size, return_edges=False):\n",
        "        print(\"INPUT SHAPE: \",inputs.shape)\n",
        "        prior_logits, _, prior_hidden = self.encoder(inputs[:, :-1])\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        for step in range(burn_in_steps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            current_edge_logits = prior_logits[:, step]\n",
        "            predictions, decoder_hidden, _ = self.single_step_forward(current_inputs, decoder_hidden, current_edge_logits, True)\n",
        "        all_timestep_preds = []\n",
        "        all_timestep_edges = []\n",
        "        for window_ind in range(burn_in_steps - 1, inputs.size(1)-1, batch_size):\n",
        "            current_batch_preds = []\n",
        "            current_batch_edges = []\n",
        "            prior_states = []\n",
        "            decoder_states = []\n",
        "            for step in range(batch_size):\n",
        "                if window_ind + step >= inputs.size(1):\n",
        "                    break\n",
        "                predictions = inputs[:, window_ind + step] \n",
        "                current_edge_logits, prior_hidden = self.encoder.single_step_forward(predictions, prior_hidden)\n",
        "                predictions, decoder_hidden, _ = self.single_step_forward(predictions, decoder_hidden, current_edge_logits, True)\n",
        "                current_batch_preds.append(predictions)\n",
        "                tmp_prior = self.encoder.copy_states(prior_hidden)\n",
        "                tmp_decoder = self.copy_states(decoder_hidden)\n",
        "                prior_states.append(tmp_prior)\n",
        "                decoder_states.append(tmp_decoder)\n",
        "                if return_edges:\n",
        "                    current_batch_edges.append(current_edge_logits.cpu())\n",
        "            batch_prior_hidden = self.encoder.merge_hidden(prior_states)\n",
        "            batch_decoder_hidden = self.merge_hidden(decoder_states)\n",
        "            current_batch_preds = torch.cat(current_batch_preds, 0)\n",
        "            current_timestep_preds = [current_batch_preds]\n",
        "            if return_edges:\n",
        "                current_batch_edges = torch.cat(current_batch_edges, 0)\n",
        "                current_timestep_edges = [current_batch_edges]\n",
        "            for step in range(prediction_steps - 1):\n",
        "                current_batch_edge_logits, batch_prior_hidden = self.encoder.single_step_forward(current_batch_preds, batch_prior_hidden)\n",
        "                current_batch_preds, batch_decoder_hidden, _ = self.single_step_forward(current_batch_preds, batch_decoder_hidden, current_batch_edge_logits, True)\n",
        "                current_timestep_preds.append(current_batch_preds)\n",
        "                if return_edges:\n",
        "                    current_timestep_edges.append(current_batch_edge_logits.cpu())\n",
        "            all_timestep_preds.append(torch.stack(current_timestep_preds, dim=1))\n",
        "            if return_edges:\n",
        "                all_timestep_edges.append(torch.stack(current_timestep_edges, dim=1))\n",
        "        result =  torch.cat(all_timestep_preds, dim=0)\n",
        "        if return_edges:\n",
        "            edge_result = torch.cat(all_timestep_edges, dim=0)\n",
        "            return result.unsqueeze(0), edge_result.unsqueeze(0)\n",
        "        else:\n",
        "            return result.unsqueeze(0)\n",
        "\n",
        "    def nll(self, preds, target):\n",
        "        if self.nll_loss_type == 'crossent':\n",
        "            return self.nll_crossent(preds, target)\n",
        "        elif self.nll_loss_type == 'gaussian':\n",
        "            return self.nll_gaussian(preds, target)\n",
        "        elif self.nll_loss_type == 'poisson':\n",
        "            return self.nll_poisson(preds, target)\n",
        "\n",
        "    def nll_gaussian(self, preds, target, add_const=False):\n",
        "        neg_log_p = ((preds - target) ** 2 / (2 * self.prior_variance))\n",
        "        const = 0.5 * np.log(2 * np.pi * self.prior_variance)\n",
        "        #neg_log_p += const\n",
        "        if self.normalize_nll_per_var:\n",
        "            return neg_log_p.sum() / (target.size(0) * target.size(2))\n",
        "        elif self.normalize_nll:\n",
        "            return (neg_log_p.sum(-1) + const).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return neg_log_p.view(target.size(0), -1).sum() / (target.size(1))\n",
        "\n",
        "\n",
        "    def nll_crossent(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def nll_poisson(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def kl_categorical_learned(self, preds, prior_logits):\n",
        "        log_prior = nn.LogSoftmax(dim=-1)(prior_logits)\n",
        "        kl_div = preds*(torch.log(preds + 1e-16) - log_prior)\n",
        "        if self.normalize_kl:     \n",
        "            return kl_div.sum(-1).view(preds.size(0), -1).mean(dim=1)\n",
        "        elif self.normalize_kl_per_var:\n",
        "            return kl_div.sum() / (self.num_vars * preds.size(0))\n",
        "        else:\n",
        "            return kl_div.view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def kl_categorical_avg(self, preds, eps=1e-16):\n",
        "        avg_preds = preds.mean(dim=2)\n",
        "        kl_div = avg_preds*(torch.log(avg_preds+eps) - self.log_prior)\n",
        "        if self.normalize_kl:     \n",
        "            return kl_div.sum(-1).view(preds.size(0), -1).mean(dim=1)\n",
        "        elif self.normalize_kl_per_var:\n",
        "            return kl_div.sum() / (self.num_vars * preds.size(0))\n",
        "        else:\n",
        "            return kl_div.view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "\n",
        "    def save(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.load_state_dict(torch.load(path))\n",
        "\n",
        "class DNRI_Encoder(nn.Module):\n",
        "    # Here, encoder also produces prior\n",
        "    def __init__(self, params):\n",
        "        super(DNRI_Encoder, self).__init__()\n",
        "        num_vars = params['num_vars']\n",
        "        self.num_edges = params['num_edge_types']\n",
        "        self.sepaate_prior_encoder = params.get('separate_prior_encoder', False)\n",
        "        no_bn = False\n",
        "        dropout = params['encoder_dropout']\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = nn.Parameter(torch.FloatTensor(encode_onehot(self.recv_edges).transpose()), requires_grad=False)\n",
        "        self.save_eval_memory = params.get('encoder_save_eval_memory', False)\n",
        "\n",
        "\n",
        "        hidden_size = params['encoder_hidden']\n",
        "        rnn_hidden_size = params['encoder_rnn_hidden']\n",
        "        rnn_type = params['encoder_rnn_type']\n",
        "        inp_size = params['input_size']\n",
        "        self.mlp1 = RefNRIMLP(inp_size, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.mlp2 = RefNRIMLP(hidden_size * 2, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.mlp3 = RefNRIMLP(hidden_size, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.mlp4 = RefNRIMLP(hidden_size * 3, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "\n",
        "        if rnn_hidden_size is None:\n",
        "            rnn_hidden_size = hidden_size\n",
        "        if rnn_type == 'lstm':\n",
        "            self.forward_rnn = nn.LSTM(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "            self.reverse_rnn = nn.LSTM(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "        elif rnn_type == 'gru':\n",
        "            self.forward_rnn = nn.GRU(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "            self.reverse_rnn = nn.GRU(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "        out_hidden_size = 2*rnn_hidden_size\n",
        "        num_layers = params['encoder_mlp_num_layers']\n",
        "        if num_layers == 1:\n",
        "            self.encoder_fc_out = nn.Linear(out_hidden_size, self.num_edges)\n",
        "        else:\n",
        "            tmp_hidden_size = params['encoder_mlp_hidden']\n",
        "            layers = [nn.Linear(out_hidden_size, tmp_hidden_size), nn.ELU(inplace=True)]\n",
        "            for _ in range(num_layers - 2):\n",
        "                layers.append(nn.Linear(tmp_hidden_size, tmp_hidden_size))\n",
        "                layers.append(nn.ELU(inplace=True))\n",
        "            layers.append(nn.Linear(tmp_hidden_size, self.num_edges))\n",
        "            self.encoder_fc_out = nn.Sequential(*layers)\n",
        "\n",
        "        num_layers = params['prior_num_layers']\n",
        "        if num_layers == 1:\n",
        "            self.prior_fc_out = nn.Linear(rnn_hidden_size, self.num_edges)\n",
        "        else:\n",
        "            tmp_hidden_size = params['prior_hidden_size']\n",
        "            layers = [nn.Linear(rnn_hidden_size, tmp_hidden_size), nn.ELU(inplace=True)]\n",
        "            for _ in range(num_layers - 2):\n",
        "                layers.append(nn.Linear(tmp_hidden_size, tmp_hidden_size))\n",
        "                layers.append(nn.ELU(inplace=True))\n",
        "            layers.append(nn.Linear(tmp_hidden_size, self.num_edges))\n",
        "            self.prior_fc_out = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "\n",
        "    def node2edge(self, node_embeddings):\n",
        "        # Input size: [batch, num_vars, num_timesteps, embed_size]\n",
        "        if len(node_embeddings.shape) == 4:\n",
        "            send_embed = node_embeddings[:, self.send_edges, :, :]\n",
        "            recv_embed = node_embeddings[:, self.recv_edges, :, :]\n",
        "        else:\n",
        "            send_embed = node_embeddings[:, self.send_edges, :]\n",
        "            recv_embed = node_embeddings[:, self.recv_edges, :]\n",
        "        return torch.cat([send_embed, recv_embed], dim=-1)\n",
        "\n",
        "    def edge2node(self, edge_embeddings):\n",
        "        if len(edge_embeddings.shape) == 4:\n",
        "            old_shape = edge_embeddings.shape\n",
        "            tmp_embeddings = edge_embeddings.view(old_shape[0], old_shape[1], -1)\n",
        "            incoming = torch.matmul(self.edge2node_mat, tmp_embeddings).view(old_shape[0], -1, old_shape[2], old_shape[3])\n",
        "        else:\n",
        "            incoming = torch.matmul(self.edge2node_mat, edge_embeddings)\n",
        "        return incoming/(self.num_vars-1) #TODO: do we want this average?\n",
        "\n",
        "\n",
        "    def copy_states(self, prior_state):\n",
        "        if isinstance(prior_state, tuple) or isinstance(prior_state, list):\n",
        "            current_prior_state = (prior_state[0].clone(), prior_state[1].clone())\n",
        "        else:\n",
        "            current_prior_state = prior_state.clone()\n",
        "        return current_prior_state\n",
        "\n",
        "    def merge_hidden(self, hidden):\n",
        "        if isinstance(hidden[0], tuple) or isinstance(hidden[0], list):\n",
        "            result0 = torch.cat([x[0] for x in hidden], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in hidden], dim=0)\n",
        "            result = (result0, result1)\n",
        "        else:\n",
        "            result = torch.cat(hidden, dim=0)\n",
        "        return result\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if self.training or not self.save_eval_memory:\n",
        "            # Inputs is shape [batch, num_timesteps, num_vars, input_size]\n",
        "            num_timesteps = inputs.size(1)\n",
        "            x = inputs.transpose(2, 1).contiguous()\n",
        "            # New shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
        "            x = self.mlp1(x)  # 2-layer ELU net per node\n",
        "            x = self.node2edge(x)\n",
        "            x = self.mlp2(x)\n",
        "            x_skip = x\n",
        "            x = self.edge2node(x)\n",
        "            x = self.mlp3(x)\n",
        "            x = self.node2edge(x)\n",
        "            x = torch.cat((x, x_skip), dim=-1)  # Skip connection\n",
        "            x = self.mlp4(x)\n",
        "        \n",
        "            \n",
        "            # At this point, x should be [batch, num_edges, num_timesteps, hidden_size]\n",
        "            # RNN aggregation\n",
        "            old_shape = x.shape\n",
        "            x = x.contiguous().view(-1, old_shape[2], old_shape[3])\n",
        "            forward_x, prior_state = self.forward_rnn(x)\n",
        "            timesteps = old_shape[2]\n",
        "            reverse_x = x.flip(1)\n",
        "            reverse_x, _ = self.reverse_rnn(reverse_x)\n",
        "            reverse_x = reverse_x.flip(1)\n",
        "            \n",
        "            #x: [batch*num_edges, num_timesteps, hidden_size]\n",
        "            prior_result = self.prior_fc_out(forward_x).view(old_shape[0], old_shape[1], timesteps, self.num_edges).transpose(1,2).contiguous()\n",
        "            combined_x = torch.cat([forward_x, reverse_x], dim=-1)\n",
        "            encoder_result = self.encoder_fc_out(combined_x).view(old_shape[0], old_shape[1], timesteps, self.num_edges).transpose(1,2).contiguous()\n",
        "            return prior_result, encoder_result, prior_state\n",
        "        else:\n",
        "            # Inputs is shape [batch, num_timesteps, num_vars, input_size]\n",
        "            num_timesteps = inputs.size(1)\n",
        "            all_x = []\n",
        "            all_forward_x = []\n",
        "            all_prior_result = []\n",
        "            prior_state = None\n",
        "            for timestep in range(num_timesteps):\n",
        "                x = inputs[:, timestep]\n",
        "                #x = inputs.transpose(2, 1).contiguous()\n",
        "                x = self.mlp1(x)  # 2-layer ELU net per node\n",
        "                x = self.node2edge(x)\n",
        "                x = self.mlp2(x)\n",
        "                x_skip = x\n",
        "                x = self.edge2node(x)\n",
        "                x = self.mlp3(x)\n",
        "                x = self.node2edge(x)\n",
        "                x = torch.cat((x, x_skip), dim=-1)  # Skip connection\n",
        "                x = self.mlp4(x)\n",
        "            \n",
        "                \n",
        "                # At this point, x should be [batch, num_edges, num_timesteps, hidden_size]\n",
        "                # RNN aggregation\n",
        "                old_shape = x.shape\n",
        "                x = x.contiguous().view(-1, 1, old_shape[-1])\n",
        "                forward_x, prior_state = self.forward_rnn(x, prior_state)\n",
        "                all_x.append(x.cpu())\n",
        "                all_forward_x.append(forward_x.cpu())\n",
        "                all_prior_result.append(self.prior_fc_out(forward_x).view(old_shape[0], 1, old_shape[1], self.num_edges).cpu())\n",
        "            reverse_state = None\n",
        "            all_encoder_result = []\n",
        "            for timestep in range(num_timesteps-1, -1, -1):\n",
        "                x = all_x[timestep].cuda()\n",
        "                reverse_x, reverse_state = self.reverse_rnn(x, reverse_state)\n",
        "                forward_x = all_forward_x[timestep].cuda()\n",
        "                \n",
        "                #x: [batch*num_edges, num_timesteps, hidden_size]\n",
        "                combined_x = torch.cat([forward_x, reverse_x], dim=-1)\n",
        "                all_encoder_result.append(self.encoder_fc_out(combined_x).view(inputs.size(0), 1, -1, self.num_edges))\n",
        "            prior_result = torch.cat(all_prior_result, dim=1).cuda(non_blocking=True)\n",
        "            encoder_result = torch.cat(all_encoder_result, dim=1).cuda(non_blocking=True)\n",
        "            return prior_result, encoder_result, prior_state\n",
        "\n",
        "    def single_step_forward(self, inputs, prior_state):\n",
        "        # Inputs is shape [batch, num_vars, input_size]\n",
        "        x = self.mlp1(inputs)  # 2-layer ELU net per node\n",
        "        x = self.node2edge(x)\n",
        "        x = self.mlp2(x)\n",
        "        x_skip = x\n",
        "        x = self.edge2node(x)\n",
        "        x = self.mlp3(x)\n",
        "        x = self.node2edge(x)\n",
        "        x = torch.cat((x, x_skip), dim=-1)  # Skip connection\n",
        "        x = self.mlp4(x)\n",
        "\n",
        "        old_shape = x.shape\n",
        "        x  = x.contiguous().view(-1, 1, old_shape[-1])\n",
        "        old_prior_shape = prior_state[0].shape\n",
        "        prior_state = (prior_state[0].view(1, old_prior_shape[0]*old_prior_shape[1], old_prior_shape[2]),\n",
        "                       prior_state[1].view(1, old_prior_shape[0]*old_prior_shape[1], old_prior_shape[2]))\n",
        "\n",
        "        x, prior_state = self.forward_rnn(x, prior_state)\n",
        "        prior_result = self.prior_fc_out(x).view(old_shape[0], old_shape[1], self.num_edges)\n",
        "        prior_state = (prior_state[0].view(old_prior_shape), prior_state[1].view(old_prior_shape))\n",
        "        return prior_result, prior_state\n",
        "\n",
        "    \n",
        "class DNRI_Decoder(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(DNRI_Decoder, self).__init__()\n",
        "        self.num_vars = num_vars =  params['num_vars']\n",
        "        input_size = params['input_size']\n",
        "        self.gpu = params['gpu']\n",
        "        n_hid = params['decoder_hidden']\n",
        "        edge_types = params['num_edge_types']\n",
        "        skip_first = params['skip_first']\n",
        "        out_size = params['input_size']\n",
        "        do_prob = params['decoder_dropout']\n",
        "\n",
        "        self.msg_fc1 = nn.ModuleList(\n",
        "            [nn.Linear(2*n_hid, n_hid) for _ in range(edge_types)]\n",
        "        )\n",
        "        self.msg_fc2 = nn.ModuleList(\n",
        "            [nn.Linear(n_hid, n_hid) for _ in range(edge_types)]\n",
        "        )\n",
        "        self.msg_out_shape = n_hid\n",
        "        self.skip_first_edge_type = skip_first\n",
        "\n",
        "        self.hidden_r = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_i = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_h = nn.Linear(n_hid, n_hid, bias=False)\n",
        "\n",
        "        self.input_r = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_i = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_n = nn.Linear(input_size, n_hid, bias=True)\n",
        "\n",
        "        self.out_fc1 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc3 = nn.Linear(n_hid, out_size)\n",
        "\n",
        "        print('Using learned recurrent interaction net decoder.')\n",
        "\n",
        "        self.dropout_prob = do_prob\n",
        "\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = nn.Parameter(torch.FloatTensor(encode_onehot(self.recv_edges)), requires_grad=False)\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return torch.zeros(inputs.size(0), inputs.size(2), self.msg_out_shape, device=inputs.device)\n",
        "        \n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "\n",
        "    def forward(self, inputs, hidden, edges):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        # Edges size: [batch, num_edges, num_edge_types]\n",
        "        if self.training:\n",
        "            dropout_prob = self.dropout_prob\n",
        "        else:\n",
        "            dropout_prob = 0.\n",
        "        \n",
        "        # node2edge\n",
        "        receivers = hidden[:, self.recv_edges, :]\n",
        "        senders = hidden[:, self.send_edges, :]\n",
        "\n",
        "        # pre_msg: [batch, num_edges, 2*msg_out]\n",
        "        pre_msg = torch.cat([receivers, senders], dim=-1)\n",
        "\n",
        "        all_msgs = torch.zeros(pre_msg.size(0), pre_msg.size(1),\n",
        "                                        self.msg_out_shape, device=inputs.device)\n",
        "        \n",
        "        if self.skip_first_edge_type:\n",
        "            start_idx = 1\n",
        "            norm = float(len(self.msg_fc2)) - 1\n",
        "        else:\n",
        "            start_idx = 0\n",
        "            norm = float(len(self.msg_fc2))\n",
        "\n",
        "        # Run separate MLP for every edge type\n",
        "        # NOTE: to exclude one edge type, simply offset range by 1\n",
        "        for i in range(start_idx, len(self.msg_fc2)):\n",
        "            msg = torch.tanh(self.msg_fc1[i](pre_msg))\n",
        "            msg = F.dropout(msg, p=dropout_prob)\n",
        "            msg = torch.tanh(self.msg_fc2[i](msg))\n",
        "            msg = msg * edges[:, :, i:i+1]\n",
        "            all_msgs += msg/norm\n",
        "\n",
        "        # This step sums all of the messages per node\n",
        "        agg_msgs = all_msgs.transpose(-2, -1).matmul(self.edge2node_mat).transpose(-2, -1)\n",
        "        agg_msgs = agg_msgs.contiguous() / (self.num_vars - 1) # Average\n",
        "\n",
        "        # GRU-style gated aggregation\n",
        "        inp_r = self.input_r(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_i = self.input_i(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_n = self.input_n(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        r = torch.sigmoid(inp_r + self.hidden_r(agg_msgs))\n",
        "        i = torch.sigmoid(inp_i + self.hidden_i(agg_msgs))\n",
        "        n = torch.tanh(inp_n + r*self.hidden_h(agg_msgs))\n",
        "        hidden = (1 - i)*n + i*hidden\n",
        "\n",
        "        # Output MLP\n",
        "        pred = F.dropout(F.relu(self.out_fc1(hidden)), p=dropout_prob)\n",
        "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=dropout_prob)\n",
        "        pred = self.out_fc3(pred)\n",
        "\n",
        "        pred = inputs + pred\n",
        "\n",
        "        return pred, hidden\n",
        "\n",
        "\n",
        "class DNRI_MLP_Decoder(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(DNRI_MLP_Decoder, self).__init__()\n",
        "        num_vars = params['num_vars']\n",
        "        edge_types = params['num_edge_types']\n",
        "        n_hid = params['decoder_hidden']\n",
        "        msg_hid = params['decoder_hidden']\n",
        "        msg_out = msg_hid #TODO: make this a param\n",
        "        skip_first = params['skip_first']\n",
        "        n_in_node = params['input_size']\n",
        "\n",
        "        do_prob = params['decoder_dropout']\n",
        "        in_size = n_in_node\n",
        "        self.msg_fc1 = nn.ModuleList(\n",
        "            [nn.Linear(2 * in_size, msg_hid) for _ in range(edge_types)])\n",
        "        self.msg_fc2 = nn.ModuleList(\n",
        "            [nn.Linear(msg_hid, msg_out) for _ in range(edge_types)])\n",
        "        self.msg_out_shape = msg_out\n",
        "        self.skip_first_edge_type = skip_first\n",
        "\n",
        "        out_size = n_in_node\n",
        "        self.out_fc1 = nn.Linear(in_size + msg_out, n_hid)\n",
        "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc3 = nn.Linear(n_hid, out_size)\n",
        "\n",
        "        print('Using learned interaction net decoder.')\n",
        "\n",
        "        self.dropout_prob = do_prob\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = nn.Parameter(torch.FloatTensor(encode_onehot(self.recv_edges)), requires_grad=False)\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return None\n",
        "\n",
        "    def forward(self, inputs, hidden, edges):\n",
        "\n",
        "        # single_timestep_inputs has shape\n",
        "        # [batch_size, num_atoms, num_dims]\n",
        "\n",
        "        # single_timestep_rel_type has shape:\n",
        "        # [batch_size, num_atoms*(num_atoms-1), num_edge_types]\n",
        "        # Node2edge\n",
        "        receivers = inputs[:, self.recv_edges, :]\n",
        "        senders = inputs[:, self.send_edges, :]\n",
        "        pre_msg = torch.cat([receivers, senders], dim=-1)\n",
        "\n",
        "        if inputs.is_cuda:\n",
        "            all_msgs = torch.cuda.FloatTensor(pre_msg.size(0), pre_msg.size(1),\n",
        "                                self.msg_out_shape).fill_(0.)\n",
        "        else:\n",
        "            all_msgs = torch.zeros(pre_msg.size(0), pre_msg.size(1),\n",
        "                                self.msg_out_shape)\n",
        "\n",
        "        if self.skip_first_edge_type:\n",
        "            start_idx = 1\n",
        "        else:\n",
        "            start_idx = 0\n",
        "        if self.training:\n",
        "            p = self.dropout_prob\n",
        "        else:\n",
        "            p = 0\n",
        "\n",
        "        # Run separate MLP for every edge type\n",
        "        # NOTE: To exlude one edge type, simply offset range by 1\n",
        "        for i in range(start_idx, len(self.msg_fc2)):\n",
        "            msg = F.relu(self.msg_fc1[i](pre_msg))\n",
        "            msg = F.dropout(msg, p=p)\n",
        "            msg = F.relu(self.msg_fc2[i](msg))\n",
        "            msg = msg * edges[:, :, i:i + 1]\n",
        "            all_msgs += msg\n",
        "\n",
        "        # Aggregate all msgs to receiver\n",
        "        agg_msgs = all_msgs.transpose(-2, -1).matmul(self.edge2node_mat).transpose(-2, -1)\n",
        "        agg_msgs = agg_msgs.contiguous()\n",
        "\n",
        "        # Skip connection\n",
        "        aug_inputs = torch.cat([inputs, agg_msgs], dim=-1)\n",
        "\n",
        "        # Output MLP\n",
        "        pred = F.dropout(F.relu(self.out_fc1(aug_inputs)), p=p)\n",
        "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=p)\n",
        "        pred = self.out_fc3(pred)\n",
        "\n",
        "        # Predict position/velocity difference\n",
        "        return inputs + pred, None"
      ],
      "metadata": {
        "id": "iuQqExnLXtOC"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model"
      ],
      "metadata": {
        "id": "ShgCZ5FdsCDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(params):\n",
        "    if params['model_type'] == 'dnri':\n",
        "        model = DNRI(params)\n",
        "        print(\"dNRI MODEL: \",model)\n",
        "    if params['load_best_model']:\n",
        "        print(\"LOADING BEST MODEL\")\n",
        "        path = os.path.join(params['working_dir'], 'best_model')\n",
        "        model.load(path)\n",
        "    elif params['load_model']:\n",
        "        print(\"LOADING MODEL FROM SPECIFIED PATH\")\n",
        "        model.load(params['load_model'])\n",
        "    if params['gpu']:\n",
        "        model.cuda()\n",
        "    return model"
      ],
      "metadata": {
        "id": "rzUdzq4oWlju"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "8Aw_sYeXsxYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, params, train_writer, val_writer):\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    val_batch_size = params.get('val_batch_size', batch_size)\n",
        "    if val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "    accumulate_steps = params.get('accumulate_steps')\n",
        "    training_scheduler = params.get('training_scheduler', None)\n",
        "    num_epochs = params.get('num_epochs', 100)\n",
        "    val_interval = params.get('val_interval', 1)\n",
        "    val_start = params.get('val_start', 0)\n",
        "    clip_grad = params.get('clip_grad', None)\n",
        "    clip_grad_norm = params.get('clip_grad_norm', None)\n",
        "    normalize_nll = params.get('normalize_nll', False)\n",
        "    normalize_kl = params.get('normalize_kl', False)\n",
        "    tune_on_nll = params.get('tune_on_nll', False)\n",
        "    verbose = params.get('verbose', False)\n",
        "    val_teacher_forcing = params.get('val_teacher_forcing', False)\n",
        "    continue_training = params.get('continue_training', False)\n",
        "    #train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    train_data_loader = DATA\n",
        "    #val_data_loader = DataLoader(val_data, batch_size=val_batch_size)\n",
        "    val_data_loader = VAL\n",
        "    lr = params['lr']\n",
        "    wd = params.get('wd', 0.1)\n",
        "    mom = params.get('mom', 0.9)\n",
        "    \n",
        "    model_params = [param for param in model.parameters() if param.requires_grad]\n",
        "    if params.get('use_adam', False):\n",
        "        opt = torch.optim.Adam(model_params, lr=lr, weight_decay=wd)\n",
        "    else:\n",
        "        opt = torch.optim.SGD(model_params, lr=lr, weight_decay=wd, momentum=mom)\n",
        "\n",
        "    working_dir = params['working_dir']\n",
        "    best_path = os.path.join(working_dir, 'best_model')\n",
        "    checkpoint_dir = os.path.join(working_dir, 'model_checkpoint')\n",
        "    training_path = os.path.join(working_dir, 'training_checkpoint')\n",
        "    if continue_training:\n",
        "        print(\"RESUMING TRAINING\")\n",
        "        model.load(checkpoint_dir)\n",
        "        train_params = torch.load(training_path)\n",
        "        start_epoch = train_params['epoch']\n",
        "        opt.load_state_dict(train_params['optimizer'])\n",
        "        best_val_result = train_params['best_val_result']\n",
        "        best_val_epoch = train_params['best_val_epoch']\n",
        "        print(\"STARTING EPOCH: \",start_epoch)\n",
        "    else:\n",
        "        start_epoch = 1\n",
        "        best_val_epoch = -1\n",
        "        best_val_result = 10000000\n",
        "    \n",
        "    training_scheduler = build_scheduler(opt, params)\n",
        "    end = start = 0 \n",
        "    #misc.seed(1)\n",
        "    result = []\n",
        "    for epoch in range(start_epoch, num_epochs+1):\n",
        "        print(\"EPOCH\", epoch, (end-start))\n",
        "        model.train()\n",
        "        model.train_percent = epoch / num_epochs\n",
        "        start = time.time() \n",
        "        for batch_ind, batch in enumerate(train_data_loader):\n",
        "            \n",
        "            inputs = batch['inputs']\n",
        "            #inputs = batch\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "            loss, loss_nll, loss_kl, logits, _ = model.calculate_loss(inputs, is_train=True, return_logits=True)\n",
        "            loss.backward()\n",
        "            if verbose:\n",
        "                print(\"\\tBATCH %d OF %d: %f, %f, %f\"%(batch_ind+1, len(train_data_loader), loss.item(), loss_nll.mean().item(), loss_kl.mean().item()))\n",
        "            if accumulate_steps == -1 or (batch_ind+1)%accumulate_steps == 0:\n",
        "                if verbose and accumulate_steps > 0:\n",
        "                    print(\"\\tUPDATING WEIGHTS\")\n",
        "                if clip_grad is not None:\n",
        "                    nn.utils.clip_grad_value_(model.parameters(), clip_grad)\n",
        "                elif clip_grad_norm is not None:\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)        \n",
        "                opt.step()\n",
        "                opt.zero_grad()\n",
        "                if accumulate_steps > 0 and accumulate_steps > len(train_data_loader) - batch_ind - 1:\n",
        "                    break\n",
        "            \n",
        "        if training_scheduler is not None:\n",
        "            training_scheduler.step()\n",
        "        \n",
        "        if train_writer is not None:\n",
        "            train_writer.add_scalar('loss', loss.item(), global_step=epoch)\n",
        "            if normalize_nll:\n",
        "                train_writer.add_scalar('NLL', loss_nll.mean().item(), global_step=epoch)\n",
        "            else:\n",
        "                train_writer.add_scalar('NLL', loss_nll.mean().item()/(inputs.size(1)*inputs.size(2)), global_step=epoch)\n",
        "            \n",
        "            train_writer.add_scalar(\"KL Divergence\", loss_kl.mean().item(), global_step=epoch)\n",
        "        model.eval()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        total_nll = 0\n",
        "        total_kl = 0\n",
        "        if verbose:\n",
        "            print(\"COMPUTING VAL LOSSES\")\n",
        "        with torch.no_grad():\n",
        "            for batch_ind, batch in enumerate(val_data_loader):\n",
        "                inputs = batch['inputs']\n",
        "                if gpu:\n",
        "                    inputs = inputs.cuda(non_blocking=True)\n",
        "                loss, loss_nll, loss_kl, logits, _ = model.calculate_loss(inputs, is_train=False, teacher_forcing=val_teacher_forcing, return_logits=True)\n",
        "                \n",
        "                total_kl += loss_kl.sum().item()\n",
        "                total_nll += loss_nll.sum().item()\n",
        "                if verbose:\n",
        "                  print(\"\\tVAL BATCH %d of %d: %f, %f\"%(batch_ind+1, len(val_data_loader), loss_nll.mean(), loss_kl.mean()))\n",
        "            \n",
        "        #total_kl /= len(val_data_loader)\n",
        "        #total_nll /= len(val_data_loader)\n",
        "        total_loss = model.kl_coef*total_kl + total_nll #TODO: this is a thing you fixed\n",
        "  \n",
        "        if val_writer is not None:\n",
        "            val_writer.add_scalar('loss', total_loss, global_step=epoch)\n",
        "            val_writer.add_scalar(\"NLL\", total_nll, global_step=epoch)\n",
        "            val_writer.add_scalar(\"KL Divergence\", total_kl, global_step=epoch)\n",
        "        if tune_on_nll:\n",
        "            tuning_loss = total_nll\n",
        "        else:\n",
        "            tuning_loss = total_loss\n",
        "        if tuning_loss < best_val_result:\n",
        "            best_val_epoch = epoch\n",
        "            best_val_result = tuning_loss\n",
        "            print(\"BEST VAL RESULT. SAVING MODEL...\")\n",
        "            #model.save(best_path)\n",
        "        model.save(checkpoint_dir)\n",
        "        torch.save({\n",
        "                    'epoch':epoch+1,\n",
        "                    'optimizer':opt.state_dict(),\n",
        "                    'best_val_result':best_val_result,\n",
        "                    'best_val_epoch':best_val_epoch,\n",
        "                   }, training_path)\n",
        "        print(\"EPOCH %d EVAL: \"%epoch)\n",
        "        print(\"\\tCURRENT VAL LOSS: %f\"%tuning_loss)\n",
        "        print(\"\\tBEST VAL LOSS:    %f\"%best_val_result)\n",
        "        print(\"\\tBEST VAL EPOCH:   %d\"%best_val_epoch)\n",
        "        result.append(tuning_loss)\n",
        "        end = time.time()\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "4vdJXF9FaLto"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Forward Prediction"
      ],
      "metadata": {
        "id": "24nOLAx_s3H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_forward_prediction(model, dataset, burn_in_steps, forward_pred_steps, params, return_total_errors=False):\n",
        "    dataset.return_edges = False\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, pin_memory=gpu)\n",
        "    model.eval()\n",
        "    total_se = 0\n",
        "    batch_count = 0\n",
        "    all_errors = []\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        with torch.no_grad():\n",
        "            model_inputs = inputs[:, :burn_in_steps]\n",
        "            gt_predictions = inputs[:, burn_in_steps:burn_in_steps+forward_pred_steps]\n",
        "            if gpu:\n",
        "                model_inputs = model_inputs.cuda(non_blocking=True)\n",
        "            model_preds = model.predict_future(model_inputs, forward_pred_steps).cpu()\n",
        "            batch_count += 1\n",
        "            if return_total_errors:\n",
        "                all_errors.append(F.mse_loss(model_preds, gt_predictions, reduction='none').view(model_preds.size(0), model_preds.size(1), -1).mean(dim=-1))\n",
        "            else:\n",
        "                total_se += F.mse_loss(model_preds, gt_predictions, reduction='none').view(model_preds.size(0), model_preds.size(1), -1).mean(dim=-1).sum(dim=0)\n",
        "    if return_total_errors:\n",
        "        return torch.cat(all_errors, dim=0)\n",
        "    else:\n",
        "        return total_se / len(dataset)\n",
        "\n",
        "def eval_forward_prediction_fixedwindow(model, dataset, burn_in_steps, forward_pred_steps, params, return_total_errors=False):\n",
        "    dataset.return_edges = False\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    data_loader = DataLoader(dataset, batch_size=1)\n",
        "    model.eval()\n",
        "    total_se = 0\n",
        "    batch_count = 0\n",
        "    all_errors = []\n",
        "    total_count = torch.zeros(forward_pred_steps)\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        print(\"BATCH IND %d OF %d\"%(batch_ind+1, len(data_loader)))\n",
        "        with torch.no_grad():\n",
        "\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "            model_preds = model.predict_future_fixedwindow(inputs, burn_in_steps, forward_pred_steps, batch_size).cpu()\n",
        "            for window_ind in range(model_preds.size(1)):\n",
        "                current_preds = model_preds[:, window_ind]\n",
        "                start_ind = burn_in_steps + window_ind\n",
        "                gt_preds = inputs[:, start_ind:start_ind + forward_pred_steps].cpu()\n",
        "                if gt_preds.size(1) < forward_pred_steps:\n",
        "                    mask = torch.cat([torch.ones(gt_preds.size(1)), torch.zeros(forward_pred_steps - gt_preds.size(1))])\n",
        "                    gt_preds = torch.cat([gt_preds, torch.zeros(gt_preds.size(0), forward_pred_steps-gt_preds.size(1), gt_preds.size(2), gt_preds.size(3))], dim=1)\n",
        "                else:\n",
        "                    mask = torch.ones(forward_pred_steps)\n",
        "                total_se += F.mse_loss(current_preds, gt_preds, reduction='none').view(current_preds.size(0), current_preds.size(1), -1).mean(dim=-1).sum(dim=0).cpu()*mask\n",
        "                total_count += mask\n",
        "\n",
        "    return total_se / total_count\n",
        "\n",
        "\n",
        "def eval_forward_prediction_dynamicvars(model, dataset, params):\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    collate_fn = params.get('collate_fn', None)\n",
        "    data_loader = DataLoader(dataset, batch_size=1, pin_memory=gpu, collate_fn=collate_fn)\n",
        "    model.eval()\n",
        "    total_se = 0\n",
        "    batch_count = 0\n",
        "    final_errors = torch.zeros(0)\n",
        "    final_counts = torch.zeros(0)\n",
        "    bad_count = 0\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        print(\"DATA POINT \",batch_ind)\n",
        "        inputs = batch['inputs']\n",
        "        gt_preds = inputs[0, 1:]\n",
        "        masks = batch['masks']\n",
        "        node_inds = batch.get('node_inds', None)\n",
        "        graph_info = batch.get('graph_info', None)\n",
        "        burn_in_masks = batch['burn_in_masks']\n",
        "        pred_masks = (masks.float() - burn_in_masks)[0, 1:]\n",
        "        with torch.no_grad():\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "                masks = masks.cuda(non_blocking=True)\n",
        "                burn_in_masks = burn_in_masks.cuda(non_blocking=True)\n",
        "            model_preds = model.predict_future(inputs, masks, node_inds, graph_info, burn_in_masks)[0].cpu()\n",
        "            max_len = pred_masks.sum(dim=0).max().int().item()\n",
        "            if max_len > len(final_errors):\n",
        "                final_errors = torch.cat([final_errors, torch.zeros(max_len - len(final_errors))])\n",
        "                final_counts = torch.cat([final_counts, torch.zeros(max_len - len(final_counts))])\n",
        "            for var in range(masks.size(-1)):\n",
        "                var_gt = gt_preds[:, var]\n",
        "                var_preds = model_preds[:, var]\n",
        "                var_pred_masks = pred_masks[:, var]\n",
        "                var_losses = F.mse_loss(var_preds, var_gt, reduction='none').mean(dim=-1)*var_pred_masks\n",
        "                tmp_inds = torch.nonzero(var_pred_masks)\n",
        "                if len(tmp_inds) == 0:\n",
        "                    continue\n",
        "                for i in range(len(tmp_inds)-1):\n",
        "                    if tmp_inds[i+1] - tmp_inds[i] != 1:\n",
        "                        bad_count += 1\n",
        "                        break\n",
        "                num_entries = var_pred_masks.sum().int().item()\n",
        "                final_errors[:num_entries] += var_losses[tmp_inds[0].item():tmp_inds[0].item()+num_entries]\n",
        "                final_counts[:num_entries] += var_pred_masks[tmp_inds[0]:tmp_inds[0]+num_entries]\n",
        "    print(\"FINAL BAD COUNT: \",bad_count)\n",
        "    return final_errors/final_counts, final_counts"
      ],
      "metadata": {
        "id": "RNpuii-haje_"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "tmGdYg-HTaIs"
      },
      "outputs": [],
      "source": [
        "def eval_edges(model, dataset, params):\n",
        "\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    eval_metric = params.get('eval_metric')\n",
        "    num_edge_types = params['num_edge_types']\n",
        "    skip_first = params['skip_first']\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, pin_memory=gpu)\n",
        "    full_edge_count = 0.\n",
        "    model.eval()\n",
        "    correct_edges = 0.\n",
        "    edge_count = 0.\n",
        "    correct_0_edges = 0.\n",
        "    edge_0_count = 0.\n",
        "    correct_1_edges = 0.\n",
        "    edge_1_count = 0.\n",
        "\n",
        "    correct = num_predicted = num_gt = 0\n",
        "    all_edges = []\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        gt_edges = batch['edges'].long()\n",
        "        with torch.no_grad():\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "                gt_edges = gt_edges.cuda(non_blocking=True)\n",
        "\n",
        "            _, _, _, edges, _ = model.calculate_loss(inputs, is_train=False, return_logits=True)\n",
        "            edges = edges.argmax(dim=-1)\n",
        "            all_edges.append(edges.cpu())\n",
        "            if len(edges.shape) == 3 and len(gt_edges.shape) == 2:\n",
        "                gt_edges = gt_edges.unsqueeze(1).expand(gt_edges.size(0), edges.size(1), gt_edges.size(1))\n",
        "            elif len(gt_edges.shape) == 3 and len(edges.shape) == 2:\n",
        "                edges = edges.unsqueeze(1).expand(edges.size(0), gt_edges.size(1), edges.size(1))\n",
        "            if edges.size(1) == gt_edges.size(1) - 1:\n",
        "                gt_edges = gt_edges[:, :-1]\n",
        "            edge_count += edges.numel()\n",
        "            full_edge_count += gt_edges.numel()\n",
        "            correct_edges += ((edges == gt_edges)).sum().item()\n",
        "            edge_0_count += (gt_edges == 0).sum().item()\n",
        "            edge_1_count += (gt_edges == 1).sum().item()\n",
        "            correct_0_edges += ((edges == gt_edges)*(gt_edges == 0)).sum().item()\n",
        "            correct_1_edges += ((edges == gt_edges)*(gt_edges == 1)).sum().item()\n",
        "            correct += (edges*gt_edges).sum().item()\n",
        "            num_predicted += edges.sum().item()\n",
        "            num_gt += gt_edges.sum().item()\n",
        "    prec = correct / (num_predicted + 1e-8)\n",
        "    rec = correct / (num_gt + 1e-8)\n",
        "    f1 = 2*prec*rec / (prec+rec+1e-6)\n",
        "    all_edges = torch.cat(all_edges)\n",
        "    return f1, correct_edges / (full_edge_count + 1e-8), correct_0_edges / (edge_0_count + 1e-8), correct_1_edges / (edge_1_count + 1e-8), all_edges\n",
        "\n",
        "def plot_sample(model, dataset, num_samples, params):\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1)\n",
        "    use_gt_edges = params.get('use_gt_edges')\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size)\n",
        "    model.eval()\n",
        "    batch_count = 0\n",
        "    all_errors = []\n",
        "\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        gt_edges = batch.get('edges', None)\n",
        "        with torch.no_grad():\n",
        "            model_inputs = inputs[:, :burn_in_steps]\n",
        "            gt_predictions = inputs[:, burn_in_steps:burn_in_steps+forward_pred_steps]\n",
        "            if gpu:\n",
        "                model_inputs = model_inputs.cuda(non_blocking=True)\n",
        "                if gt_edges is not None and use_gt_edges:\n",
        "                    gt_edges = gt_edges.cuda(non_blocking=True)\n",
        "            if not use_gt_edges:\n",
        "                gt_edges=None\n",
        "            model_preds = model.predict_future(model_inputs, forward_pred_steps).cpu()\n",
        "            #total_se += F.mse_loss(model_preds, gt_predictions).item()\n",
        "            print(\"MSE: \", torch.nn.functional.mse_loss(model_preds, gt_predictions).item())\n",
        "            batch_count += 1\n",
        "        fig, ax = plt.subplots()\n",
        "        unnormalized_preds = dataset.unnormalize(model_preds)\n",
        "        unnormalized_gt = dataset.unnormalize(inputs)\n",
        "        def update(frame):\n",
        "            ax.clear()\n",
        "            ax.plot(unnormalized_gt[0, frame, 0, 0], unnormalized_gt[0, frame, 0, 1], 'bo')\n",
        "            ax.plot(unnormalized_gt[0, frame, 1, 0], unnormalized_gt[0, frame, 1, 1], 'ro')\n",
        "            ax.plot(unnormalized_gt[0, frame, 2, 0], unnormalized_gt[0, frame, 2, 1], 'go')\n",
        "            if frame >= params['burn_in_steps']:\n",
        "                tmp_fr = frame - params['burn_in_steps']\n",
        "                ax.plot(unnormalized_preds[0, tmp_fr, 0, 0], unnormalized_preds[0, tmp_fr, 0, 1], 'bo', alpha=0.5)\n",
        "                ax.plot(unnormalized_preds[0, tmp_fr, 1, 0], unnormalized_preds[0, tmp_fr, 1, 1], 'ro', alpha=0.5)\n",
        "                ax.plot(unnormalized_preds[0, tmp_fr, 2, 0], unnormalized_preds[0, tmp_fr, 2, 1], 'go', alpha=0.5)\n",
        "            ax.set_xlim(-6, 6)\n",
        "            ax.set_ylim(-6, 6)\n",
        "        ani = animation.FuncAnimation(fig, update, interval=100, frames=params['burn_in_steps']+forward_pred_steps)\n",
        "        path = os.path.join(params['working_dir'], 'pred_trajectory_%d.mp4'%batch_ind)\n",
        "        ani.save(path, codec='mpeg4')\n",
        "        if batch_count >= num_samples:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(params)\n",
        "if params['mode'] == 'train':\n",
        "    with build_writers(params['working_dir']) as (train_writer, val_writer):\n",
        "        result = train(model, train_data, val_data, params, train_writer, val_writer)\n",
        "\n",
        "elif params['mode'] == 'eval':\n",
        "    test_data = TEST\n",
        "    forward_pred = 50 - params['test_burn_in_steps']\n",
        "    test_mse  = eval_forward_prediction(model, test_data, params['test_burn_in_steps'], forward_pred, params)\n",
        "    path = os.path.join(params['working_dir'], params['error_out_name']%params['test_burn_in_steps'])\n",
        "    np.save(path, test_mse.cpu().numpy())\n",
        "    test_mse_1 = test_mse[0].item()\n",
        "    test_mse_15 = test_mse[14].item()\n",
        "    test_mse_25 = test_mse[24].item()\n",
        "    print(\"FORWARD PRED RESULTS:\")\n",
        "    print(\"\\t1 STEP: \",test_mse_1)\n",
        "    print(\"\\t15 STEP: \",test_mse_15)\n",
        "    print(\"\\t25 STEP: \",test_mse_25)\n",
        "\n",
        "\n",
        "    f1, all_acc, acc_0, acc_1, edges = eval_edges(model, val_data, params)\n",
        "    print(\"Val Edge results:\")\n",
        "    print(\"\\tF1: \",f1)\n",
        "    print(\"\\tAll predicted edge accuracy: \",all_acc)\n",
        "    print(\"\\tFirst Edge Acc: \",acc_0)\n",
        "    print(\"\\tSecond Edge Acc: \",acc_1)\n",
        "    out_dir = os.path.join(params['working_dir'], 'preds')\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    out_path = os.path.join(out_dir, 'encoder_edges.npy')\n",
        "    np.save(out_path, edges.numpy())\n",
        "\n",
        "    plot_sample(model, test_data, params['test_burn_in_steps'], params)\n",
        "\n",
        "elif params['mode'] == 'record_predictions':\n",
        "    model.eval()\n",
        "    burn_in = params['test_burn_in_steps']\n",
        "    forward_pred = 50 - params['test_burn_in_steps']\n",
        "    test_data = TEST\n",
        "    if params['subject_ind'] == -1:\n",
        "        val_data_loader = DataLoader(test_data, batch_size=params['batch_size'])\n",
        "        all_predictions = []\n",
        "        all_edges = []\n",
        "        for batch_ind,batch in enumerate(val_data_loader):\n",
        "            print(\"BATCH %d of %d\"%(batch_ind+1, len(val_data_loader)))\n",
        "            inputs = batch['inputs']\n",
        "            if params['gpu']:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "            with torch.no_grad():\n",
        "                predictions, edges = model.predict_future(inputs[:, :burn_in], forward_pred, return_edges=True, return_everything=True)\n",
        "                all_predictions.append(predictions)\n",
        "                all_edges.append(edges)\n",
        "        if params['error_suffix'] is not None:\n",
        "            out_path = os.path.join(params['working_dir'], 'preds/', 'all_test_subjects_%s.npy'%params['error_suffix'])\n",
        "        else:\n",
        "            out_path = os.path.join(params['working_dir'], 'preds/', 'all_test_subjects.npy')\n",
        "\n",
        "        predictions = torch.cat(all_predictions, dim=0)\n",
        "        edges = torch.cat(all_edges, dim=0)\n",
        "\n",
        "    else:\n",
        "        data = test_data[params['subject_ind']]\n",
        "        inputs = data['inputs'].unsqueeze(0)\n",
        "        if params['gpu']:\n",
        "            inputs = inputs.cuda(non_blocking=True)\n",
        "        with torch.no_grad():\n",
        "            predictions, edges = model.predict_future(inputs[:, :burn_in], forward_pred, return_edges=True, return_everything=True)\n",
        "            predictions = predictions.squeeze(0)\n",
        "            edges = edges.squeeze(0)\n",
        "        out_path = os.path.join(params['working_dir'], 'preds/', 'subject_%d.npy'%args.subject_ind)\n",
        "    tmp_dir = os.path.join(params['working_dir'], 'preds/')\n",
        "    if not os.path.exists(tmp_dir):\n",
        "        os.makedirs(tmp_dir)\n",
        "    torch.save([predictions.cpu(), edges.cpu()], out_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvqz0fqwYhEp",
        "outputId": "43eea57b-191f-4d63-f024-9b76235dba74"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using learned recurrent interaction net decoder.\n",
            "dNRI MODEL:  DNRI(\n",
            "  (encoder): DNRI_Encoder(\n",
            "    (mlp1): RefNRIMLP(\n",
            "      (model): Sequential(\n",
            "        (0): Linear(in_features=4, out_features=256, bias=True)\n",
            "        (1): ELU(alpha=1.0, inplace=True)\n",
            "        (2): Dropout(p=0.5, inplace=False)\n",
            "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (4): ELU(alpha=1.0, inplace=True)\n",
            "      )\n",
            "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mlp2): RefNRIMLP(\n",
            "      (model): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): ELU(alpha=1.0, inplace=True)\n",
            "        (2): Dropout(p=0.5, inplace=False)\n",
            "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (4): ELU(alpha=1.0, inplace=True)\n",
            "      )\n",
            "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mlp3): RefNRIMLP(\n",
            "      (model): Sequential(\n",
            "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (1): ELU(alpha=1.0, inplace=True)\n",
            "        (2): Dropout(p=0.5, inplace=False)\n",
            "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (4): ELU(alpha=1.0, inplace=True)\n",
            "      )\n",
            "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mlp4): RefNRIMLP(\n",
            "      (model): Sequential(\n",
            "        (0): Linear(in_features=768, out_features=256, bias=True)\n",
            "        (1): ELU(alpha=1.0, inplace=True)\n",
            "        (2): Dropout(p=0.5, inplace=False)\n",
            "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (4): ELU(alpha=1.0, inplace=True)\n",
            "      )\n",
            "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (forward_rnn): LSTM(256, 64, batch_first=True)\n",
            "    (reverse_rnn): LSTM(256, 64, batch_first=True)\n",
            "    (encoder_fc_out): Linear(in_features=128, out_features=2, bias=True)\n",
            "    (prior_fc_out): Linear(in_features=64, out_features=2, bias=True)\n",
            "  )\n",
            "  (decoder): DNRI_Decoder(\n",
            "    (msg_fc1): ModuleList(\n",
            "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (1): Linear(in_features=512, out_features=256, bias=True)\n",
            "    )\n",
            "    (msg_fc2): ModuleList(\n",
            "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "    )\n",
            "    (hidden_r): Linear(in_features=256, out_features=256, bias=False)\n",
            "    (hidden_i): Linear(in_features=256, out_features=256, bias=False)\n",
            "    (hidden_h): Linear(in_features=256, out_features=256, bias=False)\n",
            "    (input_r): Linear(in_features=4, out_features=256, bias=True)\n",
            "    (input_i): Linear(in_features=4, out_features=256, bias=True)\n",
            "    (input_n): Linear(in_features=4, out_features=256, bias=True)\n",
            "    (out_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (out_fc2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (out_fc3): Linear(in_features=256, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "EPOCH 1 0\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 1 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649526.096340\n",
            "\tBEST VAL LOSS:    1649526.096340\n",
            "\tBEST VAL EPOCH:   1\n",
            "EPOCH 2 9.178101539611816\n",
            "EPOCH 2 EVAL: \n",
            "\tCURRENT VAL LOSS: 1650203.197498\n",
            "\tBEST VAL LOSS:    1649526.096340\n",
            "\tBEST VAL EPOCH:   1\n",
            "EPOCH 3 8.077099561691284\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 3 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649415.114029\n",
            "\tBEST VAL LOSS:    1649415.114029\n",
            "\tBEST VAL EPOCH:   3\n",
            "EPOCH 4 8.092051029205322\n",
            "EPOCH 4 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649461.248362\n",
            "\tBEST VAL LOSS:    1649415.114029\n",
            "\tBEST VAL EPOCH:   3\n",
            "EPOCH 5 9.266104936599731\n",
            "EPOCH 5 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649561.824108\n",
            "\tBEST VAL LOSS:    1649415.114029\n",
            "\tBEST VAL EPOCH:   3\n",
            "EPOCH 6 8.350375890731812\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 6 EVAL: \n",
            "\tCURRENT VAL LOSS: 1648920.361912\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 7 8.256523847579956\n",
            "EPOCH 7 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649554.117273\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 8 8.23183798789978\n",
            "EPOCH 8 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649125.234894\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 9 8.177351474761963\n",
            "EPOCH 9 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649455.232784\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 10 8.582304239273071\n",
            "EPOCH 10 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649517.885874\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 11 8.128286600112915\n",
            "EPOCH 11 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649160.752472\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 12 8.134880542755127\n",
            "EPOCH 12 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649533.563709\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 13 8.025098323822021\n",
            "EPOCH 13 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649194.518480\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 14 8.286528587341309\n",
            "EPOCH 14 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649718.791214\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 15 8.330541849136353\n",
            "EPOCH 15 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649114.914871\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 16 8.214139223098755\n",
            "EPOCH 16 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649175.614187\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 17 8.478070735931396\n",
            "EPOCH 17 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649257.740009\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 18 7.870061159133911\n",
            "EPOCH 18 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649641.511127\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 19 7.801135540008545\n",
            "EPOCH 19 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649578.881395\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 20 7.7718825340271\n",
            "EPOCH 20 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649158.210556\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 21 7.882666349411011\n",
            "EPOCH 21 EVAL: \n",
            "\tCURRENT VAL LOSS: 1648986.926378\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 22 7.754789590835571\n",
            "EPOCH 22 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649375.159512\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 23 7.765963315963745\n",
            "EPOCH 23 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649400.712982\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 24 9.026969909667969\n",
            "EPOCH 24 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649136.261496\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 25 7.847320079803467\n",
            "EPOCH 25 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649846.866451\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 26 7.8325278759002686\n",
            "EPOCH 26 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649562.125351\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 27 7.841717481613159\n",
            "EPOCH 27 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649665.750561\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 28 7.92864727973938\n",
            "EPOCH 28 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649465.902376\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 29 7.838300943374634\n",
            "EPOCH 29 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649935.622654\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 30 7.8044397830963135\n",
            "EPOCH 30 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649412.964108\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 31 7.829118728637695\n",
            "EPOCH 31 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649700.835333\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 32 7.855985879898071\n",
            "EPOCH 32 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649551.311043\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 33 7.960028171539307\n",
            "EPOCH 33 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649662.403992\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 34 7.886757135391235\n",
            "EPOCH 34 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649170.430157\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 35 7.92506742477417\n",
            "EPOCH 35 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649627.448324\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 36 7.906169414520264\n",
            "EPOCH 36 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649063.281200\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 37 7.84958815574646\n",
            "EPOCH 37 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649646.437943\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 38 7.798848628997803\n",
            "EPOCH 38 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649056.279388\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 39 7.7570881843566895\n",
            "EPOCH 39 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649458.414585\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 40 7.914149522781372\n",
            "EPOCH 40 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649157.134754\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 41 7.900399923324585\n",
            "EPOCH 41 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649827.287918\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 42 7.793264865875244\n",
            "EPOCH 42 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649007.990925\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 43 8.90023922920227\n",
            "EPOCH 43 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649288.558117\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 44 7.839882135391235\n",
            "EPOCH 44 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649394.732624\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 45 7.819579362869263\n",
            "EPOCH 45 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649307.121340\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 46 7.797590255737305\n",
            "EPOCH 46 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649554.747107\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 47 7.83296799659729\n",
            "EPOCH 47 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649624.061886\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 48 7.9548399448394775\n",
            "EPOCH 48 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649413.278227\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 49 7.828372001647949\n",
            "EPOCH 49 EVAL: \n",
            "\tCURRENT VAL LOSS: 1648941.542206\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 50 7.820066452026367\n",
            "EPOCH 50 EVAL: \n",
            "\tCURRENT VAL LOSS: 1648974.668217\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 51 7.883684158325195\n",
            "EPOCH 51 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649079.460360\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 52 7.932727336883545\n",
            "EPOCH 52 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649307.035379\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 53 7.86195182800293\n",
            "EPOCH 53 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649193.247894\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 54 7.92033839225769\n",
            "EPOCH 54 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649599.765533\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 55 7.826361894607544\n",
            "EPOCH 55 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649143.306671\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 56 8.062292575836182\n",
            "EPOCH 56 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649516.716970\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 57 7.966641187667847\n",
            "EPOCH 57 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649296.419538\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 58 7.996446847915649\n",
            "EPOCH 58 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649154.328367\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 59 8.00626516342163\n",
            "EPOCH 59 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649296.714176\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 60 8.026355504989624\n",
            "EPOCH 60 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649589.159729\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 61 7.996246337890625\n",
            "EPOCH 61 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649648.507355\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 62 9.110814332962036\n",
            "EPOCH 62 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649432.196167\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 63 7.969233274459839\n",
            "EPOCH 63 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649321.946384\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 64 7.945382595062256\n",
            "EPOCH 64 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649156.297882\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 65 7.9044349193573\n",
            "EPOCH 65 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649321.607836\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 66 8.055136442184448\n",
            "EPOCH 66 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649050.881744\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 67 8.026735782623291\n",
            "EPOCH 67 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649432.525417\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 68 8.023494958877563\n",
            "EPOCH 68 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649336.330868\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 69 7.97006630897522\n",
            "EPOCH 69 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649388.505016\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 70 7.856819152832031\n",
            "EPOCH 70 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649611.247421\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 71 7.943925380706787\n",
            "EPOCH 71 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649009.567072\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 72 7.932507753372192\n",
            "EPOCH 72 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649276.899565\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 73 7.9272401332855225\n",
            "EPOCH 73 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649548.909271\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 74 7.8692710399627686\n",
            "EPOCH 74 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649455.420170\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 75 7.885042190551758\n",
            "EPOCH 75 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649791.880297\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 76 7.9721503257751465\n",
            "EPOCH 76 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649407.276257\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 77 7.827455043792725\n",
            "EPOCH 77 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649147.331451\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 78 7.947091817855835\n",
            "EPOCH 78 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649380.245264\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 79 7.843294858932495\n",
            "EPOCH 79 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649595.773691\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 80 8.439316511154175\n",
            "EPOCH 80 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649276.315287\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 81 8.46207594871521\n",
            "EPOCH 81 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649203.833944\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 82 7.898278474807739\n",
            "EPOCH 82 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649086.307472\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 83 7.888079404830933\n",
            "EPOCH 83 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649529.838036\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 84 7.773900747299194\n",
            "EPOCH 84 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649172.620295\n",
            "\tBEST VAL LOSS:    1648920.361912\n",
            "\tBEST VAL EPOCH:   6\n",
            "EPOCH 85 7.7812180519104\n",
            "BEST VAL RESULT. SAVING MODEL...\n",
            "EPOCH 85 EVAL: \n",
            "\tCURRENT VAL LOSS: 1648768.109238\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 86 8.081199884414673\n",
            "EPOCH 86 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649614.041683\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 87 7.9112389087677\n",
            "EPOCH 87 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649480.065979\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 88 8.028369426727295\n",
            "EPOCH 88 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649480.936890\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 89 7.8513031005859375\n",
            "EPOCH 89 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649960.597622\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 90 7.968249797821045\n",
            "EPOCH 90 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649010.358665\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 91 7.927703142166138\n",
            "EPOCH 91 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649430.354683\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 92 7.909266710281372\n",
            "EPOCH 92 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649031.308031\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 93 7.771583557128906\n",
            "EPOCH 93 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649385.030865\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 94 7.82110595703125\n",
            "EPOCH 94 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649460.990271\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 95 7.87257719039917\n",
            "EPOCH 95 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649718.126375\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 96 7.8501808643341064\n",
            "EPOCH 96 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649528.309263\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 97 7.818213939666748\n",
            "EPOCH 97 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649032.745956\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 98 7.972354412078857\n",
            "EPOCH 98 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649434.565113\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 99 9.114091157913208\n",
            "EPOCH 99 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649208.545792\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n",
            "EPOCH 100 7.7691404819488525\n",
            "EPOCH 100 EVAL: \n",
            "\tCURRENT VAL LOSS: 1649454.403312\n",
            "\tBEST VAL LOSS:    1648768.109238\n",
            "\tBEST VAL EPOCH:   85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGAE Jax"
      ],
      "metadata": {
        "id": "i5-lp7bUtNH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(result)"
      ],
      "metadata": {
        "id": "Y_HToELvtP71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "e8ccee9d-c9de-45f7-d0be-d8ad30ea90b2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe182134490>]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEDCAYAAADeP8iwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9ebAkV30m+v0qs7K2e+vufXtXa2u0S6AGsUhGCNtgg2V7WAwYo2FgiHmzBBMvRjAOGzsc8+Y9O/TG5jlsIBgZI5sxjI0B2dgIC7AQRhLQLbVaLbXQ2vty93trzcqsPO+PzHPy5FJVWcu9t3T7fBEdfSsrKysr8+T5ne/3/RZijEFBQUFBQUFGarNPQEFBQUFh+KCMg4KCgoJCBMo4KCgoKChEoIyDgoKCgkIEyjgoKCgoKESgjIOCgoKCQgRbxjgQ0ReIaI6Ijibc/71E9AwRPU1Ef7Xe56egoKDwSgJtlTwHIvoZAGUAf8EYu67DvlcC+GsAdzDGloloG2NsbiPOU0FBQeGVgC3DHBhjDwNYkrcR0eVE9AARHSKiHxDRVd5b/xbAnzLGlr3PKsOgoKCgIGHLGIcW+DyA/8QYuxnAfwHwGW/7fgD7ieiHRPQYEb19085QQUFBYQihb/YJrBeIaATAGwH8DRHxzRnvfx3AlQBuB7AbwMNEdD1jbGWjz1NBQUFhGLFljQNcVrTCGLsp5r3TAH7EGLMAvExEz8E1Fj/ZyBNUUFBQGFZsWbcSY2wN7sT/HgAgFzd6b38DLmsAEU3DdTO9tBnnqaCgoDCM2DLGgYi+DOBRAK8iotNE9BEAvw7gI0T0JICnAfyyt/u3ASwS0TMA/hnA3Yyxxc04bwUFBYVhxJYJZVVQUFBQGBy2DHNQUFBQUBgctoQgPT09zfbt27fZp6GgoKDwisKhQ4cWGGMzce9tCeOwb98+HDx4cLNPQ0FBQeEVBSI60eo95VZSUFBQUIhAGQcFBQUFhQiUcVBQUFBQiEAZBwUFBQWFCJRxUFBQUFCIQBkHBQUFBYUIOhqHJB3WiOh2IjrsdVX7vrT9OBE95b13UNo+SUQPEtHz3v8T3vZfJ6Ij3mcekWohKSgoKChsIJIwhy8CaNnvgIjG4fZJuJMxdi2A94R2eQtj7CbG2AFp238F8F3G2JUAvuu9BoCXAbyZMXY9gP8Gtx/DhsBuOvjrn5xC01HlRBQUFBQ6Goe4DmshfADA1xhjJ739k3RV+2UA93l/3wfgV7zPPsK7swF4DG6vhQ3Bj19ewif+9ggOnVjuvLOCgoLCFscgNIf9ACaI6CGvHeeHpPcYgH/ytn9M2j7LGDvn/X0ewGzMcT8C4FutvpSIPkZEB4no4Pz8fL+/AZVGEwBQs5p9H0tBQUHhlY5BlM/QAdwM4K0AcgAeJaLHGGPPAbiVMXaGiLYBeJCInvWYiABjjBFRwJdDRG+BaxxubfWljLHPw3M7HThwoG9fkGm7RqFhO/0eSkFBQeEVj0Ewh9MAvs0YqzDGFgA8DOBGAGCMnfH+nwPwdQCv8z5zgYh2AID3v3BFEdENAO4F8Msb2WPBtFyjwI2EgoKCwsWMQRiH+wHcSkQ6EeUB3ALgGBEViGgUAIioAODnAfCIp78DcJf3913eMUBEewF8DcBveMxjw1BXzEFBQUFBoKNbyeuwdjuAaSI6DeB3AaQBgDH2OcbYMSJ6AMARAA6AexljR4noMgBfJyL+PX/FGHvAO+zvA/hrr1vbCQDv9bb/DoApAJ/xPmeHopzWDZw5KOOgoKCgkMA4MMben2CfewDcE9r2Ejz3Usz+i3A1ivD2jwL4aKfvWw8I5tBUxkFBQUFBZUh7EJqDpYyDgoKCgjIOHhRzUFBQUPChjIMHP1pJGQcFBQUFZRw8cKOgBGkFBQUFZRwETC8zWuU5KCgoKCjjIKCYg4KCgoIPZRw81C2VBKegoKDAoYyDB8EcVLSSgoKCgjIOHJw5qDwHBQUFBWUcBBRzUFBQUPChjIMHVbJbQUFBwYcyDh7qqvCegoKCgoAyDh44c1B5DgoKCgrKOAjUVfkMBQUFBQFlHDyYqvCegoKCgoAyDgAYY0pzUFBQUJCgjAOCbEG5lRQUFBSUcQDg6w2AYg4KCgoKQALjQERfIKI5IjraZp/biegwET1NRN+Xth8noqe89w5K2yeJ6EEiet77f8LbTkT0x0T0AhEdIaLX9PsDk4DrDXlDU8ZBQUFBAcmYwxcBvL3Vm0Q0DuAzAO5kjF0L4D2hXd7CGLuJMXZA2vZfAXyXMXYlgO96rwHgFwBc6f37GIDPJvkR/YKXzChm00qQVlBQUEAC48AYexjAUptdPgDga4yxk97+cwm+95cB3Of9fR+AX5G2/wVz8RiAcSLakeB4fYEzh9GsjqbDYCsDoaCgcJFjEJrDfgATRPQQER0iog9J7zEA/+Rt/5i0fZYxds77+zyAWe/vXQBOSfud9rZFQEQfI6KDRHRwfn6+rx/ANYdiLg1AhbMqKCgo6AM6xs0A3gogB+BRInqMMfYcgFsZY2eIaBuAB4noWY+JCDDGGBGxbr+UMfZ5AJ8HgAMHDnT9eRmcORSz7uVo2A7yRj9HVFBQUHhlYxDM4TSAbzPGKoyxBQAPA7gRABhjZ7z/5wB8HcDrvM9c4O4i73/uijoDYI907N3etnUF1xxGsx5zUKK0goLCRY5BGIf7AdxKRDoR5QHcAuAYERWIaBQAiKgA4OcB8IinvwNwl/f3Xd4x+PYPeVFLrwewKrmf1g11zhxyLnNQuQ4KCgoXOzq6lYjoywBuBzBNRKcB/C6ANAAwxj7HGDtGRA8AOALAAXAvY+woEV0G4OtExL/nrxhjD3iH/X0Af01EHwFwAsB7ve3/COAXAbwAoArgwwP5lR0QZg7KOCgoKFzs6GgcGGPvT7DPPQDuCW17CZ57KWb/RbgaRXg7A/AfOn3foMGNQVG5lRQUFBLg3/+vQxjPG/i/f/X6zT6VdcMgBOlXPHiLUO5WUtFKCgoK7fDCXBkzo5nNPo11hSqfgShzMC3V00FBQaE1KmYTlt1XkOTQQxkH+MxhNKuYwyBQazTxBw88i1pDGVmFrYlqw97y84QyDpCYQ05pDoPAT44v4bMPvYiDJ9ol1isovHJRaTRhKeOw9VG3mtBShLyhAVDGoV9UG7b3v2IOClsPVtNBw3aUcbgYYNoOsnoKhpYSrxV6R8V0jYJyKylsRfBFj9VUmsOWh2k3kUlrMHT3cijm0B8Uc1DYyuCLnq0+TyjjALfwXlZPIaO7biVzi9PF9UbFe3hqKupLYQui4i1+lFvpIoBpO4o5DBAV0314at5DpKCwlVA1uVtpa88TyjjAFaQzegoZnWsOasXbD7jmoNxKClsRPnNQmsOWh2AOmmIOg4DSHBS2Mvj4VnkOFwHqVhNZPYVUipDWSBmHPiE0B2UcFLYgKpJbyS0HtzWhjAN85gAAhpZSoax9ouppDlUlSCtsQXDmwBjQdJRx2NIwPc0BAAw9pZhDn+A+WSVIK2xFcOYAbG3dQRkHeElwnDko4xDBfMnEoRPLifdXgrTCVkZVWvRsZd1BGQcEmUNG17b0De8Ff/YvL+NDf/ajxP7VihKkFbYwKg2ZOWzduUIZBwB120E27buVVChrEGXTQqXRTJzUVlXlMxS2MLimBijjsOXhMgdfkFZupSB4G9WlSiPR/oI5WMOjOZxbreG3v/HUln6YFTYGAeawhXs6KOOAOOagJhAZ/HosV6yO+zLGhDtpmJjDvzy/gC89dhInFqubfSoKr3DI43oru6A7Ggci+gIRzRHR0Tb73E5Eh4noaSL6fug9jYieIKJvStvuIKLHiegoEd1HRLq3fYyI/p6InvSO9eF+flwS2E0HTYf5zEEJ0hFwN9tixUywryPC+4ZJc6h791TdW4V+UWkotxLHFwG8vdWbRDQO4DMA7mSMXQvgPaFdPg7gmLR/CsB9AN7HGLsOwAkAd3lv/wcAzzDGbgRwO4D/QURGol/SI/ikwZlDRjGHCARzqHZ2K/G6SsWsjprVHJokId76dSuv9BQ2BlVTCdIAAMbYwwDatfT6AICvMcZOevvP8TeIaDeAdwC4V9p/CkCDMfac9/pBAO/iXwdglIgIwIj3vevquOaTBmcOGcUcIvA1h85uJc4WpkczYMyteDsMMBVzUBgQKg1blNq5qI1DAuwHMEFEDxHRISL6kPTepwF8AoB8BRcA6ER0wHv9bgB7vL//BMDVAM4CeArAxxljsVefiD5GRAeJ6OD8/HzPJ88njUAS3Ba+4b2Au5WWEwjSnHJPj2QADE/ZbsEclHEYWvzhP/0UX/7xyc0+jY6oNpoYy/OWwsPBjNcDgzAOOoCb4TKEtwH4FBHtJ6J3AphjjB2Sd2aun+F9AP6IiH4MoASAzyBvA3AYwE4ANwH4EyIqxn0pY+zzjLEDjLEDMzMzPZ983Zs0smkVrdQK3IAuJXIruddzxjMO1SHJkhaaQ3M4jJVCFF974gy+/fT5zT6NjqiYNsa9fvOKObTHaQDfZoxVGGMLAB4GcCOANwG4k4iOA/gKgDuI6EsAwBh7lDF2G2Psdd7+3MX0YbguKsYYewHAywCuGsA5tkSYOWR0TeU5hMANaBLmUBXMwZWKhiViSTGH4cdqzUK5PhyLiXaoNpoYzyvjkAT3A7iViHQiygO4BcAxxthvMsZ2M8b2wWUK32OMfRAAiGib938GwCcBfM471kkAb/XemwXwKgAvDeAcWyLCHJTmEIFgDkncSpw5jHLmMBzGgWsfKthgONF0GEp1G6UhNw6MMVQaNsZy7uJnKxsHvdMORPRluJFD00R0GsDvAkgDAGPsc4yxY0T0AIAjcLWFexljLcNePdztuZ1SAD7LGPuet/2/AfgiET0FgAB80mMj64ZYzUFNIAF0E61UDWkOw2IcOBtU93Y4Uapbgf+HFXXLAWMQzKGxhQvvdTQOjLH3J9jnHgD3tHn/IQAPSa/vBnB3zH5nAfx8p+8bJDhzyMjMYQuvBnoBd8kkiVbioay+ID0cK0HOHNS9HU6s1rhxGI7x0go84EJoDlt4sXHRZ0hHNYcUrCaDs4XrtHcLmTl0yluoSKGsgGIOCsnAjUO5YQ/1s8dzHJTmcBHADCXBGZ6RUCtMF4wxmLaDgqGh6TCsdVjZVU0bRMBUwfXJDotxEMxBGYehBDcOjLkGYljB64WN5be+5nDRG4d6KAmOJ7co4dIFN5Lbx7IAOkcsVRpN5NMa8oZ7PYcmWkkxh6EGNw7AcLuWeMAFdyttZc3hojcOwq0klc8A1CTCwa/PzvEcAGCxg3GoNmzkMzpynnEYOuawhVd6r2TIxmGYw1l5wIVyK10EMEOhrJxBDEOuw8nFKv7zV57YVEPFS2fsSMoczCZGMjqyOmcOw/GgK+Yw3Agyh+GNWPKZg+dW6nM8zZXq+L2/f3oox6UyDjGhrMBwTCKPvLiAbxw+i1PLm1dmmk+q28dc5tApS7pi2sgbGlIpQi6tDR1zUO7C4cQrxa3EmcNoVgdR/8zhoWfn8ec/PI6nz64O4vQGioveONStJoh8rWGYBOlh6IvAJ9PEzKFho2C4EdJ5Q0M1VFvp2fNrsDfh2orCe0NwXxWiWJOMw9owMwfvWcxnNKS1VN+aw4JXBv/sSr3vcxs0LnrjYNoOMnoKbiFY30gMA3PgRes208XF3UoT+TQMPdWROVQbTeQzrkspZ2gBw7ZQNvGOP/4X/O3jp9fvhFtAlc8YbqzWLBSz7qJiqJmDl8dTMHQYWqpv5rBYdp+nMyvD14TqojcOdasp9AbAF6aHwf3AKWytsYmag+0nCU7mjQSaQ4g5SJrDhbU6mg7Ds+dL63fCLVBXmsNQY7VmYddEHsBwGwfOHHJpDWmN+jYOC2XFHIYWpuUIvQEYLubA3Ur1TSx7LWsyEwWjY5Z0tdEUYaw5Qw9oDrzN6EvzlXU623g0HQbLo//DcF8VolitWdhezEBL0VAL0lVJU0sPlDnUBnF6A4UyDnZTRCgBwyVIc5dMfTPdSsI4aJgspDvWV6qYNgoZjzmktYBh4599eWFjjYPsllOaw3BitWZhPG9gJKOjbA43c8h7zDitpfru5+AzB2Uchg51yxHZ0YBvHIbDrTQEgrRIEkxhIuRWKtUtfPPIWfGaMYZqo4mCpzm4bqWocTi9XN1QHcWUutENg9FXiGK1amEsl8ZoVh9qt1K1YYvxbegDYA7e86SMwxAizByGKc+BC9L1zcxzkMqLTBaMgCD9pcdO4j/+1RM4tVQV+9oOEyursCDNS347DOIzgGtUfvlPf7huXcBk5qWMw/DBcRhKpo1iLo3RbHqo3UoVU2YO/WkOjsOwVGnA0FNYrlpD0xiL46I3DmHmMEwZ0sKtNAShrBldw0TewGrNEqGoT5xcBuCvejhLKBgtmIPEOmTd4fRyDU+eWsEzZ9fW5zdIzMG8yNxKVtPpWCxxs1Gq22AMgjl0qt+1mahZthjf/WoOKzULTYfh6h1us8thE6UveuPQUnMYgkmEryS6EaSrDXugk4GIVtJd5sCY6x9mjOHwqRUAwLlVd1Dzct15rjkYemA1tFS1RIe4lyTd4egZNwGo0sXK6f7DZ/D/fef5RPterMzBcRju/JMf4ve/9exmn0pb8AS4sVwaxSF3K1XMphjf/eY5LHp6ww27xgAMn2vpojcOEc1hCKOVagmNQ63RxOv++3fx5R+fGtg58FV3Rtcw4VVaXao0cG61jrmSO7i5cfCZg+RWsoLMYc9kHtMjGbwsMYcjnnHoRlv51lPnE+dL8N+QS2toDIG7cKPwk+NLOHZuDc+cWx9GNihw41DM6kPvVqo2fOZgaKm+ymcseJFKN+xWxmEoEdEchijPQWgOVrJzWSibKJv2QH33cmHCKck4PHFyRexzbtUd1HzlzwW7XFqD1WSCei9VGpjMG7hsuhCIWPKZQ3TiLpt2rNGoWc3ERpMzr9GsPhSMcKPw1UOu8bywNlzuijBk5jDsgnRAc9D70xx4pNK1O8eQImUchg6m7QiDALyymQN/qJ46s4oX58sDOQfuVjI0N1oJcKOODp9ahqGncNlMQfhKeSMUEcoaqsy6Um1gomDg0umCcCsxxnDkNGcO0Unh//jSIfzO/dGuszWrmViL4QaumEsP5L5++jvP4QfPz/d9nPVExbTxD0+dAwBcWDM3+WzaQxiHfFqEsg6rTiJHK/WrOXC30mwxg+3FLM680jQHIvoCEc0RUcu+0ER0OxEdJqKniej7ofc0InqCiL4pbbuDiB4noqNEdB8R6UmOtR6oW06AOehaCikaDuPAV8xmYuPg0/H7nzgzkHMwbQeGlkIqRZgUzMHC4VMruHZnEXsn8zi/5q54eHy6nwQX7OmwVG1gsmDg0pkCFsom1uoWTi/XxOTAK17KOL1cE24rGXWrmTj/I8Ac+ryvZ1dq+PR3nher8mHFt46eR7XRxO2vmsFqzdrURMpOCDKHNJoOS7wgWg8cPbMq9LMwInkO/WgOlQZSBIznDewcz70imcMXAby91ZtENA7gMwDuZIxdC+A9oV0+DuCYtH8KwH0A3scYuw7ACQB3JTzWwOG6lYKXYRj6SLs5A175jC6Zw1TBwDcOnx3I6kvOIOc17OdKdTx1ZhU37RnHjrEcznHm0PDrzgAyc3BdQ3XLwUTeZQ4A8PJ8BU95LqVLpwuxoXxl047dXms0Ay6rtr+BM4ds/8zh20+fBwCcjzFYw4SvHjqFfVN5/OL1OwBsjGtprlTHHf/joa5Za9itBGxeCY2mw/Cuzz6C//mDlyLvWU0HDa8rIoC+aystlN3FkpYi1zisvsKMA2PsYQBLbXb5AICvMcZOevvP8TeIaDeAdwC4V9p/CkCDMfac9/pBAO/qdKz1gmk5gdpKgCu+Jl2trxdM2wFvpZt01cdX7r/22j04uVTF45Iu0CvqdlO43bJpDQVDw2MvLaJuOZ5xyGKx0kDdagYqVgJALu0+6NVGU+RHTOTTuHzGMw4LFRw5vYq0Rnj13vHY8t5V00YtRnPhrCHJtRmk5vCto65xGPRkW7ea+NFLiwM51qmlKh57aQnvvnk3thfdarob4Vo6dq6El+Yr+GmXtbNWaxbSmlvi3TcOmyNKN2wHpu3EhlXz8ZkToaz9aQ6LZRPTI26v9Z3j7iJrmPpnD0Jz2A9ggogeIqJDRPQh6b1PA/gEAPkKLgDQieiA9/rdAPYkOFYARPQxIjpIRAfn53vz/zoOQ6PpDCVzkEXY5MzBfaDec2APMnoK9x/u37VkhtxuEwUDB4+7+Q2v3jMhSnlfWKsHKlYCPnOoWU2R4zBRMLBnMo8UueGsR8+s4lXbRzGRNyLGwXEYKo1mrAHgxQiTXBtZc7CarOcHcL5k4ifHl2BoKZxbrQ/UL/7NI+fwa59/DHMDMDpfPXQaRMCvvma3aO96fgOYAzeY3bqwVmtudjQRoZh12WmSXIeHfjqHT371SPcn2gacWT4/F2U/ghlLoaz9RSuZmPJCu3eNZ9FoOkKkHgYMwjjoAG6GyxDeBuBTRLSfiN4JYI4xdkjemblP1PsA/BER/RhACUCz3bHivpQx9nnG2AHG2IGZmZmeTtzP/g0yB0NLbXq0ktwHIWm0En+gdoxl8bPXzOKbR871nd4fdrtNFgzYDsNkwcCeyRx2eE2Azq7UUWm4vTFyaT8JDvCYg2ccJgsGMrqG3RN5vDRfxlNnVnH9rjFRwVWecPnEHxetxCcgM8G1kZkD0HsOy3eOXQBjwC/duBOm7QQa1PSLJa+u/yCOef/hM3jT5dPYNZ7D7KhrHAZhdDph3gtt7lYvWKtZKHo9mbtxK3376Qv43wdPDbRVp9l0z/3EYiVi5Lgmxsd1Wu9fc5gq+MwBGK4CfIMwDqcBfJsxVmGMLQB4GMCNAN4E4E4iOg7gKwDuIKIvAQBj7FHG2G2Msdd5+z/X4VjrAjnBS0ZGT226IC1H7iRdiZXqNtIaIaOn8Cs37cJSpdF3VI1pOyIxEICIWLppzziICDvG+cq05lasTLsVKwFZkLZFXSX++UunC3jkxUWs1ixct2sMeUOHw4IhxFwUDE82jPmCZVfMIcubwvd2b7919Dz2TubxlqtmvN88uAmX903ut+hc02E4sVTFa/aOAwCKOR0ZPbUhGonPHLq7vpw5AMCod4+SuJX4960N0Ejz595h0erBYU2tX81hsdwQzIEbh2HKkh6EcbgfwK1EpBNRHsAtAI4xxn6TMbabMbYPLlP4HmPsgwBARNu8/zMAPgngc+2ONYBzjEVL5qBvPnPgbpOCoXVhHCyMZl16/ub9M9BShEMnlvs6DzfU178+PGLp1XvcyYe7lVzmYIvsUQAiqqPa8N1K/POXThcEm7hh17gID5SjRCotQnmtJkPTcw0lSZwzvW5/I9659WL4V2sWHnlhAb9w3Xbhxx/khFvyfne/bVXd7HWIhEUiwvaxLC6U1t9d0a9bCfCZQzkBc+Dft7IOxgEAnp8LaieCOWT61xzqVhNl0w5oDsBw5TronXYgoi8DuB3ANBGdBvC7ANIAwBj7HGPsGBE9AOAIXG3hXsZYy7BXD3d7bqcUgM8yxr7nHa+XY/UMPoi7YQ7l0Op4vcBXKRMFo6toJf5wGXrKjRnvM+rDtIJuJcEcvJVp3tAxlkvj/GodFbMpIjnc9yS3UtUCEcQkcJknSqc1wv7tI3j2/JrYd8r7PDcUDdtB02HQvGteC7jckjGHjJ7qqxz7d49dgO0wvO267ZjxHuhBitKDYg5hhgYAs6PZDYpWcg1QL8aBj4eRLtxKwjhUB2ccLMlN9PyFoO5Qs4LMoZ88B64t8HIyxayOkYw+VG6ljsaBMfb+BPvcA+CeNu8/BOAh6fXdAO7u5ViDhJz9K8NoYRwqpo03/j/fxW+/8xq898CewHvcV87bjfYLrjlMFQwcX0zWQtBlDv4tHcnoYkXaK0zbCRxz10QOhp7CDbvHxbYdY1mRJc3ZAuC7leqeID2eS4sJ/rLpEQDAVduLyOiaEPnklbPMImpWU6z85UiyJIaTd/vjCY69PNAPHD2P7cUsbto9DttjLedXB7caLwvm0KdxkIR/jtmxLI6c7j9yrRPmvIiobkvMy8xhxNBB1NmtZDUdUX5itda+x0g3kJ/75y7EM4dgEhwDY6zr5543+eGaAxFh53h2qJjDRZ0hzVc4WT3qVorzSz95agVrdTv2Br7rs4/g0wkLwSUBf8C6Zg6ZtHg9mh0Ac7CD0Uq/fstePPDx28TDDHDj4DGHjMQc0jJzaARWs5d6K8XrvKJj3JDIxffkv1tFbyULZe2POTgOw8PPz+Nnr9mGVIpg6G4pkYFqDiZnDv25lZa9VfRE3r8/s6MZXFgbbHRVGIwxzJU8t1KH5MQnT61g1TtPx2FYq/vGIZUijBidK7POSW6yQQYGNDxBejSjRyKWuOHmCyA+nqweROlFLwCBaw4Ahi7X4aI2Di2Zg5aK7efwuFeiOk5we3mhghcGVLIC8FfQkwUDDdtJFH4pu5UAN+Sum0qncTClPAfA1WcumxkJ7LNjPIdzq3WvtID//bqWgqGlhOYgr2Z3FLP4tQN78O6bd7vn6j1wtQBziDcCtS4juUzbYw49NnJyM4wdwXYAYLY4WFcNd6O0ysxNCsEcJEO8fSyLuuVgrbZ+iWXLVUtMku16njsOw699/lH80XfcGJSS6Zfr5khSX0m+9oN0K/GxcfXOYiRiSTAHqZ8D0BsT5ayHaw6AZxy2mCD9ioVgDjFJcHGrS15sLm61Wrecnh/sutWM+Bp5tNKk95AnmdDKpi18tgAGpDlE80DC2DmWxVKlgcVKQzw4HG7DHxvLVSswYaVShD949w24+ZIJAL4+ERCkQ24l8XeXOSAR5tDlwyz8w6P+g7zdY0uDAnejVAekOUxKhngbT4Qrrd/EI0/W7ZgDN7SPeQl/PNKoGDAOnSuzXlhdH+PADdy1O4uRiCXOHHJSPwf3M70Yhyhz2DWew1KlsamdH2Vc1MbBL0fdWXNgjOEJr39BmFUwxlC3mz0bhz//4XH8wqcfDtB+wRy8wZNkElyrWyJcE8BA+vGadjSDPIztY36Mdt4I7ptLa4I5TBbScY3BkcUAACAASURBVB8HEEyY45CrtLYyCImilTzmkOmxqOJ8SDwEBs8cBuVWWqo2YGipwH3ws6Q3yDi0uSe8LeZPL5SwWrMCpTM4umEOKUruVirVLfyf//swVtr0Qedj49qdrrtTjliqNJowNH+RwY1DL6HRi+UG8oYW0Oh2emHhw+JauqiNA1/hxIWyhieQ44tVEXoZdmU0mg4Y6xxhYTcdEYIp49xqDWt1OzCRc+PAV9udfOuOw1A27Ygg3b9xiNaeCmOnF87KGAJuJcDrBmd5moO0mg2Df052JbViDnLiW5Lie/1qDtwFMCO5AHZ4bGlQ7WQ5w+tXkF6pWJgopAMC6WzRPe/1zHXgGsC20Uzbe8KfIcaAQyeWWhqHTuP2/JqJtObWJGo32cs4cnoVX3viTNvwbj42rto+Ci1FgYilqmmLMFYAUoBDD5qDlB3Nsc1LWJzfgLDjJLiojcPrL5vC//roLdg9kQtsj8tzeNwbUIaeikzU3Fh08u//1teP4oP3/iiynRsVeQVU80JI41bUcag0XN9tRHPocyUaFqTjwEs0AIgyB0PDQslEw3aEiywOOalIH0dAkG6lOXTBHHo1Dvxhlf3DfDU+N4CaRU2vTAgQDWU9t1rDz/3h93F6OVnEWlj4B1yWAwRF3EGDZ2BfMpVvy+Z4JjgA/Pjl5RbGobNbaW6tjm2jWUwWjMR5DvzarrU5NhekCxkd+6bygYilSqMZcJumdU9z6CE0erHSCIwn/p1A99Fe64WL2jhMj2TwpiumA9QOiM9zePzkMkYzOq7cNhIxDjy0st1EXKpb+MbhM4EmNxzc7yobh2rDRt7QBKvpxBy4gRmV3UreCqzXWkKMMTTszpoDL6EBxDMHrqeEJ63AflJkE4fMHOoJXEytMAjNIa1RYAKbHWDNItkIhpPgnj1fwvNzZTx5ajXRsVZijEM2rYlclPXCXMnEWC6NsVy6bZAAdyvtGs/hJ8fjmcNIArfS+bU6ZosZjOXSiTUHPp7aCfOW7T4rhp7C/tlRvCBFLPFnkqMfzWG+ZIowVo58TMTeZuKiNg6tYOipSCP6J06u4MY948gbWmTw89ftxN8Hjp6HaTuxqxb+IMiDturVje/eOMhupf4GW6torjByhibKeRcizEEXk1I7t5KupZDRU8GJ0nQzm4HgpNmKRbT+HU1k0prvI+7WreQ9yHLi4yCzpOVxE2YOfOGQVC9YqjQwEaPtzBYz6645zBYzyKbbZ/QveS66n792FkdOrwjm1YvmsH0si7FcOrHm4BuH1vvz5z6tEa7cNoLjUsSS2wUuahx60hwqjYCGBUSbY202lHGIQUZzmQMXiCumjWfPr+E1e8fdwR/yqfLXDa/eexzuP3wWgHvjwysNbjDkQV63msgZmihi1ylkk9PwAHPwch56dS0J49DBrQT47CEfZg5pTSSNtROkAffhkFlB2bTFKjgut2E0qycKZRXMoVfjUDYxPRp8kAcp8ga1puCkyCfJpJFGK6GoMI7Z4vqW0LiwZmK2mO1oHBYrDYxmdNx6xTSspps/oqcoMOkWs2k0mk7b41xYM7FtNIvxfHLjwMX+tm4lPuY1DVfOjgYillzm4I/vXjUHx2FYqjQimoMoN9OnTjgoKOMQg7D74cnTK3AY8OpLJrxeD2HmEO8K4Zhbq+ORFxfESiG8KvKZg+xWanpuJfdcOvkhY5kDr1Nj9hbq16owYRy4KB0OZZUf+nZuJXffoEZSbTTFNavHGIeJfLIEQR5xxX9HmBV2wkI56h8u5nRk04MpaMfv3VguHTHk/L35BNqG4zAsx7iVAM84rKNbab5kYmY0g1xaa3tPlioNTI4YOHDJJIhcdy0v183RqTJr2XSDN7aPZTGeM7BSbSRynXLD286txI2Doadw5ayb18IjlqqNYJJnr26l1ZqFpsPauJUUcxha8JUyHyg8v+E1eyaQTaeizEEyFnFRFn/35Fk4DHjfa/cCiNLaOOZQbTSRS0vMoUNUDD9GMcat1Gt4ZKtQ3zhwUVqO5gB8oRkIxt7HgZft5iibtniAwjqDniKXOSQsvNdftJIZMQ5EhO3F7EA0Bz5mZouZyOKC39ckzKFUt+GwePfd9mIW82UzNlquXziOmx3tModUWza3VHG7n43l03jV7GgkAQ5Ax4Y/nK3NFjMYz6fhMKCcwHWaRJDmE72hp3DpdAFaivCJrx7B/t/+Fp4+uyZKuABSElwP4wkI5s0A7nOWouERpDvWVroYEZ5EHj+xjMtnChjLpzsyhzjjcP/hs7h+1xhu8iqZyoOTh6ACoWglb9XMNYdOA4YfI86t1GsinK85dHYr8aqSrZhDihDIwYhDPqNHBOkdY1mkNQrlNjjCcCYJZeXMoRfjwBjDYgxzANzV+CA1h9liFmeWgzHufIJM0sltSSTAxWsOTYdhsWyKpLhBYbnagNVkmB3NuElcVrNlvaHFSgO7vHj+1+6bxLPnS4EEOACiBEyrcFbOgGaLWdieS2e1anUcX5Uk0Uq2gxQBWoqgpTT83p3X4oW5MrJpl8W/w2u7Crj9HIBeAhy87OiQESciFIz+qxoMCso4xEB2K/Hktzuu2gYA3soozBxau5VemHMb2nzqndeIh0CmtWUvBBWIi1bKCzG43mFCi3MrFQRz6NU4JHcr8dLdhQhzcM9nIm90rGRbCDEHWZQPi9BZL5KrU15AU+r214vmsFaz0Wg6EfEQcNlSvyXRAd/tN1vMomo14ThMXCuhOSRgKDw7eryFW8k9zuCNg8hxKGaFS6RV8uRSxcT1u4oAgNdeOom/fOxEG+bQwjiUfOPA3XArVQt7JtufJ9+3rVupGexf8sHXX9Jy3141B7+uUnTBkQvpbpsJ5VaKAb/ppuXg8ZPLWKo08Np9bpmHOMFNnrjDVVDvP3wGKQJ+6cYdKObcQS+vXOQHIMwcAoJ0R83BgpYisT/QeQXWCb4g3XmYvP267fi9O6/F1duLge2cOYzn26/q+L7VkCA9kvEYQkhzyKU1z2gEJ/rvPHMB/+aLPxHBBNwQZNMadM2l7TyWPQl4dvTMaPRB3l7MYm7N7LugHR8D24tZMBYU3/l7pbrd0RCKnhltjMN6tAuV3Ty5NtF1jDHPreRey9ftc2fzqHFo3/CHV8OdLWbFuFpJUJk1UZ6D7YjnvxN61RxOLrk5K9tixpRbDy35+Pz6E6fx9NlkYc7dQhmHGPDVeqPp4E//+UVM5NP4pRt3AvCYg51ckP7Ry0u4cc84to1m/f64khEI/C0N2qrV7DrPYSSjB6i8YA49Nmv3NYfObqW8oeOuN+6LsANuHDrpDfwYsnGoes2DwqsptwR3CjlDC5TvBoAfvbyI7z07J44T7tnRqhx7K/h19+PdSo2mI7J+ewWftLZ5mcyyW0EeH50S7pZiiu7J5wqsTwkNfl7bRrPSeI1e45Jpw2oyTHljYftYFrddOY1X7x0P7MeZQ6vKrBfW6hjJuP0Pxj3DkiTXIUkoq8scOo93oPfCe9//6Tyu2j4aqw3l0lqgC2Q7OA7D3X9zBP9w5FxX358UyjjEgK8cnji5jO89O4eP3naZCDPL6hqaDgsMCLONcVitWmKFINxKMcxBT1GsIJ3WUtBT1DEqJ1yRFfCjlXqNfhBupQ55Du3AV5KdIpUA15jx62faTVhNhpGMLuozcdQ4c9BTkevCJ1ruYgl3+zO0wRmH7QNKhCvXbRQMTdw/OWLJLcPubu80sfMJMi7PYXrEQIrWp5c0L9U9M5pBzvCi62LGK89xkBcKf/mRW/DhN10a2K+jW8nLqQB81pEknNVnDnZLtucyh2S9GXrJm1mtWjh4Ylm4qcNwn4Fkz+tKzYLtsNixOQgo4xAD7nP84+++gNGsjt94g+93jFvJB6OVgjdWbmRSMDSkKOjz5NR5x3hWDPCm42Ym80gf15XVOc9hNCTIZXS3wU2Srlpx6Mat1Aq5LphDLq0LhlCVmrlHNIeGWw4jZ0TDJvlv5RNllDloXQmIfumM9VuN82q6fAEiLzBKdQuXb3NDKjvlKSxVG9BTFIio4dC1FKZHMj0bsrrVxJOn4hsGXVgzMZ5Pu6Kt3prp8uzoyZhrKYOff7toJW6Yi10YB87Img5rmWjWCPVMb4de+jk8/Pw8mg7DW6+ONw45QxeNvjgch+GPv/u8MMIcraKeBgVlHGLAb/qZlRo+/MZ9gSgInncgT9aBaKXQRLxSawjjQEQo5tIB5sD/3j2eF3TXbyriG4dOzGEthjkAwdV4t/An1mQ0Ow78N7TLjuYoZDSvRpQfwVXwmENEczCiWgTQmTlkuuwPvlA2oaUolvkI5tBnR7iSaQs3CRA0Dmt1G1d4xqHTqn/FK27YqivZjvEcTi/3VvHza4+fwa985oexbSwvrNUFO862qQXG3V5THcaC7lWVbc0cTMx6ReqyXtRakuJ7FbMpXEGtdIdujEOc5vDp7zyHf/3nP275mX9+dg4T+TRu2jMR+37B0CJJcCeWqvjDB5/DP4bcRwttFi6DgDIOMeCTYd7QIpQ3E8cc7Ca0FCGbDpZ/MO0m6pYTiB4pZtMBnyd/APZM5rzm8EysnnmkTzadivjWwyjV7UCOA8dIggqXrTAQ5pB2z6ld0T2xr6HBYe738pVdwdDdzGkr6lbKeIxKToDi13M5xBy4Ue9acyi5cflxkVbbRjMgGoxbaSSbjpRPaHphzjvHc8imUx0ZylKlEegAF8Y1O0Zx9MxqTwL6fMkEY8DB40uR9+ZKpmBR7ZgDL7qXhEW26mIociqkYo/j+WT1lSpe4hzQOmLJanZjHKKawzNn13D0zFrs/k2H4aHn5vHm/TOiXW4YuVBQBuAvOMOFE3mwRJywPQh0vApE9AUimiOio232uZ2IDhPR00T0/dB7GhE9QUTflLbdQUSPE9FRIrqPiPTQZ15LRDYRvbuXH9Uv+ETywddfElnx8hWovPqsWw6yeipSIptTXTmOu5gLtkDkk9mu8TysJkPNaoqJkBej65R16h4n6lYC3Mm1b+PQh+bQFXPg5QMaTYk5aMhGBGlHrBjl8wT8B4mvJMPspxfNoZVPN81dNX3W3y/VLYxKzMHv7eD+X8zqXv+I9gwl3FApjOt3jWOtbotomW7PEQB+EmccvAqpQLBveBiLlWDf5HYYzaZRisnsX5JyKjjGcumOlVntpgPTdkSZl5bMoekIRtAJcbWV3Ozt+GM/eXoFS5UG3tJCbwDcZyBSQsU7XsQ4xFQLHiSSXIUvAnh7qzeJaBzAZwDcyRi7FsB7Qrt8HMAxaf8UgPsAvI8xdh2AEwDukt7XAPwBgH9K9hMGj6u2F/E777wG//GOKyLvZXXuVgpHz2gohDqv8T65cqhemDms1SwYekqESq7VbLFyyAc0h85JcHFupX76SJsDcCtdvm0Et79qBrdc2iEIHcFucPwB8d1K/gNY8653Lh29F8KtVHGvse9WkphDF5rDQtmMDWPlmCoYgqX0irLnVuJ1qfwyDzzrPY3Z0c7NhZYr8aUzOG7Y7TawOXK6+9BHvog5eDyY1+Gu5E0RaRXnduVYKjfc5EWj83hqVXyPX4PtIeaw2uEecJF3p2AO8fubXYSyijwH22diFdNG3XJiI5j++dk5aCnCm/fPtDxmPpOcOSyUG5FqwYNEx6vAGHsYQHS54OMDAL7GGDvp7T/H3yCi3QDeAeBeaf8pAA3G2HPe6wcBvEt6/z8B+FsAc9gkaCnCv7n10tiMy4xYrUZXsiMZPeAv5sxhPGwcApqD6w6Soy6qwq3kM4d2gjRjLDZaCXAn1yTMoekwfPwrT+C//M2TYtsg3EojGR1f/PDrsGcy33FfLsjWLL+rXsHQI8yp3vDzHPj+HHyFu9yKOXRwK4VFULeuUptS40bnRLxOcN1KOkYMzhya3rn4iY3bipmO/RiWq1ZbhrZ/dhSGlsJTZ3owDt7q9acXSoHxu1xtwHb8lTxnc3GJXLx0RhJM5A1xD2Vw4yAn8o3njI55Dry8xo7xDsyhC80hlSLoKQoYAp7nFLcg+96zc7h570RskiJHPq3DtB3Y8jG5cViLCtJThUxLjalfDEJz2A9ggogeIqJDRPQh6b1PA/gEAPlpXACgE9EB7/W7AewBACLaBeBXAXy205cS0ceI6CARHZyfnx/Az0gGnzkEu5Fl0qnIRBxXq76Y0yPRSsVsOmAcaoI5uJNFJh0N2ZRRs5poOizWrRQ2WHFgjOH3/v5p3H/4LH708qLYPgjj0A14XaaKafvN3DNaJM+hZjWRM1LCePJrIwvZKxFB2mMObdxK51ZruPn/+g6+/fR5cbz5shnoABfGIBoqlTzWx38/FyS5oSrm0qItaSu9gDGGlWr7VqyGnsLVO0bxVI/MQUsRGPMbXwF+WQ+hObSpBbYYU4m0FaYKBhbLccbB/b7txe40B/4M7EygOXQz3tNaKmAcuFEIL8jOr9bx9Nm1ti4lwM9Nqsaw4ShzaM9q+8UgnnodwM1wGcLbAHyKiPYT0TsBzDHGDsk7M3d0vw/AHxHRjwGUAPAr8WkAn2SMdeT9jLHPM8YOMMYOzMy0pmmDRlwoq2k1kdW1iOaw0sqtFGIOoxHmEIxWiovKkcFXFnEhjKNZPZK1Hca9P3gZf/HoCYzn0yIWHXDZkaGn1m1lEkZeWnVWJLcSj9ZyvPwS22FB5sDDXxtNcG2a+6BjmUMLt9LB48to2A6+88wFAO6k3bCdtj7dOB9xN+AGbTSjI+31J+ar3DWJOcwWMwEtJoySacN2WMd8kut3j+HomdWuG0Ct1W28es84tBQFSoY8c84VX3d53RTb1QLrhjlMjWSwWG5EjOH51TqIghnrYwnKdvPrJjSHFvs37OSaA+CK0vJ4qgjDHrxP33/OdYS0ym/gEAueRtQ4LFUagYXNfMlct0glYDDG4TSAbzPGKoyxBQAPA7gRwJsA3ElExwF8BcAdRPQlAGCMPcoYu40x9jpvf+5iOgDgK95n3g3gM0T0KwM4x4EhLgPUdSulWruV8jJzSAd6OnAhOcAcrKBbqZPm4PdyiHErGe2Zw7eeOof//o/H8IvXb8e/ve0yVBpN8V2m1d0qql+IPtKNps8cPLcS4LKAmog+kgVpd5s8cXIdICyqt3Mr8Tj+R1502ZMIFRxt4wboImkpDtVGE4z5CYsjGV3keMg9OuTaSHFYbpMdLeP6XWMomTaOL0Y7ErZDqW5htpjFNTuKAd3hLx87gctnCrh+l6tncIYWFy7cjXGYHjHQaDqRhc1cqY6pghGYwMdzBky7ff8H/gyM5d2osHaCdFK3EuCOJ/4sO1K717B78vhiFWmNsN8rA94KhdhcF/9vntvA/14vMRoYjHG4H8CtRKQTUR7ALQCOMcZ+kzG2mzG2Dy5T+B5j7IMAQETbvP8zAD4J4HMAwBi7lDG2z/vMVwH8e8bYNwZwjgNDNkYEDQjS0kTBjYPs7imGsj9LdRvFXLzmkE+oOfAVZpxGMpJ1S1K0KtX8P3/wEq7YNoI/fO9NYhXCo0qS9I8eJPxQThsV00aK3Ost99GuS8bBX6VyQ+tnm7eMVmpnHE67xuHMSg2nlqp+9cx1ZA7coPEKunlDi6w+i1ldRAO1ynVYbpMdLeP6XW6pim51B65p3XzJBJ44tQyr6eCJk8t48tQK7nrjPsEuDa112enFitkxx4GDu5/CrqU5r8mPjLEEJTRkDcsNCom/Z93UVgI8t5InSFdC5eZl8GTYTiw8Fwpndo/l/y6uuTiOVy14M91KRPRlAI8CeBURnSaijxDRvyOifwcAjLFjAB4AcATAjwHcyxhrGfbq4W4iOuZ95u8ZY9/r61dsIOJ8qnWvgf1IRgvcyNWahdGsHohp9iuzWuL/0UxarBzXZEE6zZlDe80hriIrh0isajGBrdQsvGp2FNm0JkIMF73ViWk3N5Q55KVQ1krDRsFwa0XlJOG57hkCudcFvzb8gdw5nhMr6bDmkNHik+DspoOnzqzi1iumAQCPvriYKFQwn9H6as4iXIISc6iEopVc5uCeQ6u+DkmZw5WzI8joqa4jllyGq+O1+yZRtxw8c3YN9z1yHKMZHf/qNbvFfkQUy3SrDTeKZzJBGCuAyFjkmI/xsycpvleWNCw3nDzekHST5wAENQfZIMS1e+1UUhwIhnNzyMyB6w6rXumMdnpYv+hYspsx9v4E+9wD4J427z8E4CHp9d0A7u5wzH/d6Xs3A36ST5xbyW2ubjcd6FoqUDqDQxTf8wYnX5FpXvOa1Zolkmu6dyvFC9KAK5TFDU45ymkytFozbaevHIduERSkbeFmykp+WM6AcoYm6vjwa8PFwD2TOZxcqrqx7Zbbh5qvBltpDs/PlVG3HLz75t149vwaHn1pUfTf6MQcGrYbutiNr5pD9OHwfqvLHDzXhGmLJkXbOrmVqsmMQ1pL4Zqdxa6Yg9V0ULccjGbTOOBVJ/7Ho+fwD0+dwwdff0lE64rLy+FjqlvmsBDDHF41OxrYlqT4nmAOGT2i+8kwu4hWAoKagxyhFC4auFa3MZog5DQnsWeOct3GzGgG8yVTGIf1Lp0BqAzprpFp5VbSNRFpwFeSqzUrUqpa7ulgNV0fOt82lksL5qClSExo2bQG03ZaiojtmEMhlFgV/awlPjfNV2t81W1tsFsp7VPqSqMpjIVcBlroMWlNnBvfxo3kngk3bHa1ZnmuMV9Ub+VW4nrDTXvG8frLpvDoi4tYKJtIUfuM3n6bwpdDzKEgMYdS3RJjg5fXaJXrICqyJph8b9g1hqfPrCbuClcKCONZ7JnM4c9+8DJsh+GuN+yL7B9XC0yUzkgooHKDzHsfAK4rJS5CZyyfwDg0/KCNYm7AbqU45hA2DjUrtoJBGCJaSWYOpo19U/lA4cR2Nb8GBWUcuoQ70UQzpDNengOAQDhlhDlIPR3Ck/pYLi00h3xaExNaXFa2jHI7t1K2tXGQV4SA7Of13UrZDWQOuhetU224eQ78esruI+7LzqRTkWxcLl7ynIrlqoW61QwYuFahrE+eXsFYLo1LpvJ4w+VTOL9Wx0+OL2GyYLQsdQBIInqPWejcDcl/qxxAsFYL5q5sK2Zalu1eqbr9PJJMQNfvHkel0cTLC+VE5xhmpgcumYTtMNy+fwb7pguR/eMaYnHj0E2eAxDUHHhORbhcBM8bWG3jVqqYbihuRk+hmI13KzHGehKk+XgKupWirYDDHe/ikE9H3Urluo2xXBrTI/79F31GhlyQvqhA5A4wudaR6fUXECWypbafLd1KNSvy0HHjwAvLcfBM4Fa6Q6lugSjaohPw3RVxSTnlUAhs3tCQ0VPiQear7o0E7wZXNZu+IM/LQDeaQusJ9NeOuJVc47BSbXgdyfzf0MqtdPjUKm7YPQYiwhsumwLg9uLoFA2Sj3EDdINwGLKcN7EWKokyO5qNVObkWKq6dZWShB13mykdXsS8zst2v+uN+2L3j3ODdlM6A3Dv01guHdAc/MZLQUE6mVupiYKh+cUvY0JZmw4DY+iBOXiCdIsII8A19Ek0B5HrEhK3RzI8EdK9/9zdNux5DhcdMnqoSqjtRysB/gpitWZjLBdcKck9HeRoFCDEHCTj0Knhz5rX6CeuOFy7lW34oSciTI9kxMDb6GglwG/4U5aYQ1ZyN/GOeDkjGq3Er/tuL+Y+ljnoKTQdFnCp1BpNPHehJDSGS6cLmC1mwFjnujV+6GGPbiUzeA94ZVogWkxxtphpqTmsVNuXzpBx+cwIcmktsXFYC4VK/6vX7MIXP/zalmUg4jQHUXSvCzfI1IiBBamRkmgqVAzek7yhIa1R21wHeTy5mkO0pwNfNPSqOfDnKUUxbqW6JbwG7RDnpizVLYx4EWuy5rCepTMAZRx6gkub3QHhNv5hIgkOcAcGYwyrtahbSe7psBYKdS1mfeOQk1hAOBM4jFILsRmQauPHGQczKmRPFgzh5zWtjY1WAvxyFG4Pbc5o3P/DmgPXZeRopVxaE1R7uQVzAIINWp4+6/rfb9ztGgeZPXTy6RY6RIN1Ap9EChJzqErMQb6v29pkSS91qKskQ0sRrtlZjG0v+bnvv4h3/PEPAtv8RYx7Lhldw+2v2taSpbRiDoaeQiFBXSWO6UImyBxK8a4UIsJYzmhbfE8OcCjm9NieDnxMdJcEF9Ucto1mA89b3WqiYTuJJvKsroHIz5LnSZIjmTS2jfqLg/nS+pbOAJRx6AnZtCbcG3JJaLkef81yO5mFB4Tc02EtrDnk3e01yw4wh0ybMshAUFQOI65HgP+5qFYxNWIIt1LDdkQtqY1C3nOrlM2meJgDmoNkHICgf5uvsERoY7URqzkAQeNw2BOjb9gzJra98XI3pLUjcxAlL3pnDtl0SkxIBcNtRtSwnUi9rG2jGZi2EyumLlesjjkOMi6fKeD4YrQ668HjS3jm3FqAWbULeIhDXG/vpXIDU216TcRhaiRYQoOvmuNcKZ2K75Vl4xCKGOTgY6IrzUEyDvwZ2z6WDSTByQUUOyHl9YHnhsu0HVhN5tXXymKxYsJuOuteOgNQxqEnZCW3kpyUJQvScdnRHLwyKx9AY1K0Ut1ysFK1AsahXRlkwO8fHYdCG80h1jgUMsFQ1o1mDmm3jlK1YYtVplzMzRekuR6hScbBFqWv9RRhuWpFmAP/PWbTv5ZPnl7FrvFcILnqDZe7zEGu/hl7vkZ3zOG+R47jjv/3IRF5VvJWhRz8flUbdsToiyzpGN1huQu3EgDsncxjvmRGtJKTS1UwhkDznHah0nGI6z/STXY0x9SIIbQKwF0tFwzffSvDLdvdXpDmhlyOGJTRm1vJT4IrmTYMPYWpghEQp7kRSiJIA+6Y4hGPsttx26jr6lysNLzs6PWLVAKUcegJslupLiVZyav0uLpKHLynQ5g58MFzYa0uJkQgvtifjJLZmjkYXpx8XLRSOcatNDViYKFsgjG24UlwgLsSL5lu2XI/z8EXX6i+EwAAIABJREFU5HnEls8ctIBbaSTrJs6N54145hDjVnry1ApulFgD4IraX/rILXjva/d0PF8geSjrkdOreGmhglPL7qo9zA64huHqJU5gtdmqLSljzDUOXUy+e6fcKKNTS34vCsaY6PWwVJGNQ3fMITbPoRfjUMi4EUrepD1XqgeqscoYz7UvvucK0smYQ1eF9/QgcxjJ6G6DLbl0fy2oLXZCIeNX+pWDRniU1tyaiYVSY11LZwDKOPSETDqeORRimEOscQgxB25U+L4L5UYwWimmGJcMd4JpvSoZbVG2O545GKIT20bnOQBu9zue4MMnXl6Soe6Fsmop8hMFpXtRlibaiXway5Uocwgbh6VKAyeXqrjB0xtk3HrldEdXQFzf53bg0Sa8W1i5bgVYHx9D51fd/eR7s3PcnRjlCR1wx0u4AU4n7PUiuk5INZbmS6ZYgCxWgsxBdn11QpzmsFRpJE6A45geMcCYXxpkvtS6Qu5Yh8qsAUGah5OHNArOHHotvFeu++1e5WilbpmD7FaSo9m4YTy/VneZg3IrDR9czcFjDlLtHkNPwdBSKJvNzsbBi1YqGBp0bzDK+8ZGK8WUQQaiq88wWvV0iKvmOsWTj8qNDc+QBlyf+6IwDn4UVc5zN/EWoXIOCPdvyxMA7wcQ1Rzcv3n44Yvzbqz/VduDWbdJ0W0SHI+4OeqJwfI5A34o4/k11wDIRn/nmNsulJ8zB399+bb2Rd1kXOIZB7kr3Anp7zBzSOpSAtzFTDRaqZG4dAbHVCgRbr5kYqYYf4zxnNE2Wqna6EJz6MI4GCFBupDRvS52knHoQnMAvKAEHrEmsXteQuX5udK6l84AlHHoCVkpz4GvtPjqdCTrJjHFdYHj4D0d1mrBOHZ5X9572f27PXMod3h4W/V0WKtbMLSUMD6AX95gvmyi0WVt+0Egb+ii7HYhFLHFBWn5fLPplAhvdbUX9zrwGv9ugmJr5rCYoLheO/Ay20k1B585rPrnLBl2bijOecxBXm2mUoTLpkdaG4eZ5MZhPJ/GaEYPGIeTkkC9GDEOyVwigPt81C1HRFWZthuanDQ7moOPRX6P2jGH8XwaZdMONOGSUZECHFpqDj0I0nKeAy+9Ppp1S6rwc1lrs1CMQ17qIy0nuE6PuD3Lnz7rsk7FHIYQMm02JbcS4LpCAm6lVoK0xxzkh072SQailXjJjpjM3rrVRKPptH14R1q0XCzHPPT8AT7n9UXe+DwH//tk4ZE3/Kk3glnbsn9bFnA5cwjnagjj4AnSvCZRt/5wGQWpkmo7NGxHuEiOnlkN9HLwj+X+fSHGrQS47CBiHOYqyBtaoAFOJxAR9k7lI8yBBxPJfT3CyXidwGthmZLrDuj+GnPmsFA2UWs0UTLtSI4Dx6s85nco1MYUcK97o+lgxGNl/Jq2cit1L0hLzDWrB0LaAUS0xU7IG5qIfvOr9rr9PibzBp7hxkEJ0sOHbNqv7FkLGwdDF8YhRRCtH2Xwng5L1UZgZRhgDoEMae9hi4lWCifSxUGu9Bn+7Ejoc/wBPrvCjcMGM4eMZBxC16BmuRnSsljPo5XEROv9nvGCyxx49joHdxn0O3HJkHMT2oFn+F6zo4jlqoWzq3UxofjHcn/buRbG4YqZEZxergV8+i/Ml3HZTCE2CbId9k7mA2zh1FIVO8dyGMulRdIaEE3G64RsKPSar/y7vcbTUiFInuMQLtfNcduV08joKfyT16hJhlx0D3An9LieDj3lOei+5sDZCb9nfGJfq1nI6EGG3g55Q0fVCpZt52NkZjQjenEot9IQIhMIZQ26lUY9t9KKlwAX98DyB+3Mci3IHDpoDnFuJR650q4v7UhGbxHKGo1y4uUNzq64x914zSEqzgK+cag1gqVFsrrvbnIYApoDbxbTLlppqdJAXsq27vWck7iVeNG0t17tdgN76vSqEDHFsbgg7e0b9lNfvq0AxoCX5n0h+cW5clcuJY69U3mcXq6JnIYTixXsmcy5LTpDgnQ3bqVw0iY/Vrcr3WI2DS1FWKyYwh3XKrY/b+i49YppPPjMhUiSYDlkHPixW7mVulkQyZpDSRKk+WsgeV0l/7fEMwfAjVjjP0/lOQwhAqGsnDno3K3EmYPd0sfIB8r5tXqArqc1P4NUNg5pLQUtRbGC9CMvLgCAKKUch1aCtOvSCJ5jztBQMDScWdkct1Iu4FYKGkguSAc0B485hFdYE5I7Ly7PgU8Ey11kFrdCPqMlEqR5EtfP7J+BliI8fnIZdqj3NzeOQnMIGwfPCHDXUq3RxJmVGq7oxThM5tFoOsIQnVyq4ZLJgpslL7mV4sZJO/gNsbgB9kpndClIp1IkzsVnDq2P8XPXzOLMSg3HzpUC2+WKrBxxPR16dSs5zK2UUPZCysPFLt26SsmNq6w5lOp2QBfkv3+9S2cAyjj0BJ4hzRgTE7avOfhupZbGwXvgmw6LDBr+mVzIHeVG60Q1hx88v4Arto2I3rhxGM22jlaKWxFOjhiS5jAkzMEzAjXLCbqVvPLQ4cgrmUnFaw7exFVN3vS+3Tkn0Ry4cdg7mccVMyN47CW3HansVsqm3bBdHs4bdvtdOl0AkW8cXlroPlKJ45JJN9fh5GIVFdPGQtnE3qk8JgtGTLRSF8whxHRFL4cervNUwcBCudE2O5rjrVfPggj4zrGga4nfG3nBFdfTgTOAbgvvAbxLoYOCoQtD2jtz0EXP9LJpBcYA11zWu3QGoIxDT8imNTDmTjARt1KGRys1MNZiRSoPlLDQx9/Lh9wc2XQqwhzqVhM/fnkJt1053fZ8C4YumhDJiNMcAHfgCbfSJtRW8v+OupXCgjTvkhfuoy2zgTjNQXYr9c0cjGTMYX6tDiJ3wrt2V1FELMmCNBGhYOhuX+mMHikXnk1r2DORx4ueW4n/35NbSYSzVoQwvXcyH8hMtptuzks3gnQmFHq9WGkgrVHgdybF9EgGixUT8yUTWoow2eZezYxm8Oo943gwpDvwLnBB5tDarZTusvAe4HfiG8nKmoM7JtstFOMgt8UNux15ImS7vuaDgjIOPSAjZSzXI9FKrn+/LXOQqjOGV2TCOBhh46CJkE2Og8eXYdoOfubK+OqYHH4p8eDnw4XdOKakleOG11Yy2gvSPM9B3t50mEiA4pOY7FbqpDl0m5wVRqGF4B/GnFcsTddSuG7nmAjZDZc+4Yyp1Wr98pkCXpxzGcOLc2WkCLhkKt/1ee8cz0JLEU4uVYVxuMRjDsvVhrdy7S7SBpCaMwnmYGKyy7pKHLy+0lypjukRo6Po/nPXbMdTZ1YF8wWigjSA2J4OPeU5eOOJj7+RjOa7leq+IJ00xwFw64sBrjssXBqHu5XWW4wGkvWQ/gIRzRFRy77QRHQ7ER0moqeJ6Puh9zQieoKIviltu4OIHieio0R0HxHp3vZfJ6IjRPQUET1CRDf28+PWC1kpeohHEHGD4U4UTSxXLYy1KNErD5Qw3fTdSjHGIcQcfvD8PNIa4ZbLJtueL1+xlaQGJOHoHhky/d/48hm6+F5dekhFKGuo1wW/FzwSKM6tFJsh3ZQ0hz6NgywgtsNcyRQP9/W7/XIdYfaWD4VchnH5zAheWijDcRhemC9jz2S+J0Fd11LYNZ7DicWqiFraO5nHZCGDpsNiG1IlQThp0zXAvU1mU15l1vmS2TJSScbPXTMLAPiOxB7Coi6A2J4OZo95DoDrnnS/Iy2+Z00KZU1SrpsjL7nlSqFnlPeyWO/SGUAy5vBFAG9v9SYRjQP4DIA7GWPXAnhPaJePAzgm7Z8CcB+A9zHGrgNwAsBd3tsvA3gzY+x6AP8NwOeT/YyNhd9fwUE91IaST8SrNQvjuc5updaaQ/Bh5xnCMn7w/AJuvmQi4H6Jg9/Twf98pdEUroswpqSBt9HGgf/u2L7EMYI0358LluFSJEBr5lC33Hak/YSxAsmZw4W1ushyvXpHUeQUhH/riGAO8avNy7eNoG45OLNS6zlSieOSqTxOecyhmNUxnjf85LNKQ+rl0EWGdKjPxmKld11nasRApdHEyaVqouicK7aN4LLpQiCktdoqWinU04Ens3VVW8kzDrJbKZvWvEoJ7vG7ZQ6i3bDZjOQi8cXFeifAAQmMA2PsYQBLbXb5AICvMcZOevvP8TeIaDeAdwC4V9p/CkCDMfac9/pBAO/yPvsIY4xnsTwGYHfC37GhENEYtruSlScreQC2civxng5AdEU2JjSH4HY5QgpwJ8Nnzq3htg4uJUBuFeqvlNpV2pTdLBsdrcQFaTnfAfAzpOshtxKPEuPGgV9PQ/cLIbbKcxhEAhzgMoe65XTsyTwnrX5HMjou9VpshscAd621inDhxuD5uRJeXqjg8ploq86k2DOZx4mlKk4sVbHXc03x67FUaSTKownDj1byBelerzEPf315odI2UknGz14zi8deWhSMgVc4laPf4no69NbPwdMcBHPwFjde8b2a1YTtsK4EaR6MUm3YkfIq28eyuGr7KG7e2zo6cVAYxLJwP4AJInqIiA4R0Yek9z4N4BMAZCV0AYBORAe81+8GEFf68iMAvtXqS4noY0R0kIgOzs/P9/cLuoSc5FMPJVnJA7CVceA9HYBoqGI7t5Jcr4aHsHYSowF/wMpZ0u36TgfcShuc58B/d7jlaTatwWHu6i6WOYTqMQF+ufRW/Ry4rtKvID0i+YhboekwLJbNQIbvdTvHAp8PH6/Vav0KLzLp4ecWYNpOf8xhMo+VqoVnzq6K6KVJqWyF71bqgTlYg3ErAYDDksf1v/HyKVhNJgT/smkjrVFgHMTVV2o03aKO7XqGh2GEmYMXqeQW37OE6N0Vc5DqdYWTJNNaCg/855/Bz3rus/XEIJ58HcDNcBnC2wB8ioj2E9E7Acwxxg7JOzOXx70PwB8R0Y8BlAAE/CVE9Ba4xuGTrb6UMfZ5xtgBxtiBmZnOq+dBQmgOthutJE9W8mQbVzqDgw+W8EP32n2TeN2lk5E+EOFKlw8/t4DxfBrX7gyWmo4DH7CyW6ldSr8cj75Z0Urhmv1hETr893zJRC6tBVZ9fNKXjXfKq+jaaDoDyY52z9lb6bXRHRbLJhwWjNO/7cppTBWMyKqSH6+Vn3+yYGAinxZROVf0EMbKwSOWFsoNwRz44sBlDsEosCQQ0Ure4qmXukoc8ueSModrdhYBQJSZkLvAccTVV2rYTldiNCC5lbggnfXvXdm0hfHpLlrJZw6luhXo97GR6D62LIrTABYZYxUAFSJ6GMCNAF4D4E4i+kUAWQBFIvoSY+yDjLFHAdwGAET083DZB7zXN8B1Q/0CY2xxAOc3cGQk2ly3moJJAMEVb7sBwQWq8EP3hsun8IbL3xDZXy5NzRjDv7wwjzddMZ1olcPZTLxbKS6UdfPcSryQXcQ4yCJ0TN2phZIZEXbjmAPgrvZk5tC/5uD5iNswBz9O3xdV333zbvzqq3cFhHf3eO7vaOeKuHxmBAdPLIu/e8VeKcqJGwrfrWSKxUtP0UpWU1zjXiPCZOE1KXPYNprFzGhGFKgrm3aEicYxB6vJuhKjAT/sVQjS3vfwst28xlpXgrQ3vperlugCtxkYxLLwfgC3EpFORHkAtwA4xhj7TcbYbsbYPrhM4XuMsQ8CABFt8/7PwGUHn/Ne7wXwNQC/IWkSQwffreQK0kG3UkLjwPtGJ1xRyJrDTy+UcGHNxG1XdHYpARBJOWVpZeuHKEa/X34gN9qtBLgPR7jXcBLmEI6jj2MOgKtHNGxHuAI2gjnw8g+yW4mIIoYB8N0K7SYFbhAmC0Zf0VbcIAB+Ge+MrmE0o2Oh3GirTbVCWiOv/0b/BlhmDjMJopU4rpV6ZMtd4DjiejqYttO9cQjlORSkSLNS3e66XDfg6228NM5mGYeO30pEXwZwO4BpIjoN4HcBpAGAMfY5xtgxInoAwBG42sK9jLGWYa8e7vbcTikAn2WMfc/b/jtwBevPeNE/NmPsQItjbBqyIeaQaeVW6mAcUoTEDdfl6qP3Hz4LLUV469XJ/I6COUiaQ7sQRbkX8Ua7lQBgezEbac+ZbWUcvOtXMm1cGhJmJ1oxB91nDkTdUf448HvYljmsdS7/II7XQXMAfFdSP2I0/w6eEb1HMhSTXi/xjJ5CxusmmBSi/4bVFJnevbqV8oYujpXUrQS4xQ3/5fkFmHYzUK6bYzROc+jBrWRIbqVs2g+/Hs2mUTbLXTf6AfzFxlwoAm+j0fFbGWPvT7DPPQDuafP+QwAekl7fDeDumP0+CuCjnb5vs5GVaLNpNQOZ0HGCaBzGcmmMZtOJE4O45tB0GL7xxBm8ef9MYpqtaylk08GeA+EudDIyuiZ8pt0+LIPAlz56S8AAAOFChFKGtB5vmAE/1yGWOTQdLHl9l7sRIOPAk5bC/ZhlJCn/wCF6HbdjDttco9CPS4ljz2QepbqFneN+CRZuMHjzmm7Bx6vvVuo99HJqxMDp5VpXheau3TkG22F4/kI5Np8nXFYbcHNfumcOviAtawMjXhmdtS5bhAL+4ocXahxa46AQhdxfoW45mJUGFL+RaY0iE5yMD9+6Dz+zP7mQnk1rMG0Hj7y4gHOrdfzWO67u6pwn8oZYxQEucyCKRgVxTBUMWE1n3eu3xCEuwSeuhHl4e/ghunpHEdMjUcGXaw4N2wlkUvcKwRw6uJUm8ulEGk64Y1kcrtzm9i/oR4zmuG5nEY7DAkZyqmDgzEod4/l0VxMbB4+uE26lPupXTY1ksFqzukr0k0XpimlHel1wYyF3bLP6EqQbAePq9lCxhObQjYHVUoRsOoULazw8+5UrSF90kDOk63YwzyGjp6Cn3IqJ7SbWq7YXcdX2Ytff+Vc/OonRrI6fTehS4tgzkcdpqfcwT8tvVY5gaiQjIjCGAYHchpgMaQCRqI63X7cdb79ue+RYhu4a2rJp9bWi5UjCHC6sJcvwBeRQ1taP557JPD73wdfgTQl1p3b41DuvERnjHJMFA0+dWcW20UxPPu9sOgXTcrBQ7r2uEsfsaCZSOqYTLpnMYySj4+mzq6g2om4l/pz2yxwM3X1+TNsJ6BqjWR1Wk2Gh7EbRdXvcgqEPv+agEEW7PAciQiGjD7ycLv+OB5+5gPcc2NN1uYTdkzk8+qIf/FWq220f2KmCgVOboDe0QivNQb72SR8i7lZarljYN919TaIweIRKe+ZgtuxiFsbVO4rYN5UXSXKt8PbrdiQ/yTbIpqP9LCYLGRHK2svKlSctLlXMviuI/tY7rm57beOQShGu3jGKZ86teYlkwd9HRJFqxQ3bEQJzUsih0zJz5c/W/9/e2QfLVZd3/PO9u/fevW/JzZtpyE2MQGIJaCCmgICVglQMFDoqFZSRKhZn6rSUsVixOradaWdaHUWnFYYigtqijtLKMI6tFZF2RmmDYArGF4ZqEgwmEPLCDbk3N/fpH+ecvWffcnfPnr27Z/f5zGRyz++c3f297J7nPC+/53nmhZcS3QuGBnLFglvtMit1zq8/Q8SjMcr3OUCwmGkLh+iGODNrvGXz6oZfv3bpMM8eOlqsazvfj/78U5en8lSaFtXyKUFgIuqrkYaiFoO5PqZngkp8zUYqxft2Is1h36GjddvMN6wc46Gbf6skjclCE5gVjT0Hjya6ORXCgljN7I6OePmykaKZqBE2rlpUNCuVaw4wt4s5YjpRtFJcOMR8DlFBrwMvNRTGGjESq6VeLXPyQuDCIQGSig638vQZEDibGy1sMh/RZ6xdOsxrXt741vk1S4YxC55kgJpJ9yKuO28dn3zbmck62wJqhbJGkTHQmOYwFYaypiEcBvJ9YS6d6k+3Zsa+F+s3K3UC0bzsOXg0kVkj0hyayavULKeftJjJ6SB9RVXhMNhf4nMIzEqNaeSlwqHSxPnMgZcaCmONOJEvbaFws1JCoiypUzOzFMqeNv7mza+qO0S1kc8DePPm1YlU9DXF3P1HOHnFKIePzrS8QHma1BIOEPyQJqeP1/2ENZDvY+f+aWZmrenUGRFBNbjqmkO0mamRUMx2E3cgJzErDeZzPPfiNJNTM6xLkE48DeLaRrXf49hgFc0hYSgrlD7hFx3eR2caCmONiPwX8SpwC40Lh4QM5vuKYWrlNQ/OXDOe+uedftIizlo7ztt+o1oaqvmJNjvtCjWHw0ePsW4em3YnURK+OlD6A44igOp9whrI9RVLY6ahOUBUDa665lBtA1ynE9/RnFRzCMxKU6lr0fWyfuUo+T7V1hwK+eLaQKQ5NOhziF0f/4yS9OBJ5i9MvNkukxK4WSkxhf4cB8IwtYWQ7GuWDvMvf3j+CcuBnoiXjQ0ykO9jd1jUpdHSj+0mMh/1qbIYy1AdO4rj9Ieb4CA94RBUg6uuOUQb4FYuyp5ZCZIJh0K+j4MvHWNy+njbzEqD+RzrVwYhv9UeHEZT0BziZqV4gEd8zprRHNplUgIXDokZzPdxMMynUr7JqhPp6xMT40PFil/lRUSywNBAEFVTblaLzEz1JiiL3wBSEw5hkadqRBvgsmRWiof4JrWZN5tXKQ02rgpMSzUd0vF9DglCWfOxUPCSaKXYnCUJTok2fbpwyCAlmsMCJ6dLypqlw+x64QhTM8eZnpltKva8HQz156puLCzW727A5xCRls9hZCBXLCpTTtGslCGH9NBArniDSrbPYW6d0hLASTj9pNrCYSxMjheRJFpJUvFhI/4ZJbUjEgjX+TLzLgQuHBJS6O8r1o1tl8OoUdYsHWLn80cS5ejvBAr91Z1zhf7GnrLi+aLSMnkMD5xAczgUJAUsr9HR6UQ39aTpMyLaGZJ7ycaVvH7DCtavrNxJPlbIMxXulIdon0Pjt8Rob0T8Rj6Yn9v4liyUNblgTgsXDgkp9OeKSbWyYFaCIJz10NGZ4uaaLJqVqt1gk4SyQiAkTpTipBFGTxCt9LO9h0tSY2eFZUXhkGyHdPn7tIM1S4e5591nV316LxZpCjW+qQRmJZhL211RM6IwfxqUWgzFUn+3i2zc1TqQQj5HVH42K5pDFLEUFUHJmuZQ26xUvUBQLSIzwLKRgdRyRw0PVo9Wmp01tu862JIItlaztAnhMFSiOXRmyPRoIUplH9R6PnZ8lsFEmkPwmloV/ZpySLfxAS5bj44dREloZVY0h0g47AmEQzufSpJw5prxklKpEZHQqNckED0dNlMHoZyRGtFKTz/3IoenZtiUSeEQmIOaMSsN5Po69nsW9evw0RlmZg0zEmkOA7nqPq/RZjSHBoMsWkFnrloGiGsLWdEc1lRoDtla/j+/bGPV9rPWjvN8GBlTD9ENIE1H6fBAniPTx5mdtZJkho/vCgrOnJVB4RA98TejOSxNUTtLm7mNaseKfodmfA4VNSPCG3uSaKW5mh6uOWSOLAqHxUNB+uUdoeaQ5ImmE7n67LVcffbauq+PnvTSFA6RGeDIseMlT8qP73qB0cE8J6dQd2GhuWLTSRTyyXboRtp0p5qUIFbTYWqmKBwS+RxqmZUizSGBQ7rRvTutwIVDQuIRL1kRDhBoD1Ft3XbaM9tJ0ayUUhgrxEuFzpTcJH646yCvnljcdEGhdnDG6sWcsXpxotcWYppDpxJ9/1+cmuHY8eaFQ3ltlChUPIlZbcQd0tklnjKjPLdSJxOvGZw1s1JatMKsFGkO8XDWo8eOs2PPoUz6G5olEg7tjFSaj7GYz2Eq0hySmJXyfYwM5CpqoywdGWB8uL9qnfD5+LVFBSSYWNK+KLfevDukQKlDOluaAwT9T2Jf7QYGW+RzgLmwSIAnf3mImVnLZKRSs0Q+h3bucZiPsVi00nQTmsNATlW18Pe+/hR+Z9NJifq2dtkwj9xyMS9rY8qVeWdC0l2S9kp64gTXXCjpcUlPSvpu2bmcpMckPRBru0jSDyQ9IekeSfmwXZI+LekpSdslbW5mcK0kvis6U8JhSZCbKWthrGnSEp9DZFaKaQ6P7zoAtCYRY6eTBbNSob+PXFgNbroZzSHXVzWMesXYYFNaYzsFA9RnVrobuLTWSUnjwGeAK8zsdOCqsktuBHbEru8D7gGuNrMzgF8A14Wn3wSsD//dANxW1yjaQPTl788pU/bkSHPIWuqMNIlqgKfpc5gzK81pDj/cdYBViwuZSriXFpETtrx2cychKUi+16TPYcnwACszlBqlXuadCTN7GNh/gkveDtxnZjvD6/dGJyRNAJcBd8auXwZMm9lPw+NvAW8J/74S+LwFfB8Yl5ROLcSUicxKWcmrFFEUDj3qbwA49+Rl3Hjx+kRFk2oRPTkemSrVHHpRawBYtXiIL15/Dpdv6sifb5HRwTyHYqGsSYTDX115Op+6pnMKY6VFGkbnDcASSQ9JelTSO2PnbgU+AMSrlz8H5CVtCY/fCkRFClYDu2LX7g7bKpB0g6Rtkrbt27cvhWE0RqQ5lNdy6HRWj7tZaXggz02XbEh0I6j9nqWaw/MvTrFz/5GedEZHXLB+ebHWRqcyFpYKbcastGx0MFNJFesljV9HHngNgYbwRuAjkjZIuhzYa2aPxi82MwOuBj4p6b+Bw0Bj1cOD97nDzLaY2ZYVK1Y0PYhGKWoOGdkdHVHoz7FqcSFR7LVTm5FYKCvA9t3B5rde1RyyQmRWmgrNSv0ZijxsNWncIXYDz5vZJDAp6WFgE7AZuELSVqAALJL0RTO71sy+B7wOQNJvE2gfAM8wp0UATIRtHUdkTsqSMzri41dt6mhHYRYZLgtlfWzXAfoEr0q4T8BZGEYLefZPTjelOXQraczE14ELJOUlDQPnADvM7BYzmzCzdQSawoNmdi2ApJeF/w8CfwbcHr7X/cA7w6ilc4GDZrYnhT6mTmROyprmAHD+qcs5bdWi+S906mYg10e+T0xOzXD02HEe2P5LTlu1qO5kgE57iKrBRQ7pQdccisz7zZV0L3AhsFzSbuCjQD+Amd1uZjskfRPYTuBbuNPMaoa9htxx2QcoAAAIaklEQVQcmp36gNvM7MGw/RvAVuAp4AjwrsaHtDBEX6KsOaSd1iApLBV6nE9866c8vW+SL1x/dru75czDWKGfw02mz+hW5hUOZnZNHdd8DPjYCc4/BDwUO74ZuLnKdQa8b77P6wQK/dk1KzmtYWQwz/effp6f/Oowbz9nLa9bv/C+MKcxyh3SvboxtBo+EwnJqkPaaR0jg3l+/OxhVo8P8aGtp7W7O04djA7meenY8eLmRdcc5vCZSEhWQ1md1hGVdvy7t766Y2sYOKVE6/TCkSDluwuHOfwbnJCiWcl9Dk7ImzdPcNmrV3HeKcvb3RWnTqKcSFE9EI9WmsOFQ0KiTKxuVnIirjtvXbu74DRIlEZm/4suHMrxmUhIPgxddIe042SXSHPYPzlNvk8Vabd7GdccmuDmN76S156yrN3dcBwnIZHPYf+Rafc3lOHCoQne+/pT2t0Fx3GaIMoxtn/ShUM5PhuO4/QsUXbiF45M+x6HMnw2HMfpWSKzkpk7o8vx2XAcp2cZHsih0AfteZVK8dlwHKdniarBgW+AK8dnw3GcnmbMhUNVfDYcx+lpor0O7pAuxWfDcZyepmhWcuFQgs+G4zg9TbTXwc1KpfhsOI7T00RmJRcOpfhsOI7T04y5WakqPhuO4/Q0HspanbpmQ9JdkvZKqlkbWtKFkh6X9KSk75ady0l6TNIDsbaLJf0gfM1/STo1bF8r6Tvh9dslbU06OMdxnPkompVccyih3tm4G7i01klJ48BngCvM7HTgqrJLbgR2lLXdBrzDzM4E/hn4cNj+YeArZnYWcHX4vo7jOC3BNYfq1DUbZvYwsP8El7wduM/MdobX741OSJoALgPuLH9bYFH492Lgl/O0O47jpM6Y73OoSlopuzcA/ZIeAsaAT5nZ58NztwIfCNvjvAf4hqSXgEPAuWH7XwD/LumPgBHgDSn10XEcp4LRQQ9lrUZas5EHXkOgIbwR+IikDZIuB/aa2aNVXnMTsNXMJoDPAZ8I268B7g7btwJfkFTRT0k3SNomadu+fftSGobjOL3GmIeyViWt2dgN/JuZTZrZc8DDwCbgfOAKST8HvgRcJOmLklYAm8zskfD1XwbOC/++HvgKgJl9DygAFRXbzewOM9tiZltWrFiR0jAcx+k1Ioe0Z2UtJa3Z+DpwgaS8pGHgHGCHmd1iZhNmto7AufygmV0LvAAslrQhfP0lzDmsdwIXA0g6jUA4uGrgOE5LiPY59Oe8fnScunwOku4FLgSWS9oNfBToBzCz281sh6RvAtuBWeBOM6sZ9mpmM5L+APiapFkCYfHu8PT7gX+UdBOBc/r3zcwSjc5xHGcePJS1OuqG++6WLVts27Zt7e6G4zgZxMy49T9+xlVbJphYMtzu7iwokh41sy3VzqUVreQ4jpNJJHHTJRvmv7DHcD3KcRzHqcCFg+M4jlOBCwfHcRynAhcOjuM4TgUuHBzHcZwKXDg4juM4FbhwcBzHcSpw4eA4juNU0BU7pCXtA36R8OXLgedS7E5W6MVx9+KYoTfH3YtjhsbH/XIzq5q5tCuEQzNI2lZr+3g304vj7sUxQ2+OuxfHDOmO281KjuM4TgUuHBzHcZwKXDjAHe3uQJvoxXH34pihN8fdi2OGFMfd8z4Hx3EcpxLXHBzHcZwKXDg4juM4FfS0cJB0qaSfSHpK0gfb3Z9WIGmNpO9I+pGkJyXdGLYvlfQtST8L/1/S7r62Akk5SY9JeiA8foWkR8I1/7KkgXb3MU0kjUv6qqQfS9oh6bW9sNaSbgq/309IuldSoRvXWtJdkvZKeiLWVnV9FfDpcPzbJW1u5LN6VjhIygH/ALwJ2AhcI2lje3vVEmaA95vZRuBc4H3hOD8IfNvM1gPfDo+7kRuBHbHjvwU+aWanEtQuv74tvWodnwK+aWa/DmwiGHtXr7Wk1cAfA1vM7AwgB1xNd6713cClZW211vdNwPrw3w3AbY18UM8KB+Bs4Ckze9rMpoEvAVe2uU+pY2Z7zOwH4d+HCW4WqwnGek942T3A77anh61D0gRwGXBneCzgIuCr4SVdNW5Ji4HfBD4LYGbTZnaAHlhrgpLHQ5LywDCwhy5cazN7GNhf1lxrfa8EPm8B3wfGJa2q97N6WTisBnbFjneHbV2LpHXAWcAjwEoz2xOeehZY2aZutZJbgQ8As+HxMuCAmc2Ex9225q8A9gGfC01pd0oaocvX2syeAT4O7CQQCgeBR+nutY5Ta32busf1snDoKSSNAl8D/sTMDsXPWRDP3FUxzZIuB/aa2aPt7ssCkgc2A7eZ2VnAJGUmpC5d6yUET8mvAE4CRqg0vfQEaa5vLwuHZ4A1seOJsK3rkNRPIBj+yczuC5t/FamY4f9729W/FnE+cIWknxOYDC8isMePh6YH6L413w3sNrNHwuOvEgiLbl/rNwD/Z2b7zOwYcB/B+nfzWseptb5N3eN6WTj8D7A+jGgYIHBg3d/mPqVOaGf/LLDDzD4RO3U/cF3493XA1xe6b63EzG4xswkzW0ewtg+a2TuA7wBvDS/rqnGb2bPALkmvDJsuBn5El681gTnpXEnD4fc9GnfXrnUZtdb3fuCdYdTSucDBmPlpXnp6h7SkrQR26Rxwl5n9dZu7lDqSLgD+E/hf5mzvHyLwO3wFWEuQ7vz3zKzc0dUVSLoQ+FMzu1zSyQSaxFLgMeBaM5tqZ//SRNKZBA74AeBp4F0ED4FdvdaS/hJ4G0F03mPAewjs61211pLuBS4kSM39K+CjwL9SZX1DQfn3BCa2I8C7zGxb3Z/Vy8LBcRzHqU4vm5Ucx3GcGrhwcBzHcSpw4eA4juNU4MLBcRzHqcCFg+M4jlOBCwfHcRynAhcOjuM4TgX/D7KnoMfGm3ytAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2G944_MuiOaL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}